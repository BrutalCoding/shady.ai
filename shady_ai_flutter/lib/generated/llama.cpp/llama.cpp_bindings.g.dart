// ignore_for_file: deprecated_member_use

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint
import 'dart:ffi' as ffi;

/// llama.cpp bindings
class LLaMa {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  LLaMa(ffi.DynamicLibrary dynamicLibrary) : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  LLaMa.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  late final ffi.Pointer<ffi.Size> _GGML_OBJECT_SIZE =
      _lookup<ffi.Size>('GGML_OBJECT_SIZE');

  int get GGML_OBJECT_SIZE => _GGML_OBJECT_SIZE.value;

  set GGML_OBJECT_SIZE(int value) => _GGML_OBJECT_SIZE.value = value;

  late final ffi.Pointer<ffi.Size> _GGML_TENSOR_SIZE =
      _lookup<ffi.Size>('GGML_TENSOR_SIZE');

  int get GGML_TENSOR_SIZE => _GGML_TENSOR_SIZE.value;

  set GGML_TENSOR_SIZE(int value) => _GGML_TENSOR_SIZE.value = value;

  late final ffi.Pointer<ffi.Size> _GGML_GRAPH_SIZE =
      _lookup<ffi.Size>('GGML_GRAPH_SIZE');

  int get GGML_GRAPH_SIZE => _GGML_GRAPH_SIZE.value;

  set GGML_GRAPH_SIZE(int value) => _GGML_GRAPH_SIZE.value = value;

  /// misc
  void ggml_time_init() {
    return _ggml_time_init();
  }

  late final _ggml_time_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('ggml_time_init');
  late final _ggml_time_init = _ggml_time_initPtr.asFunction<void Function()>();

  int ggml_time_ms() {
    return _ggml_time_ms();
  }

  late final _ggml_time_msPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>('ggml_time_ms');
  late final _ggml_time_ms = _ggml_time_msPtr.asFunction<int Function()>();

  int ggml_time_us() {
    return _ggml_time_us();
  }

  late final _ggml_time_usPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>('ggml_time_us');
  late final _ggml_time_us = _ggml_time_usPtr.asFunction<int Function()>();

  int ggml_cycles() {
    return _ggml_cycles();
  }

  late final _ggml_cyclesPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>('ggml_cycles');
  late final _ggml_cycles = _ggml_cyclesPtr.asFunction<int Function()>();

  int ggml_cycles_per_ms() {
    return _ggml_cycles_per_ms();
  }

  late final _ggml_cycles_per_msPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>('ggml_cycles_per_ms');
  late final _ggml_cycles_per_ms =
      _ggml_cycles_per_msPtr.asFunction<int Function()>();

  void ggml_numa_init() {
    return _ggml_numa_init();
  }

  late final _ggml_numa_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('ggml_numa_init');
  late final _ggml_numa_init = _ggml_numa_initPtr.asFunction<void Function()>();

  bool ggml_is_numa() {
    return _ggml_is_numa();
  }

  late final _ggml_is_numaPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function()>>('ggml_is_numa');
  late final _ggml_is_numa = _ggml_is_numaPtr.asFunction<bool Function()>();

  void ggml_print_object(
    ffi.Pointer<ggml_object> obj,
  ) {
    return _ggml_print_object(
      obj,
    );
  }

  late final _ggml_print_objectPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_object>)>>(
          'ggml_print_object');
  late final _ggml_print_object = _ggml_print_objectPtr
      .asFunction<void Function(ffi.Pointer<ggml_object>)>();

  void ggml_print_objects(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_print_objects(
      ctx,
    );
  }

  late final _ggml_print_objectsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_context>)>>(
          'ggml_print_objects');
  late final _ggml_print_objects = _ggml_print_objectsPtr
      .asFunction<void Function(ffi.Pointer<ggml_context>)>();

  int ggml_nelements(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_nelements(
      tensor,
    );
  }

  late final _ggml_nelementsPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_nelements');
  late final _ggml_nelements =
      _ggml_nelementsPtr.asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  int ggml_nrows(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_nrows(
      tensor,
    );
  }

  late final _ggml_nrowsPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_nrows');
  late final _ggml_nrows =
      _ggml_nrowsPtr.asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  int ggml_nbytes(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_nbytes(
      tensor,
    );
  }

  late final _ggml_nbytesPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_nbytes');
  late final _ggml_nbytes =
      _ggml_nbytesPtr.asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  int ggml_nbytes_pad(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_nbytes_pad(
      tensor,
    );
  }

  late final _ggml_nbytes_padPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_nbytes_pad');
  late final _ggml_nbytes_pad =
      _ggml_nbytes_padPtr.asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  int ggml_nbytes_split(
    ffi.Pointer<ggml_tensor> tensor,
    int nrows_split,
  ) {
    return _ggml_nbytes_split(
      tensor,
      nrows_split,
    );
  }

  late final _ggml_nbytes_splitPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_nbytes_split');
  late final _ggml_nbytes_split = _ggml_nbytes_splitPtr
      .asFunction<int Function(ffi.Pointer<ggml_tensor>, int)>();

  int ggml_blck_size(
    int type,
  ) {
    return _ggml_blck_size(
      type,
    );
  }

  late final _ggml_blck_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int32)>>(
          'ggml_blck_size');
  late final _ggml_blck_size =
      _ggml_blck_sizePtr.asFunction<int Function(int)>();

  int ggml_type_size(
    int type,
  ) {
    return _ggml_type_size(
      type,
    );
  }

  late final _ggml_type_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Int32)>>(
          'ggml_type_size');
  late final _ggml_type_size =
      _ggml_type_sizePtr.asFunction<int Function(int)>();

  double ggml_type_sizef(
    int type,
  ) {
    return _ggml_type_sizef(
      type,
    );
  }

  late final _ggml_type_sizefPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Int32)>>(
          'ggml_type_sizef');
  late final _ggml_type_sizef =
      _ggml_type_sizefPtr.asFunction<double Function(int)>();

  ffi.Pointer<ffi.Char> ggml_type_name(
    int type,
  ) {
    return _ggml_type_name(
      type,
    );
  }

  late final _ggml_type_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'ggml_type_name');
  late final _ggml_type_name =
      _ggml_type_namePtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  ffi.Pointer<ffi.Char> ggml_op_name(
    int op,
  ) {
    return _ggml_op_name(
      op,
    );
  }

  late final _ggml_op_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'ggml_op_name');
  late final _ggml_op_name =
      _ggml_op_namePtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  ffi.Pointer<ffi.Char> ggml_op_symbol(
    int op,
  ) {
    return _ggml_op_symbol(
      op,
    );
  }

  late final _ggml_op_symbolPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'ggml_op_symbol');
  late final _ggml_op_symbol =
      _ggml_op_symbolPtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  int ggml_element_size(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_element_size(
      tensor,
    );
  }

  late final _ggml_element_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_element_size');
  late final _ggml_element_size = _ggml_element_sizePtr
      .asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_quantized(
    int type,
  ) {
    return _ggml_is_quantized(
      type,
    );
  }

  late final _ggml_is_quantizedPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Int32)>>(
          'ggml_is_quantized');
  late final _ggml_is_quantized =
      _ggml_is_quantizedPtr.asFunction<bool Function(int)>();

  /// TODO: temporary until model loading of ggml examples is refactored
  int ggml_ftype_to_ggml_type(
    int ftype,
  ) {
    return _ggml_ftype_to_ggml_type(
      ftype,
    );
  }

  late final _ggml_ftype_to_ggml_typePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'ggml_ftype_to_ggml_type');
  late final _ggml_ftype_to_ggml_type =
      _ggml_ftype_to_ggml_typePtr.asFunction<int Function(int)>();

  bool ggml_is_transposed(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_transposed(
      tensor,
    );
  }

  late final _ggml_is_transposedPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_transposed');
  late final _ggml_is_transposed = _ggml_is_transposedPtr
      .asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_contiguous(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_contiguous(
      tensor,
    );
  }

  late final _ggml_is_contiguousPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_contiguous');
  late final _ggml_is_contiguous = _ggml_is_contiguousPtr
      .asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_is_permuted(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_is_permuted(
      tensor,
    );
  }

  late final _ggml_is_permutedPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_is_permuted');
  late final _ggml_is_permuted = _ggml_is_permutedPtr
      .asFunction<bool Function(ffi.Pointer<ggml_tensor>)>();

  bool ggml_are_same_shape(
    ffi.Pointer<ggml_tensor> t0,
    ffi.Pointer<ggml_tensor> t1,
  ) {
    return _ggml_are_same_shape(
      t0,
      t1,
    );
  }

  late final _ggml_are_same_shapePtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_are_same_shape');
  late final _ggml_are_same_shape = _ggml_are_same_shapePtr.asFunction<
      bool Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// use this to compute the memory overhead of a tensor
  int ggml_tensor_overhead() {
    return _ggml_tensor_overhead();
  }

  late final _ggml_tensor_overheadPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>('ggml_tensor_overhead');
  late final _ggml_tensor_overhead =
      _ggml_tensor_overheadPtr.asFunction<int Function()>();

  /// main
  ffi.Pointer<ggml_context> ggml_init(
    ggml_init_params params,
  ) {
    return _ggml_init(
      params,
    );
  }

  late final _ggml_initPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_context> Function(ggml_init_params)>>('ggml_init');
  late final _ggml_init = _ggml_initPtr
      .asFunction<ffi.Pointer<ggml_context> Function(ggml_init_params)>();

  void ggml_free(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_free(
      ctx,
    );
  }

  late final _ggml_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_context>)>>(
          'ggml_free');
  late final _ggml_free =
      _ggml_freePtr.asFunction<void Function(ffi.Pointer<ggml_context>)>();

  int ggml_used_mem(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_used_mem(
      ctx,
    );
  }

  late final _ggml_used_memPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_context>)>>(
          'ggml_used_mem');
  late final _ggml_used_mem =
      _ggml_used_memPtr.asFunction<int Function(ffi.Pointer<ggml_context>)>();

  int ggml_set_scratch(
    ffi.Pointer<ggml_context> ctx,
    ggml_scratch scratch,
  ) {
    return _ggml_set_scratch(
      ctx,
      scratch,
    );
  }

  late final _ggml_set_scratchPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<ggml_context>, ggml_scratch)>>('ggml_set_scratch');
  late final _ggml_set_scratch = _ggml_set_scratchPtr
      .asFunction<int Function(ffi.Pointer<ggml_context>, ggml_scratch)>();

  bool ggml_get_no_alloc(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_get_no_alloc(
      ctx,
    );
  }

  late final _ggml_get_no_allocPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ggml_context>)>>(
          'ggml_get_no_alloc');
  late final _ggml_get_no_alloc = _ggml_get_no_allocPtr
      .asFunction<bool Function(ffi.Pointer<ggml_context>)>();

  void ggml_set_no_alloc(
    ffi.Pointer<ggml_context> ctx,
    bool no_alloc,
  ) {
    return _ggml_set_no_alloc(
      ctx,
      no_alloc,
    );
  }

  late final _ggml_set_no_allocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ggml_context>, ffi.Bool)>>('ggml_set_no_alloc');
  late final _ggml_set_no_alloc = _ggml_set_no_allocPtr
      .asFunction<void Function(ffi.Pointer<ggml_context>, bool)>();

  ffi.Pointer<ffi.Void> ggml_get_mem_buffer(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_get_mem_buffer(
      ctx,
    );
  }

  late final _ggml_get_mem_bufferPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ggml_context>)>>('ggml_get_mem_buffer');
  late final _ggml_get_mem_buffer = _ggml_get_mem_bufferPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ggml_context>)>();

  int ggml_get_mem_size(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_get_mem_size(
      ctx,
    );
  }

  late final _ggml_get_mem_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_context>)>>(
          'ggml_get_mem_size');
  late final _ggml_get_mem_size = _ggml_get_mem_sizePtr
      .asFunction<int Function(ffi.Pointer<ggml_context>)>();

  int ggml_get_max_tensor_size(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_get_max_tensor_size(
      ctx,
    );
  }

  late final _ggml_get_max_tensor_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<ggml_context>)>>(
          'ggml_get_max_tensor_size');
  late final _ggml_get_max_tensor_size = _ggml_get_max_tensor_sizePtr
      .asFunction<int Function(ffi.Pointer<ggml_context>)>();

  ffi.Pointer<ggml_tensor> ggml_new_tensor(
    ffi.Pointer<ggml_context> ctx,
    int type,
    int n_dims,
    ffi.Pointer<ffi.Int64> ne,
  ) {
    return _ggml_new_tensor(
      ctx,
      type,
      n_dims,
      ne,
    );
  }

  late final _ggml_new_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Int32, ffi.Int, ffi.Pointer<ffi.Int64>)>>('ggml_new_tensor');
  late final _ggml_new_tensor = _ggml_new_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, int, int, ffi.Pointer<ffi.Int64>)>();

  ffi.Pointer<ggml_tensor> ggml_new_tensor_1d(
    ffi.Pointer<ggml_context> ctx,
    int type,
    int ne0,
  ) {
    return _ggml_new_tensor_1d(
      ctx,
      type,
      ne0,
    );
  }

  late final _ggml_new_tensor_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Int32, ffi.Int64)>>('ggml_new_tensor_1d');
  late final _ggml_new_tensor_1d = _ggml_new_tensor_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_new_tensor_2d(
    ffi.Pointer<ggml_context> ctx,
    int type,
    int ne0,
    int ne1,
  ) {
    return _ggml_new_tensor_2d(
      ctx,
      type,
      ne0,
      ne1,
    );
  }

  late final _ggml_new_tensor_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Int32, ffi.Int64, ffi.Int64)>>('ggml_new_tensor_2d');
  late final _ggml_new_tensor_2d = _ggml_new_tensor_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_new_tensor_3d(
    ffi.Pointer<ggml_context> ctx,
    int type,
    int ne0,
    int ne1,
    int ne2,
  ) {
    return _ggml_new_tensor_3d(
      ctx,
      type,
      ne0,
      ne1,
      ne2,
    );
  }

  late final _ggml_new_tensor_3dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Int32,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64)>>('ggml_new_tensor_3d');
  late final _ggml_new_tensor_3d = _ggml_new_tensor_3dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, int, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_new_tensor_4d(
    ffi.Pointer<ggml_context> ctx,
    int type,
    int ne0,
    int ne1,
    int ne2,
    int ne3,
  ) {
    return _ggml_new_tensor_4d(
      ctx,
      type,
      ne0,
      ne1,
      ne2,
      ne3,
    );
  }

  late final _ggml_new_tensor_4dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Int32,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64)>>('ggml_new_tensor_4d');
  late final _ggml_new_tensor_4d = _ggml_new_tensor_4dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, int, int, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_new_i32(
    ffi.Pointer<ggml_context> ctx,
    int value,
  ) {
    return _ggml_new_i32(
      ctx,
      value,
    );
  }

  late final _ggml_new_i32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>, ffi.Int32)>>('ggml_new_i32');
  late final _ggml_new_i32 = _ggml_new_i32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>, int)>();

  ffi.Pointer<ggml_tensor> ggml_new_f32(
    ffi.Pointer<ggml_context> ctx,
    double value,
  ) {
    return _ggml_new_f32(
      ctx,
      value,
    );
  }

  late final _ggml_new_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>, ffi.Float)>>('ggml_new_f32');
  late final _ggml_new_f32 = _ggml_new_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>, double)>();

  ffi.Pointer<ggml_tensor> ggml_dup_tensor(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> src,
  ) {
    return _ggml_dup_tensor(
      ctx,
      src,
    );
  }

  late final _ggml_dup_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_dup_tensor');
  late final _ggml_dup_tensor = _ggml_dup_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_view_tensor(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> src,
  ) {
    return _ggml_view_tensor(
      ctx,
      src,
    );
  }

  late final _ggml_view_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_view_tensor');
  late final _ggml_view_tensor = _ggml_view_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_get_tensor(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ffi.Char> name,
  ) {
    return _ggml_get_tensor(
      ctx,
      name,
    );
  }

  late final _ggml_get_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ffi.Char>)>>('ggml_get_tensor');
  late final _ggml_get_tensor = _ggml_get_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ggml_tensor> ggml_set_zero(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_set_zero(
      tensor,
    );
  }

  late final _ggml_set_zeroPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_tensor>)>>('ggml_set_zero');
  late final _ggml_set_zero = _ggml_set_zeroPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_set_i32(
    ffi.Pointer<ggml_tensor> tensor,
    int value,
  ) {
    return _ggml_set_i32(
      tensor,
      value,
    );
  }

  late final _ggml_set_i32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_tensor>, ffi.Int32)>>('ggml_set_i32');
  late final _ggml_set_i32 = _ggml_set_i32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_set_f32(
    ffi.Pointer<ggml_tensor> tensor,
    double value,
  ) {
    return _ggml_set_f32(
      tensor,
      value,
    );
  }

  late final _ggml_set_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_set_f32');
  late final _ggml_set_f32 = _ggml_set_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_tensor>, double)>();

  int ggml_get_i32_1d(
    ffi.Pointer<ggml_tensor> tensor,
    int i,
  ) {
    return _ggml_get_i32_1d(
      tensor,
      i,
    );
  }

  late final _ggml_get_i32_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_get_i32_1d');
  late final _ggml_get_i32_1d = _ggml_get_i32_1dPtr
      .asFunction<int Function(ffi.Pointer<ggml_tensor>, int)>();

  void ggml_set_i32_1d(
    ffi.Pointer<ggml_tensor> tensor,
    int i,
    int value,
  ) {
    return _ggml_set_i32_1d(
      tensor,
      i,
      value,
    );
  }

  late final _ggml_set_i32_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Int,
              ffi.Int32)>>('ggml_set_i32_1d');
  late final _ggml_set_i32_1d = _ggml_set_i32_1dPtr
      .asFunction<void Function(ffi.Pointer<ggml_tensor>, int, int)>();

  double ggml_get_f32_1d(
    ffi.Pointer<ggml_tensor> tensor,
    int i,
  ) {
    return _ggml_get_f32_1d(
      tensor,
      i,
    );
  }

  late final _ggml_get_f32_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_get_f32_1d');
  late final _ggml_get_f32_1d = _ggml_get_f32_1dPtr
      .asFunction<double Function(ffi.Pointer<ggml_tensor>, int)>();

  void ggml_set_f32_1d(
    ffi.Pointer<ggml_tensor> tensor,
    int i,
    double value,
  ) {
    return _ggml_set_f32_1d(
      tensor,
      i,
      value,
    );
  }

  late final _ggml_set_f32_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Int,
              ffi.Float)>>('ggml_set_f32_1d');
  late final _ggml_set_f32_1d = _ggml_set_f32_1dPtr
      .asFunction<void Function(ffi.Pointer<ggml_tensor>, int, double)>();

  ffi.Pointer<ffi.Void> ggml_get_data(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_get_data(
      tensor,
    );
  }

  late final _ggml_get_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ggml_tensor>)>>('ggml_get_data');
  late final _ggml_get_data = _ggml_get_dataPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ffi.Float> ggml_get_data_f32(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_get_data_f32(
      tensor,
    );
  }

  late final _ggml_get_data_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(
              ffi.Pointer<ggml_tensor>)>>('ggml_get_data_f32');
  late final _ggml_get_data_f32 = _ggml_get_data_f32Ptr
      .asFunction<ffi.Pointer<ffi.Float> Function(ffi.Pointer<ggml_tensor>)>();

  int ggml_get_unary_op(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_get_unary_op(
      tensor,
    );
  }

  late final _ggml_get_unary_opPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ggml_tensor>)>>(
          'ggml_get_unary_op');
  late final _ggml_get_unary_op = _ggml_get_unary_opPtr
      .asFunction<int Function(ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ffi.Char> ggml_get_name(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_get_name(
      tensor,
    );
  }

  late final _ggml_get_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ggml_tensor>)>>('ggml_get_name');
  late final _ggml_get_name = _ggml_get_namePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_set_name(
    ffi.Pointer<ggml_tensor> tensor,
    ffi.Pointer<ffi.Char> name,
  ) {
    return _ggml_set_name(
      tensor,
      name,
    );
  }

  late final _ggml_set_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ffi.Char>)>>('ggml_set_name');
  late final _ggml_set_name = _ggml_set_namePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ggml_tensor> ggml_format_name(
    ffi.Pointer<ggml_tensor> tensor,
    ffi.Pointer<ffi.Char> fmt,
  ) {
    return _ggml_format_name(
      tensor,
      fmt,
    );
  }

  late final _ggml_format_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ffi.Char>)>>('ggml_format_name');
  late final _ggml_format_name = _ggml_format_namePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ffi.Char>)>();

  /// operations on tensors with backpropagation
  ffi.Pointer<ggml_tensor> ggml_dup(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_dup(
      ctx,
      a,
    );
  }

  late final _ggml_dupPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_dup');
  late final _ggml_dup = _ggml_dupPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_dup_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_dup_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_dup_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_dup_inplace');
  late final _ggml_dup_inplace = _ggml_dup_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_add(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_add(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_addPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>('ggml_add');
  late final _ggml_add = _ggml_addPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_add_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_add_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_add_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_add_inplace');
  late final _ggml_add_inplace = _ggml_add_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_add1(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_add1(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_add1Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_add1');
  late final _ggml_add1 = _ggml_add1Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_add1_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_add1_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_add1_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_add1_inplace');
  late final _ggml_add1_inplace = _ggml_add1_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_acc(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int nb2,
    int nb3,
    int offset,
  ) {
    return _ggml_acc(
      ctx,
      a,
      b,
      nb1,
      nb2,
      nb3,
      offset,
    );
  }

  late final _ggml_accPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_acc');
  late final _ggml_acc = _ggml_accPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int)>();

  ffi.Pointer<ggml_tensor> ggml_acc_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int nb2,
    int nb3,
    int offset,
  ) {
    return _ggml_acc_inplace(
      ctx,
      a,
      b,
      nb1,
      nb2,
      nb3,
      offset,
    );
  }

  late final _ggml_acc_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_acc_inplace');
  late final _ggml_acc_inplace = _ggml_acc_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int)>();

  ffi.Pointer<ggml_tensor> ggml_sub(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_sub(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_subPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>('ggml_sub');
  late final _ggml_sub = _ggml_subPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sub_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_sub_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_sub_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sub_inplace');
  late final _ggml_sub_inplace = _ggml_sub_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_mul(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_mul(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_mulPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>('ggml_mul');
  late final _ggml_mul = _ggml_mulPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_mul_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_mul_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_mul_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_mul_inplace');
  late final _ggml_mul_inplace = _ggml_mul_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_div(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_div(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_divPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>('ggml_div');
  late final _ggml_div = _ggml_divPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_div_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_div_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_div_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_div_inplace');
  late final _ggml_div_inplace = _ggml_div_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sqr(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sqr(
      ctx,
      a,
    );
  }

  late final _ggml_sqrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sqr');
  late final _ggml_sqr = _ggml_sqrPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sqr_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sqr_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_sqr_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sqr_inplace');
  late final _ggml_sqr_inplace = _ggml_sqr_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sqrt(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sqrt(
      ctx,
      a,
    );
  }

  late final _ggml_sqrtPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sqrt');
  late final _ggml_sqrt = _ggml_sqrtPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sqrt_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sqrt_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_sqrt_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sqrt_inplace');
  late final _ggml_sqrt_inplace = _ggml_sqrt_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_log(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_log(
      ctx,
      a,
    );
  }

  late final _ggml_logPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_log');
  late final _ggml_log = _ggml_logPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_log_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_log_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_log_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_log_inplace');
  late final _ggml_log_inplace = _ggml_log_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// return scalar
  ffi.Pointer<ggml_tensor> ggml_sum(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sum(
      ctx,
      a,
    );
  }

  late final _ggml_sumPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sum');
  late final _ggml_sum = _ggml_sumPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// sums along rows, with input shape [a,b,c,d] return shape [1,b,c,d]
  ffi.Pointer<ggml_tensor> ggml_sum_rows(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sum_rows(
      ctx,
      a,
    );
  }

  late final _ggml_sum_rowsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sum_rows');
  late final _ggml_sum_rows = _ggml_sum_rowsPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// mean along rows
  ffi.Pointer<ggml_tensor> ggml_mean(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_mean(
      ctx,
      a,
    );
  }

  late final _ggml_meanPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_mean');
  late final _ggml_mean = _ggml_meanPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// argmax along rows
  ffi.Pointer<ggml_tensor> ggml_argmax(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_argmax(
      ctx,
      a,
    );
  }

  late final _ggml_argmaxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_argmax');
  late final _ggml_argmax = _ggml_argmaxPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// if a is the same shape as b, and a is not parameter, return a
  /// otherwise, return a new tensor: repeat(a) to fit in b
  ffi.Pointer<ggml_tensor> ggml_repeat(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_repeat(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_repeatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_repeat');
  late final _ggml_repeat = _ggml_repeatPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_repeat_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_repeat_back(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_repeat_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_repeat_back');
  late final _ggml_repeat_back = _ggml_repeat_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// concat a and b on dim 2
  /// used in stable-diffusion
  ffi.Pointer<ggml_tensor> ggml_concat(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_concat(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_concatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_concat');
  late final _ggml_concat = _ggml_concatPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_abs(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_abs(
      ctx,
      a,
    );
  }

  late final _ggml_absPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_abs');
  late final _ggml_abs = _ggml_absPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_abs_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_abs_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_abs_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_abs_inplace');
  late final _ggml_abs_inplace = _ggml_abs_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sgn(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sgn(
      ctx,
      a,
    );
  }

  late final _ggml_sgnPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sgn');
  late final _ggml_sgn = _ggml_sgnPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_sgn_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_sgn_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_sgn_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_sgn_inplace');
  late final _ggml_sgn_inplace = _ggml_sgn_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_neg(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_neg(
      ctx,
      a,
    );
  }

  late final _ggml_negPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_neg');
  late final _ggml_neg = _ggml_negPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_neg_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_neg_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_neg_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_neg_inplace');
  late final _ggml_neg_inplace = _ggml_neg_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_step(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_step(
      ctx,
      a,
    );
  }

  late final _ggml_stepPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_step');
  late final _ggml_step = _ggml_stepPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_step_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_step_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_step_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_step_inplace');
  late final _ggml_step_inplace = _ggml_step_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_tanh(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_tanh(
      ctx,
      a,
    );
  }

  late final _ggml_tanhPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_tanh');
  late final _ggml_tanh = _ggml_tanhPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_tanh_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_tanh_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_tanh_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_tanh_inplace');
  late final _ggml_tanh_inplace = _ggml_tanh_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_elu(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_elu(
      ctx,
      a,
    );
  }

  late final _ggml_eluPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_elu');
  late final _ggml_elu = _ggml_eluPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_elu_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_elu_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_elu_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_elu_inplace');
  late final _ggml_elu_inplace = _ggml_elu_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_relu(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_relu(
      ctx,
      a,
    );
  }

  late final _ggml_reluPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_relu');
  late final _ggml_relu = _ggml_reluPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_relu_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_relu_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_relu_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_relu_inplace');
  late final _ggml_relu_inplace = _ggml_relu_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// TODO: double-check this computation is correct
  ffi.Pointer<ggml_tensor> ggml_gelu(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_gelu(
      ctx,
      a,
    );
  }

  late final _ggml_geluPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_gelu');
  late final _ggml_gelu = _ggml_geluPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_gelu_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_gelu_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_gelu_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_gelu_inplace');
  late final _ggml_gelu_inplace = _ggml_gelu_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_gelu_quick(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_gelu_quick(
      ctx,
      a,
    );
  }

  late final _ggml_gelu_quickPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_gelu_quick');
  late final _ggml_gelu_quick = _ggml_gelu_quickPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_gelu_quick_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_gelu_quick_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_gelu_quick_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_gelu_quick_inplace');
  late final _ggml_gelu_quick_inplace = _ggml_gelu_quick_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_silu(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_silu(
      ctx,
      a,
    );
  }

  late final _ggml_siluPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_silu');
  late final _ggml_silu = _ggml_siluPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_silu_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_silu_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_silu_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_silu_inplace');
  late final _ggml_silu_inplace = _ggml_silu_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// a - x
  /// b - dy
  ffi.Pointer<ggml_tensor> ggml_silu_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_silu_back(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_silu_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_silu_back');
  late final _ggml_silu_back = _ggml_silu_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// normalize along rows
  ffi.Pointer<ggml_tensor> ggml_norm(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double eps,
  ) {
    return _ggml_norm(
      ctx,
      a,
      eps,
    );
  }

  late final _ggml_normPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_norm');
  late final _ggml_norm = _ggml_normPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, double)>();

  ffi.Pointer<ggml_tensor> ggml_norm_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double eps,
  ) {
    return _ggml_norm_inplace(
      ctx,
      a,
      eps,
    );
  }

  late final _ggml_norm_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_norm_inplace');
  late final _ggml_norm_inplace = _ggml_norm_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, double)>();

  ffi.Pointer<ggml_tensor> ggml_rms_norm(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double eps,
  ) {
    return _ggml_rms_norm(
      ctx,
      a,
      eps,
    );
  }

  late final _ggml_rms_normPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_rms_norm');
  late final _ggml_rms_norm = _ggml_rms_normPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, double)>();

  ffi.Pointer<ggml_tensor> ggml_rms_norm_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double eps,
  ) {
    return _ggml_rms_norm_inplace(
      ctx,
      a,
      eps,
    );
  }

  late final _ggml_rms_norm_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float)>>('ggml_rms_norm_inplace');
  late final _ggml_rms_norm_inplace = _ggml_rms_norm_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, double)>();

  /// group normalize along ne0*ne1*n_groups
  /// used in stable-diffusion
  /// TODO: eps is hardcoded to 1e-6 for now
  ffi.Pointer<ggml_tensor> ggml_group_norm(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_groups,
  ) {
    return _ggml_group_norm(
      ctx,
      a,
      n_groups,
    );
  }

  late final _ggml_group_normPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_group_norm');
  late final _ggml_group_norm = _ggml_group_normPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_group_norm_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_groups,
  ) {
    return _ggml_group_norm_inplace(
      ctx,
      a,
      n_groups,
    );
  }

  late final _ggml_group_norm_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_group_norm_inplace');
  late final _ggml_group_norm_inplace = _ggml_group_norm_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// a - x
  /// b - dy
  ffi.Pointer<ggml_tensor> ggml_rms_norm_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    double eps,
  ) {
    return _ggml_rms_norm_back(
      ctx,
      a,
      b,
      eps,
    );
  }

  late final _ggml_rms_norm_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Float)>>('ggml_rms_norm_back');
  late final _ggml_rms_norm_back = _ggml_rms_norm_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, double)>();

  /// A: n columns, m rows
  /// B: n columns, p rows  (i.e. we transpose it internally)
  /// result is m columns, p rows
  ffi.Pointer<ggml_tensor> ggml_mul_mat(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_mul_mat(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_mul_matPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_mul_mat');
  late final _ggml_mul_mat = _ggml_mul_matPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// A: m columns, n rows,
  /// B: p columns, n rows,
  /// result is m columns, p rows
  ffi.Pointer<ggml_tensor> ggml_out_prod(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_out_prod(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_out_prodPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_out_prod');
  late final _ggml_out_prod = _ggml_out_prodPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// operations on tensors without backpropagation
  ffi.Pointer<ggml_tensor> ggml_scale(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_scale(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_scalePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_scale');
  late final _ggml_scale = _ggml_scalePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_scale_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_scale_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_scale_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_scale_inplace');
  late final _ggml_scale_inplace = _ggml_scale_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// b -> view(a,offset,nb1,nb2,3), return modified a
  ffi.Pointer<ggml_tensor> ggml_set(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int nb2,
    int nb3,
    int offset,
  ) {
    return _ggml_set(
      ctx,
      a,
      b,
      nb1,
      nb2,
      nb3,
      offset,
    );
  }

  late final _ggml_setPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_set');
  late final _ggml_set = _ggml_setPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int)>();

  /// b -> view(a,offset,nb1,nb2,3), return view(a)
  ffi.Pointer<ggml_tensor> ggml_set_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int nb2,
    int nb3,
    int offset,
  ) {
    return _ggml_set_inplace(
      ctx,
      a,
      b,
      nb1,
      nb2,
      nb3,
      offset,
    );
  }

  late final _ggml_set_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_set_inplace');
  late final _ggml_set_inplace = _ggml_set_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int)>();

  ffi.Pointer<ggml_tensor> ggml_set_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int offset,
  ) {
    return _ggml_set_1d(
      ctx,
      a,
      b,
      offset,
    );
  }

  late final _ggml_set_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size)>>('ggml_set_1d');
  late final _ggml_set_1d = _ggml_set_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_set_1d_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int offset,
  ) {
    return _ggml_set_1d_inplace(
      ctx,
      a,
      b,
      offset,
    );
  }

  late final _ggml_set_1d_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size)>>('ggml_set_1d_inplace');
  late final _ggml_set_1d_inplace = _ggml_set_1d_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int)>();

  /// b -> view(a,offset,nb1,nb2,3), return modified a
  ffi.Pointer<ggml_tensor> ggml_set_2d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int offset,
  ) {
    return _ggml_set_2d(
      ctx,
      a,
      b,
      nb1,
      offset,
    );
  }

  late final _ggml_set_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size)>>('ggml_set_2d');
  late final _ggml_set_2d = _ggml_set_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// b -> view(a,offset,nb1,nb2,3), return view(a)
  ffi.Pointer<ggml_tensor> ggml_set_2d_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int nb1,
    int offset,
  ) {
    return _ggml_set_2d_inplace(
      ctx,
      a,
      b,
      nb1,
      offset,
    );
  }

  late final _ggml_set_2d_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Size,
              ffi.Size)>>('ggml_set_2d_inplace');
  late final _ggml_set_2d_inplace = _ggml_set_2d_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// a -> b, return view(b)
  ffi.Pointer<ggml_tensor> ggml_cpy(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_cpy(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_cpyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>('ggml_cpy');
  late final _ggml_cpy = _ggml_cpyPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// a -> b, in-place, return view(b)
  ffi.Pointer<ggml_tensor> ggml_cpy_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_cpy_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_cpy_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_cpy_inplace');
  late final _ggml_cpy_inplace = _ggml_cpy_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// make contiguous
  ffi.Pointer<ggml_tensor> ggml_cont(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_cont(
      ctx,
      a,
    );
  }

  late final _ggml_contPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_cont');
  late final _ggml_cont = _ggml_contPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// make contiguous, in-place
  ffi.Pointer<ggml_tensor> ggml_cont_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_cont_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_cont_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_cont_inplace');
  late final _ggml_cont_inplace = _ggml_cont_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// return view(a), b specifies the new shape
  /// TODO: when we start computing gradient, make a copy instead of view
  ffi.Pointer<ggml_tensor> ggml_reshape(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_reshape(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_reshapePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_reshape');
  late final _ggml_reshape = _ggml_reshapePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// return view(a)
  /// TODO: when we start computing gradient, make a copy instead of view
  ffi.Pointer<ggml_tensor> ggml_reshape_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
  ) {
    return _ggml_reshape_1d(
      ctx,
      a,
      ne0,
    );
  }

  late final _ggml_reshape_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int64)>>('ggml_reshape_1d');
  late final _ggml_reshape_1d = _ggml_reshape_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_reshape_2d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
  ) {
    return _ggml_reshape_2d(
      ctx,
      a,
      ne0,
      ne1,
    );
  }

  late final _ggml_reshape_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64)>>('ggml_reshape_2d');
  late final _ggml_reshape_2d = _ggml_reshape_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// return view(a)
  /// TODO: when we start computing gradient, make a copy instead of view
  ffi.Pointer<ggml_tensor> ggml_reshape_3d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int ne2,
  ) {
    return _ggml_reshape_3d(
      ctx,
      a,
      ne0,
      ne1,
      ne2,
    );
  }

  late final _ggml_reshape_3dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64)>>('ggml_reshape_3d');
  late final _ggml_reshape_3d = _ggml_reshape_3dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_reshape_4d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int ne2,
    int ne3,
  ) {
    return _ggml_reshape_4d(
      ctx,
      a,
      ne0,
      ne1,
      ne2,
      ne3,
    );
  }

  late final _ggml_reshape_4dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64)>>('ggml_reshape_4d');
  late final _ggml_reshape_4d = _ggml_reshape_4dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  /// offset in bytes
  ffi.Pointer<ggml_tensor> ggml_view_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int offset,
  ) {
    return _ggml_view_1d(
      ctx,
      a,
      ne0,
      offset,
    );
  }

  late final _ggml_view_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int64, ffi.Size)>>('ggml_view_1d');
  late final _ggml_view_1d = _ggml_view_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_view_2d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int nb1,
    int offset,
  ) {
    return _ggml_view_2d(
      ctx,
      a,
      ne0,
      ne1,
      nb1,
      offset,
    );
  }

  late final _ggml_view_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Size,
              ffi.Size)>>('ggml_view_2d');
  late final _ggml_view_2d = _ggml_view_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_view_3d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int ne2,
    int nb1,
    int nb2,
    int offset,
  ) {
    return _ggml_view_3d(
      ctx,
      a,
      ne0,
      ne1,
      ne2,
      nb1,
      nb2,
      offset,
    );
  }

  late final _ggml_view_3dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_view_3d');
  late final _ggml_view_3d = _ggml_view_3dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_view_4d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int ne0,
    int ne1,
    int ne2,
    int ne3,
    int nb1,
    int nb2,
    int nb3,
    int offset,
  ) {
    return _ggml_view_4d(
      ctx,
      a,
      ne0,
      ne1,
      ne2,
      ne3,
      nb1,
      nb2,
      nb3,
      offset,
    );
  }

  late final _ggml_view_4dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Size,
              ffi.Size,
              ffi.Size,
              ffi.Size)>>('ggml_view_4d');
  late final _ggml_view_4d = _ggml_view_4dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int, int, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_permute(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int axis0,
    int axis1,
    int axis2,
    int axis3,
  ) {
    return _ggml_permute(
      ctx,
      a,
      axis0,
      axis1,
      axis2,
      axis3,
    );
  }

  late final _ggml_permutePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_permute');
  late final _ggml_permute = _ggml_permutePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  /// alias for ggml_permute(ctx, a, 1, 0, 2, 3)
  ffi.Pointer<ggml_tensor> ggml_transpose(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_transpose(
      ctx,
      a,
    );
  }

  late final _ggml_transposePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_transpose');
  late final _ggml_transpose = _ggml_transposePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_get_rows(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_get_rows(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_get_rowsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_get_rows');
  late final _ggml_get_rows = _ggml_get_rowsPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_get_rows_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
  ) {
    return _ggml_get_rows_back(
      ctx,
      a,
      b,
      c,
    );
  }

  late final _ggml_get_rows_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_get_rows_back');
  late final _ggml_get_rows_back = _ggml_get_rows_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_diag(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_diag(
      ctx,
      a,
    );
  }

  late final _ggml_diagPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_diag');
  late final _ggml_diag = _ggml_diagPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// set elements above the diagonal to -INF
  ffi.Pointer<ggml_tensor> ggml_diag_mask_inf(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
  ) {
    return _ggml_diag_mask_inf(
      ctx,
      a,
      n_past,
    );
  }

  late final _ggml_diag_mask_infPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_diag_mask_inf');
  late final _ggml_diag_mask_inf = _ggml_diag_mask_infPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_diag_mask_inf_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
  ) {
    return _ggml_diag_mask_inf_inplace(
      ctx,
      a,
      n_past,
    );
  }

  late final _ggml_diag_mask_inf_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int)>>('ggml_diag_mask_inf_inplace');
  late final _ggml_diag_mask_inf_inplace =
      _ggml_diag_mask_inf_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// set elements above the diagonal to 0
  ffi.Pointer<ggml_tensor> ggml_diag_mask_zero(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
  ) {
    return _ggml_diag_mask_zero(
      ctx,
      a,
      n_past,
    );
  }

  late final _ggml_diag_mask_zeroPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_diag_mask_zero');
  late final _ggml_diag_mask_zero = _ggml_diag_mask_zeroPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_diag_mask_zero_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
  ) {
    return _ggml_diag_mask_zero_inplace(
      ctx,
      a,
      n_past,
    );
  }

  late final _ggml_diag_mask_zero_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int)>>('ggml_diag_mask_zero_inplace');
  late final _ggml_diag_mask_zero_inplace =
      _ggml_diag_mask_zero_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_soft_max(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_soft_max(
      ctx,
      a,
    );
  }

  late final _ggml_soft_maxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_soft_max');
  late final _ggml_soft_max = _ggml_soft_maxPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_soft_max_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
  ) {
    return _ggml_soft_max_inplace(
      ctx,
      a,
    );
  }

  late final _ggml_soft_max_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_soft_max_inplace');
  late final _ggml_soft_max_inplace = _ggml_soft_max_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_soft_max_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_soft_max_back(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_soft_max_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_soft_max_back');
  late final _ggml_soft_max_back = _ggml_soft_max_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_soft_max_back_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_soft_max_back_inplace(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_soft_max_back_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_soft_max_back_inplace');
  late final _ggml_soft_max_back_inplace =
      _ggml_soft_max_back_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// rotary position embedding
  /// if mode & 1 == 1, skip n_past elements
  /// if mode & 2 == 1, GPT-NeoX style
  /// if mode & 4 == 1, ChatGLM style
  /// TODO: avoid creating a new tensor every time
  ffi.Pointer<ggml_tensor> ggml_rope(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
    int n_dims,
    int mode,
    int n_ctx,
  ) {
    return _ggml_rope(
      ctx,
      a,
      n_past,
      n_dims,
      mode,
      n_ctx,
    );
  }

  late final _ggml_ropePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_rope');
  late final _ggml_rope = _ggml_ropePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_rope_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
    int n_dims,
    int mode,
    int n_ctx,
  ) {
    return _ggml_rope_inplace(
      ctx,
      a,
      n_past,
      n_dims,
      mode,
      n_ctx,
    );
  }

  late final _ggml_rope_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_rope_inplace');
  late final _ggml_rope_inplace = _ggml_rope_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  /// custom RoPE
  ffi.Pointer<ggml_tensor> ggml_rope_custom(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
    int n_dims,
    int mode,
    int n_ctx,
    double freq_base,
    double freq_scale,
  ) {
    return _ggml_rope_custom(
      ctx,
      a,
      n_past,
      n_dims,
      mode,
      n_ctx,
      freq_base,
      freq_scale,
    );
  }

  late final _ggml_rope_customPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float)>>('ggml_rope_custom');
  late final _ggml_rope_custom = _ggml_rope_customPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int, double, double)>();

  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_rope_custom_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
    int n_dims,
    int mode,
    int n_ctx,
    double freq_base,
    double freq_scale,
  ) {
    return _ggml_rope_custom_inplace(
      ctx,
      a,
      n_past,
      n_dims,
      mode,
      n_ctx,
      freq_base,
      freq_scale,
    );
  }

  late final _ggml_rope_custom_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float)>>('ggml_rope_custom_inplace');
  late final _ggml_rope_custom_inplace =
      _ggml_rope_custom_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, int, int, int, int, double, double)>();

  /// xPos RoPE, in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_rope_xpos_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
    int n_dims,
    double base,
    bool down,
  ) {
    return _ggml_rope_xpos_inplace(
      ctx,
      a,
      n_past,
      n_dims,
      base,
      down,
    );
  }

  late final _ggml_rope_xpos_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Bool)>>('ggml_rope_xpos_inplace');
  late final _ggml_rope_xpos_inplace = _ggml_rope_xpos_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, double, bool)>();

  /// rotary position embedding backward, i.e compute dx from dy
  /// a - dy
  ffi.Pointer<ggml_tensor> ggml_rope_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
    int n_dims,
    int mode,
    int n_ctx,
    double freq_base,
    double freq_scale,
    double xpos_base,
    bool xpos_down,
  ) {
    return _ggml_rope_back(
      ctx,
      a,
      n_past,
      n_dims,
      mode,
      n_ctx,
      freq_base,
      freq_scale,
      xpos_base,
      xpos_down,
    );
  }

  late final _ggml_rope_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Bool)>>('ggml_rope_back');
  late final _ggml_rope_back = _ggml_rope_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int,
          double,
          double,
          double,
          bool)>();

  /// alibi position embedding
  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_alibi(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int n_past,
    int n_head,
    double bias_max,
  ) {
    return _ggml_alibi(
      ctx,
      a,
      n_past,
      n_head,
      bias_max,
    );
  }

  late final _ggml_alibiPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Float)>>('ggml_alibi');
  late final _ggml_alibi = _ggml_alibiPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, double)>();

  /// clamp
  /// in-place, returns view(a)
  ffi.Pointer<ggml_tensor> ggml_clamp(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    double min,
    double max,
  ) {
    return _ggml_clamp(
      ctx,
      a,
      min,
      max,
    );
  }

  late final _ggml_clampPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Float, ffi.Float)>>('ggml_clamp');
  late final _ggml_clamp = _ggml_clampPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, double, double)>();

  ffi.Pointer<ggml_tensor> ggml_conv_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int s0,
    int p0,
    int d0,
  ) {
    return _ggml_conv_1d(
      ctx,
      a,
      b,
      s0,
      p0,
      d0,
    );
  }

  late final _ggml_conv_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_conv_1d');
  late final _ggml_conv_1d = _ggml_conv_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int, int)>();

  /// conv_1d with padding = half
  /// alias for ggml_conv_1d(a, b, s, a->ne[0]/2, d)
  ffi.Pointer<ggml_tensor> ggml_conv_1d_ph(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int s,
    int d,
  ) {
    return _ggml_conv_1d_ph(
      ctx,
      a,
      b,
      s,
      d,
    );
  }

  late final _ggml_conv_1d_phPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int)>>('ggml_conv_1d_ph');
  late final _ggml_conv_1d_ph = _ggml_conv_1d_phPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_conv_2d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int s0,
    int s1,
    int p0,
    int p1,
    int d0,
    int d1,
  ) {
    return _ggml_conv_2d(
      ctx,
      a,
      b,
      s0,
      s1,
      p0,
      p1,
      d0,
      d1,
    );
  }

  late final _ggml_conv_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_conv_2d');
  late final _ggml_conv_2d = _ggml_conv_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          int,
          int,
          int,
          int,
          int,
          int)>();

  /// kernel size is a->ne[0] x a->ne[1]
  /// stride is equal to kernel size
  /// padding is zero
  /// example:
  /// a:     16   16    3  768
  /// b:   1024 1024    3    1
  /// res:   64   64  768    1
  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_conv_2d_sk_p0(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_conv_2d_sk_p0(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_conv_2d_sk_p0Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_conv_2d_sk_p0');
  late final _ggml_conv_2d_sk_p0 = _ggml_conv_2d_sk_p0Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  /// kernel size is a->ne[0] x a->ne[1]
  /// stride is 1
  /// padding is half
  /// example:
  /// a:      3    3    256  256
  /// b:     64   64    256    1
  /// res:   64   64    256    1
  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_conv_2d_s1_ph(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_conv_2d_s1_ph(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_conv_2d_s1_phPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_conv_2d_s1_ph');
  late final _ggml_conv_2d_s1_ph = _ggml_conv_2d_s1_phPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_conv_transpose_2d_p0(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    int stride,
  ) {
    return _ggml_conv_transpose_2d_p0(
      ctx,
      a,
      b,
      stride,
    );
  }

  late final _ggml_conv_transpose_2d_p0Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int)>>('ggml_conv_transpose_2d_p0');
  late final _ggml_conv_transpose_2d_p0 =
      _ggml_conv_transpose_2d_p0Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_pool_1d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int op,
    int k0,
    int s0,
    int p0,
  ) {
    return _ggml_pool_1d(
      ctx,
      a,
      op,
      k0,
      s0,
      p0,
    );
  }

  late final _ggml_pool_1dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int32,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_pool_1d');
  late final _ggml_pool_1d = _ggml_pool_1dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_pool_2d(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int op,
    int k0,
    int k1,
    int s0,
    int s1,
    int p0,
    int p1,
  ) {
    return _ggml_pool_2d(
      ctx,
      a,
      op,
      k0,
      k1,
      s0,
      s1,
      p0,
      p1,
    );
  }

  late final _ggml_pool_2dPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int32,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_pool_2d');
  late final _ggml_pool_2d = _ggml_pool_2dPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int, int, int, int, int)>();

  /// nearest interpolate
  /// used in stable-diffusion
  ffi.Pointer<ggml_tensor> ggml_upscale(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int scale_factor,
  ) {
    return _ggml_upscale(
      ctx,
      a,
      scale_factor,
    );
  }

  late final _ggml_upscalePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_upscale');
  late final _ggml_upscale = _ggml_upscalePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_flash_attn(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> q,
    ffi.Pointer<ggml_tensor> k,
    ffi.Pointer<ggml_tensor> v,
    bool masked,
  ) {
    return _ggml_flash_attn(
      ctx,
      q,
      k,
      v,
      masked,
    );
  }

  late final _ggml_flash_attnPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Bool)>>('ggml_flash_attn');
  late final _ggml_flash_attn = _ggml_flash_attnPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          bool)>();

  ffi.Pointer<ggml_tensor> ggml_flash_attn_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> q,
    ffi.Pointer<ggml_tensor> k,
    ffi.Pointer<ggml_tensor> v,
    ffi.Pointer<ggml_tensor> d,
    bool masked,
  ) {
    return _ggml_flash_attn_back(
      ctx,
      q,
      k,
      v,
      d,
      masked,
    );
  }

  late final _ggml_flash_attn_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Bool)>>('ggml_flash_attn_back');
  late final _ggml_flash_attn_back = _ggml_flash_attn_backPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          bool)>();

  ffi.Pointer<ggml_tensor> ggml_flash_ff(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b0,
    ffi.Pointer<ggml_tensor> b1,
    ffi.Pointer<ggml_tensor> c0,
    ffi.Pointer<ggml_tensor> c1,
  ) {
    return _ggml_flash_ff(
      ctx,
      a,
      b0,
      b1,
      c0,
      c1,
    );
  }

  late final _ggml_flash_ffPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_flash_ff');
  late final _ggml_flash_ff = _ggml_flash_ffPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>)>();

  /// partition into non-overlapping windows with padding if needed
  /// example:
  /// a:   768   64   64    1
  /// w:    14
  /// res: 768   14   14    25
  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_win_part(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int w,
  ) {
    return _ggml_win_part(
      ctx,
      a,
      w,
    );
  }

  late final _ggml_win_partPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int)>>('ggml_win_part');
  late final _ggml_win_part = _ggml_win_partPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// reverse of ggml_win_part
  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_win_unpart(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int w0,
    int h0,
    int w,
  ) {
    return _ggml_win_unpart(
      ctx,
      a,
      w0,
      h0,
      w,
    );
  }

  late final _ggml_win_unpartPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('ggml_win_unpart');
  late final _ggml_win_unpart = _ggml_win_unpartPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, int, int, int)>();

  ffi.Pointer<ggml_tensor> ggml_unary(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int op,
  ) {
    return _ggml_unary(
      ctx,
      a,
      op,
    );
  }

  late final _ggml_unaryPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int32)>>('ggml_unary');
  late final _ggml_unary = _ggml_unaryPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  ffi.Pointer<ggml_tensor> ggml_unary_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int op,
  ) {
    return _ggml_unary_inplace(
      ctx,
      a,
      op,
    );
  }

  late final _ggml_unary_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int32)>>('ggml_unary_inplace');
  late final _ggml_unary_inplace = _ggml_unary_inplacePtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int)>();

  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_get_rel_pos(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    int qh,
    int kh,
  ) {
    return _ggml_get_rel_pos(
      ctx,
      a,
      qh,
      kh,
    );
  }

  late final _ggml_get_rel_posPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ffi.Int, ffi.Int)>>('ggml_get_rel_pos');
  late final _ggml_get_rel_pos = _ggml_get_rel_posPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>, int, int)>();

  /// used in sam
  ffi.Pointer<ggml_tensor> ggml_add_rel_pos(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> pw,
    ffi.Pointer<ggml_tensor> ph,
  ) {
    return _ggml_add_rel_pos(
      ctx,
      a,
      pw,
      ph,
    );
  }

  late final _ggml_add_rel_posPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_add_rel_pos');
  late final _ggml_add_rel_pos = _ggml_add_rel_posPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_add_rel_pos_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> pw,
    ffi.Pointer<ggml_tensor> ph,
  ) {
    return _ggml_add_rel_pos_inplace(
      ctx,
      a,
      pw,
      ph,
    );
  }

  late final _ggml_add_rel_pos_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_add_rel_pos_inplace');
  late final _ggml_add_rel_pos_inplace =
      _ggml_add_rel_pos_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_map_unary_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_unary_op_f32_t fun,
  ) {
    return _ggml_map_unary_f32(
      ctx,
      a,
      fun,
    );
  }

  late final _ggml_map_unary_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_unary_op_f32_t)>>('ggml_map_unary_f32');
  late final _ggml_map_unary_f32 = _ggml_map_unary_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ggml_unary_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_unary_inplace_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_unary_op_f32_t fun,
  ) {
    return _ggml_map_unary_inplace_f32(
      ctx,
      a,
      fun,
    );
  }

  late final _ggml_map_unary_inplace_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_unary_op_f32_t)>>('ggml_map_unary_inplace_f32');
  late final _ggml_map_unary_inplace_f32 =
      _ggml_map_unary_inplace_f32Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ggml_unary_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_binary_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_binary_op_f32_t fun,
  ) {
    return _ggml_map_binary_f32(
      ctx,
      a,
      b,
      fun,
    );
  }

  late final _ggml_map_binary_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_binary_op_f32_t)>>('ggml_map_binary_f32');
  late final _ggml_map_binary_f32 = _ggml_map_binary_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ggml_binary_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_binary_inplace_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_binary_op_f32_t fun,
  ) {
    return _ggml_map_binary_inplace_f32(
      ctx,
      a,
      b,
      fun,
    );
  }

  late final _ggml_map_binary_inplace_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_binary_op_f32_t)>>('ggml_map_binary_inplace_f32');
  late final _ggml_map_binary_inplace_f32 =
      _ggml_map_binary_inplace_f32Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_binary_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom1_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_custom1_op_f32_t fun,
  ) {
    return _ggml_map_custom1_f32(
      ctx,
      a,
      fun,
    );
  }

  late final _ggml_map_custom1_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom1_op_f32_t)>>('ggml_map_custom1_f32');
  late final _ggml_map_custom1_f32 = _ggml_map_custom1_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ggml_custom1_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom1_inplace_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_custom1_op_f32_t fun,
  ) {
    return _ggml_map_custom1_inplace_f32(
      ctx,
      a,
      fun,
    );
  }

  late final _ggml_map_custom1_inplace_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom1_op_f32_t)>>('ggml_map_custom1_inplace_f32');
  late final _ggml_map_custom1_inplace_f32 =
      _ggml_map_custom1_inplace_f32Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>, ggml_custom1_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom2_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_custom2_op_f32_t fun,
  ) {
    return _ggml_map_custom2_f32(
      ctx,
      a,
      b,
      fun,
    );
  }

  late final _ggml_map_custom2_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_f32_t)>>('ggml_map_custom2_f32');
  late final _ggml_map_custom2_f32 = _ggml_map_custom2_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ggml_custom2_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom2_inplace_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_custom2_op_f32_t fun,
  ) {
    return _ggml_map_custom2_inplace_f32(
      ctx,
      a,
      b,
      fun,
    );
  }

  late final _ggml_map_custom2_inplace_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_f32_t)>>('ggml_map_custom2_inplace_f32');
  late final _ggml_map_custom2_inplace_f32 =
      _ggml_map_custom2_inplace_f32Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom3_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    ggml_custom3_op_f32_t fun,
  ) {
    return _ggml_map_custom3_f32(
      ctx,
      a,
      b,
      c,
      fun,
    );
  }

  late final _ggml_map_custom3_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_f32_t)>>('ggml_map_custom3_f32');
  late final _ggml_map_custom3_f32 = _ggml_map_custom3_f32Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ggml_custom3_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom3_inplace_f32(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    ggml_custom3_op_f32_t fun,
  ) {
    return _ggml_map_custom3_inplace_f32(
      ctx,
      a,
      b,
      c,
      fun,
    );
  }

  late final _ggml_map_custom3_inplace_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_f32_t)>>('ggml_map_custom3_inplace_f32');
  late final _ggml_map_custom3_inplace_f32 =
      _ggml_map_custom3_inplace_f32Ptr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_f32_t)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom1(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_custom1_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom1(
      ctx,
      a,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom1Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom1_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom1');
  late final _ggml_map_custom1 = _ggml_map_custom1Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ggml_custom1_op_t,
          int,
          ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom1_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ggml_custom1_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom1_inplace(
      ctx,
      a,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom1_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom1_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom1_inplace');
  late final _ggml_map_custom1_inplace =
      _ggml_map_custom1_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom1_op_t,
              int,
              ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom2(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_custom2_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom2(
      ctx,
      a,
      b,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom2Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom2');
  late final _ggml_map_custom2 = _ggml_map_custom2Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ggml_custom2_op_t,
          int,
          ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom2_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ggml_custom2_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom2_inplace(
      ctx,
      a,
      b,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom2_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom2_inplace');
  late final _ggml_map_custom2_inplace =
      _ggml_map_custom2_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom2_op_t,
              int,
              ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom3(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    ggml_custom3_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom3(
      ctx,
      a,
      b,
      c,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom3Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom3');
  late final _ggml_map_custom3 = _ggml_map_custom3Ptr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_tensor>,
          ggml_custom3_op_t,
          int,
          ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ggml_tensor> ggml_map_custom3_inplace(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
    ggml_custom3_op_t fun,
    int n_tasks,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _ggml_map_custom3_inplace(
      ctx,
      a,
      b,
      c,
      fun,
      n_tasks,
      userdata,
    );
  }

  late final _ggml_map_custom3_inplacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_t,
              ffi.Int,
              ffi.Pointer<ffi.Void>)>>('ggml_map_custom3_inplace');
  late final _ggml_map_custom3_inplace =
      _ggml_map_custom3_inplacePtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ggml_custom3_op_t,
              int,
              ffi.Pointer<ffi.Void>)>();

  /// loss function
  ffi.Pointer<ggml_tensor> ggml_cross_entropy_loss(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
  ) {
    return _ggml_cross_entropy_loss(
      ctx,
      a,
      b,
    );
  }

  late final _ggml_cross_entropy_lossPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_cross_entropy_loss');
  late final _ggml_cross_entropy_loss = _ggml_cross_entropy_lossPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>();

  ffi.Pointer<ggml_tensor> ggml_cross_entropy_loss_back(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> a,
    ffi.Pointer<ggml_tensor> b,
    ffi.Pointer<ggml_tensor> c,
  ) {
    return _ggml_cross_entropy_loss_back(
      ctx,
      a,
      b,
      c,
    );
  }

  late final _ggml_cross_entropy_loss_backPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>>('ggml_cross_entropy_loss_back');
  late final _ggml_cross_entropy_loss_back =
      _ggml_cross_entropy_loss_backPtr.asFunction<
          ffi.Pointer<ggml_tensor> Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_tensor>)>();

  /// automatic differentiation
  void ggml_set_param(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_set_param(
      ctx,
      tensor,
    );
  }

  late final _ggml_set_paramPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_set_param');
  late final _ggml_set_param = _ggml_set_paramPtr.asFunction<
      void Function(ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  void ggml_build_forward_expand(
    ffi.Pointer<ggml_cgraph> cgraph,
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_build_forward_expand(
      cgraph,
      tensor,
    );
  }

  late final _ggml_build_forward_expandPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ggml_tensor>)>>('ggml_build_forward_expand');
  late final _ggml_build_forward_expand =
      _ggml_build_forward_expandPtr.asFunction<
          void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_tensor>)>();

  void ggml_build_backward_expand(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_cgraph> gf,
    ffi.Pointer<ggml_cgraph> gb,
    bool keep,
  ) {
    return _ggml_build_backward_expand(
      ctx,
      gf,
      gb,
      keep,
    );
  }

  late final _ggml_build_backward_expandPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ggml_cgraph>,
              ffi.Bool)>>('ggml_build_backward_expand');
  late final _ggml_build_backward_expand =
      _ggml_build_backward_expandPtr.asFunction<
          void Function(ffi.Pointer<ggml_context>, ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ggml_cgraph>, bool)>();

  ggml_cgraph ggml_build_forward(
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_build_forward(
      tensor,
    );
  }

  late final _ggml_build_forwardPtr = _lookup<
          ffi.NativeFunction<ggml_cgraph Function(ffi.Pointer<ggml_tensor>)>>(
      'ggml_build_forward');
  late final _ggml_build_forward = _ggml_build_forwardPtr
      .asFunction<ggml_cgraph Function(ffi.Pointer<ggml_tensor>)>();

  ggml_cgraph ggml_build_backward(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_cgraph> gf,
    bool keep,
  ) {
    return _ggml_build_backward(
      ctx,
      gf,
      keep,
    );
  }

  late final _ggml_build_backwardPtr = _lookup<
      ffi.NativeFunction<
          ggml_cgraph Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_cgraph>, ffi.Bool)>>('ggml_build_backward');
  late final _ggml_build_backward = _ggml_build_backwardPtr.asFunction<
      ggml_cgraph Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_cgraph>, bool)>();

  /// graph allocation in a context
  ffi.Pointer<ggml_cgraph> ggml_new_graph(
    ffi.Pointer<ggml_context> ctx,
  ) {
    return _ggml_new_graph(
      ctx,
    );
  }

  late final _ggml_new_graphPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_cgraph> Function(
              ffi.Pointer<ggml_context>)>>('ggml_new_graph');
  late final _ggml_new_graph = _ggml_new_graphPtr.asFunction<
      ffi.Pointer<ggml_cgraph> Function(ffi.Pointer<ggml_context>)>();

  ffi.Pointer<ggml_cgraph> ggml_build_forward_ctx(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _ggml_build_forward_ctx(
      ctx,
      tensor,
    );
  }

  late final _ggml_build_forward_ctxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_cgraph> Function(ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_build_forward_ctx');
  late final _ggml_build_forward_ctx = _ggml_build_forward_ctxPtr.asFunction<
      ffi.Pointer<ggml_cgraph> Function(
          ffi.Pointer<ggml_context>, ffi.Pointer<ggml_tensor>)>();

  int ggml_graph_overhead() {
    return _ggml_graph_overhead();
  }

  late final _ggml_graph_overheadPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function()>>('ggml_graph_overhead');
  late final _ggml_graph_overhead =
      _ggml_graph_overheadPtr.asFunction<int Function()>();

  /// ggml_graph_plan() has to be called before ggml_graph_compute()
  /// when plan.work_size > 0, caller must allocate memory for plan.work_data
  ggml_cplan ggml_graph_plan(
    ffi.Pointer<ggml_cgraph> cgraph,
    int n_threads,
  ) {
    return _ggml_graph_plan(
      cgraph,
      n_threads,
    );
  }

  late final _ggml_graph_planPtr = _lookup<
      ffi.NativeFunction<
          ggml_cplan Function(
              ffi.Pointer<ggml_cgraph>, ffi.Int)>>('ggml_graph_plan');
  late final _ggml_graph_plan = _ggml_graph_planPtr
      .asFunction<ggml_cplan Function(ffi.Pointer<ggml_cgraph>, int)>();

  int ggml_graph_compute(
    ffi.Pointer<ggml_cgraph> cgraph,
    ffi.Pointer<ggml_cplan> cplan,
  ) {
    return _ggml_graph_compute(
      cgraph,
      cplan,
    );
  }

  late final _ggml_graph_computePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ggml_cplan>)>>('ggml_graph_compute');
  late final _ggml_graph_compute = _ggml_graph_computePtr.asFunction<
      int Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_cplan>)>();

  void ggml_graph_reset(
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_graph_reset(
      cgraph,
    );
  }

  late final _ggml_graph_resetPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_cgraph>)>>(
          'ggml_graph_reset');
  late final _ggml_graph_reset = _ggml_graph_resetPtr
      .asFunction<void Function(ffi.Pointer<ggml_cgraph>)>();

  /// same as ggml_graph_compute() but the work data is allocated as a part of the context
  /// note: the drawback of this API is that you must have ensured that the context has enough memory for the work data
  void ggml_graph_compute_with_ctx(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_cgraph> cgraph,
    int n_threads,
  ) {
    return _ggml_graph_compute_with_ctx(
      ctx,
      cgraph,
      n_threads,
    );
  }

  late final _ggml_graph_compute_with_ctxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_context>, ffi.Pointer<ggml_cgraph>,
              ffi.Int)>>('ggml_graph_compute_with_ctx');
  late final _ggml_graph_compute_with_ctx =
      _ggml_graph_compute_with_ctxPtr.asFunction<
          void Function(
              ffi.Pointer<ggml_context>, ffi.Pointer<ggml_cgraph>, int)>();

  ffi.Pointer<ggml_tensor> ggml_graph_get_tensor(
    ffi.Pointer<ggml_cgraph> cgraph,
    ffi.Pointer<ffi.Char> name,
  ) {
    return _ggml_graph_get_tensor(
      cgraph,
      name,
    );
  }

  late final _ggml_graph_get_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ggml_tensor> Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ffi.Char>)>>('ggml_graph_get_tensor');
  late final _ggml_graph_get_tensor = _ggml_graph_get_tensorPtr.asFunction<
      ffi.Pointer<ggml_tensor> Function(
          ffi.Pointer<ggml_cgraph>, ffi.Pointer<ffi.Char>)>();

  void ggml_graph_export(
    ffi.Pointer<ggml_cgraph> cgraph,
    ffi.Pointer<ffi.Char> fname,
  ) {
    return _ggml_graph_export(
      cgraph,
      fname,
    );
  }

  late final _ggml_graph_exportPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ffi.Char>)>>('ggml_graph_export');
  late final _ggml_graph_export = _ggml_graph_exportPtr.asFunction<
      void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ffi.Char>)>();

  ggml_cgraph ggml_graph_import(
    ffi.Pointer<ffi.Char> fname,
    ffi.Pointer<ffi.Pointer<ggml_context>> ctx_data,
    ffi.Pointer<ffi.Pointer<ggml_context>> ctx_eval,
  ) {
    return _ggml_graph_import(
      fname,
      ctx_data,
      ctx_eval,
    );
  }

  late final _ggml_graph_importPtr = _lookup<
      ffi.NativeFunction<
          ggml_cgraph Function(
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ggml_context>>,
              ffi.Pointer<ffi.Pointer<ggml_context>>)>>('ggml_graph_import');
  late final _ggml_graph_import = _ggml_graph_importPtr.asFunction<
      ggml_cgraph Function(
          ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Pointer<ggml_context>>,
          ffi.Pointer<ffi.Pointer<ggml_context>>)>();

  /// print info and performance information for the graph
  void ggml_graph_print(
    ffi.Pointer<ggml_cgraph> cgraph,
  ) {
    return _ggml_graph_print(
      cgraph,
    );
  }

  late final _ggml_graph_printPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ggml_cgraph>)>>(
          'ggml_graph_print');
  late final _ggml_graph_print = _ggml_graph_printPtr
      .asFunction<void Function(ffi.Pointer<ggml_cgraph>)>();

  /// dump the graph into a file using the dot format
  void ggml_graph_dump_dot(
    ffi.Pointer<ggml_cgraph> gb,
    ffi.Pointer<ggml_cgraph> gf,
    ffi.Pointer<ffi.Char> filename,
  ) {
    return _ggml_graph_dump_dot(
      gb,
      gf,
      filename,
    );
  }

  late final _ggml_graph_dump_dotPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ffi.Char>)>>('ggml_graph_dump_dot');
  late final _ggml_graph_dump_dot = _ggml_graph_dump_dotPtr.asFunction<
      void Function(ffi.Pointer<ggml_cgraph>, ffi.Pointer<ggml_cgraph>,
          ffi.Pointer<ffi.Char>)>();

  ggml_opt_params ggml_opt_default_params(
    int type,
  ) {
    return _ggml_opt_default_params(
      type,
    );
  }

  late final _ggml_opt_default_paramsPtr =
      _lookup<ffi.NativeFunction<ggml_opt_params Function(ffi.Int32)>>(
          'ggml_opt_default_params');
  late final _ggml_opt_default_params =
      _ggml_opt_default_paramsPtr.asFunction<ggml_opt_params Function(int)>();

  /// optimize the function defined by the tensor f
  int ggml_opt(
    ffi.Pointer<ggml_context> ctx,
    ggml_opt_params params,
    ffi.Pointer<ggml_tensor> f,
  ) {
    return _ggml_opt(
      ctx,
      params,
      f,
    );
  }

  late final _ggml_optPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ggml_context>, ggml_opt_params,
              ffi.Pointer<ggml_tensor>)>>('ggml_opt');
  late final _ggml_opt = _ggml_optPtr.asFunction<
      int Function(ffi.Pointer<ggml_context>, ggml_opt_params,
          ffi.Pointer<ggml_tensor>)>();

  /// initialize optimizer context
  void ggml_opt_init(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_opt_context> opt,
    ggml_opt_params params,
    int nx,
  ) {
    return _ggml_opt_init(
      ctx,
      opt,
      params,
      nx,
    );
  }

  late final _ggml_opt_initPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_opt_context>,
              ggml_opt_params,
              ffi.Int64)>>('ggml_opt_init');
  late final _ggml_opt_init = _ggml_opt_initPtr.asFunction<
      void Function(ffi.Pointer<ggml_context>, ffi.Pointer<ggml_opt_context>,
          ggml_opt_params, int)>();

  /// continue optimizing the function defined by the tensor f
  int ggml_opt_resume(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_opt_context> opt,
    ffi.Pointer<ggml_tensor> f,
  ) {
    return _ggml_opt_resume(
      ctx,
      opt,
      f,
    );
  }

  late final _ggml_opt_resumePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_opt_context>,
              ffi.Pointer<ggml_tensor>)>>('ggml_opt_resume');
  late final _ggml_opt_resume = _ggml_opt_resumePtr.asFunction<
      int Function(ffi.Pointer<ggml_context>, ffi.Pointer<ggml_opt_context>,
          ffi.Pointer<ggml_tensor>)>();

  /// continue optimizing the function defined by the tensor f
  int ggml_opt_resume_g(
    ffi.Pointer<ggml_context> ctx,
    ffi.Pointer<ggml_opt_context> opt,
    ffi.Pointer<ggml_tensor> f,
    ffi.Pointer<ggml_cgraph> gf,
    ffi.Pointer<ggml_cgraph> gb,
    ggml_opt_callback callback,
    ffi.Pointer<ffi.Void> callback_data,
  ) {
    return _ggml_opt_resume_g(
      ctx,
      opt,
      f,
      gf,
      gb,
      callback,
      callback_data,
    );
  }

  late final _ggml_opt_resume_gPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ggml_context>,
              ffi.Pointer<ggml_opt_context>,
              ffi.Pointer<ggml_tensor>,
              ffi.Pointer<ggml_cgraph>,
              ffi.Pointer<ggml_cgraph>,
              ggml_opt_callback,
              ffi.Pointer<ffi.Void>)>>('ggml_opt_resume_g');
  late final _ggml_opt_resume_g = _ggml_opt_resume_gPtr.asFunction<
      int Function(
          ffi.Pointer<ggml_context>,
          ffi.Pointer<ggml_opt_context>,
          ffi.Pointer<ggml_tensor>,
          ffi.Pointer<ggml_cgraph>,
          ffi.Pointer<ggml_cgraph>,
          ggml_opt_callback,
          ffi.Pointer<ffi.Void>)>();

  /// quantization
  int ggml_quantize_q4_0(
    ffi.Pointer<ffi.Float> src,
    ffi.Pointer<ffi.Void> dst,
    int n,
    int k,
    ffi.Pointer<ffi.Int64> hist,
  ) {
    return _ggml_quantize_q4_0(
      src,
      dst,
      n,
      k,
      hist,
    );
  }

  late final _ggml_quantize_q4_0Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>,
              ffi.Int, ffi.Int, ffi.Pointer<ffi.Int64>)>>('ggml_quantize_q4_0');
  late final _ggml_quantize_q4_0 = _ggml_quantize_q4_0Ptr.asFunction<
      int Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>, int, int,
          ffi.Pointer<ffi.Int64>)>();

  int ggml_quantize_q4_1(
    ffi.Pointer<ffi.Float> src,
    ffi.Pointer<ffi.Void> dst,
    int n,
    int k,
    ffi.Pointer<ffi.Int64> hist,
  ) {
    return _ggml_quantize_q4_1(
      src,
      dst,
      n,
      k,
      hist,
    );
  }

  late final _ggml_quantize_q4_1Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>,
              ffi.Int, ffi.Int, ffi.Pointer<ffi.Int64>)>>('ggml_quantize_q4_1');
  late final _ggml_quantize_q4_1 = _ggml_quantize_q4_1Ptr.asFunction<
      int Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>, int, int,
          ffi.Pointer<ffi.Int64>)>();

  int ggml_quantize_q5_0(
    ffi.Pointer<ffi.Float> src,
    ffi.Pointer<ffi.Void> dst,
    int n,
    int k,
    ffi.Pointer<ffi.Int64> hist,
  ) {
    return _ggml_quantize_q5_0(
      src,
      dst,
      n,
      k,
      hist,
    );
  }

  late final _ggml_quantize_q5_0Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>,
              ffi.Int, ffi.Int, ffi.Pointer<ffi.Int64>)>>('ggml_quantize_q5_0');
  late final _ggml_quantize_q5_0 = _ggml_quantize_q5_0Ptr.asFunction<
      int Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>, int, int,
          ffi.Pointer<ffi.Int64>)>();

  int ggml_quantize_q5_1(
    ffi.Pointer<ffi.Float> src,
    ffi.Pointer<ffi.Void> dst,
    int n,
    int k,
    ffi.Pointer<ffi.Int64> hist,
  ) {
    return _ggml_quantize_q5_1(
      src,
      dst,
      n,
      k,
      hist,
    );
  }

  late final _ggml_quantize_q5_1Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>,
              ffi.Int, ffi.Int, ffi.Pointer<ffi.Int64>)>>('ggml_quantize_q5_1');
  late final _ggml_quantize_q5_1 = _ggml_quantize_q5_1Ptr.asFunction<
      int Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>, int, int,
          ffi.Pointer<ffi.Int64>)>();

  int ggml_quantize_q8_0(
    ffi.Pointer<ffi.Float> src,
    ffi.Pointer<ffi.Void> dst,
    int n,
    int k,
    ffi.Pointer<ffi.Int64> hist,
  ) {
    return _ggml_quantize_q8_0(
      src,
      dst,
      n,
      k,
      hist,
    );
  }

  late final _ggml_quantize_q8_0Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>,
              ffi.Int, ffi.Int, ffi.Pointer<ffi.Int64>)>>('ggml_quantize_q8_0');
  late final _ggml_quantize_q8_0 = _ggml_quantize_q8_0Ptr.asFunction<
      int Function(ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>, int, int,
          ffi.Pointer<ffi.Int64>)>();

  int ggml_quantize_chunk(
    int type,
    ffi.Pointer<ffi.Float> src,
    ffi.Pointer<ffi.Void> dst,
    int start,
    int n,
    ffi.Pointer<ffi.Int64> hist,
  ) {
    return _ggml_quantize_chunk(
      type,
      src,
      dst,
      start,
      n,
      hist,
    );
  }

  late final _ggml_quantize_chunkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Int32,
              ffi.Pointer<ffi.Float>,
              ffi.Pointer<ffi.Void>,
              ffi.Int,
              ffi.Int,
              ffi.Pointer<ffi.Int64>)>>('ggml_quantize_chunk');
  late final _ggml_quantize_chunk = _ggml_quantize_chunkPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Void>, int, int,
          ffi.Pointer<ffi.Int64>)>();

  ffi.Pointer<gguf_context> gguf_init_empty() {
    return _gguf_init_empty();
  }

  late final _gguf_init_emptyPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<gguf_context> Function()>>(
          'gguf_init_empty');
  late final _gguf_init_empty =
      _gguf_init_emptyPtr.asFunction<ffi.Pointer<gguf_context> Function()>();

  ffi.Pointer<gguf_context> gguf_init_from_file(
    ffi.Pointer<ffi.Char> fname,
    gguf_init_params params,
  ) {
    return _gguf_init_from_file(
      fname,
      params,
    );
  }

  late final _gguf_init_from_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<gguf_context> Function(
              ffi.Pointer<ffi.Char>, gguf_init_params)>>('gguf_init_from_file');
  late final _gguf_init_from_file = _gguf_init_from_filePtr.asFunction<
      ffi.Pointer<gguf_context> Function(
          ffi.Pointer<ffi.Char>, gguf_init_params)>();

  /// GGML_API struct gguf_context * gguf_init_from_buffer(..);
  void gguf_free(
    ffi.Pointer<gguf_context> ctx,
  ) {
    return _gguf_free(
      ctx,
    );
  }

  late final _gguf_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<gguf_context>)>>(
          'gguf_free');
  late final _gguf_free =
      _gguf_freePtr.asFunction<void Function(ffi.Pointer<gguf_context>)>();

  ffi.Pointer<ffi.Char> gguf_type_name(
    int type,
  ) {
    return _gguf_type_name(
      type,
    );
  }

  late final _gguf_type_namePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function(ffi.Int32)>>(
          'gguf_type_name');
  late final _gguf_type_name =
      _gguf_type_namePtr.asFunction<ffi.Pointer<ffi.Char> Function(int)>();

  int gguf_get_version(
    ffi.Pointer<gguf_context> ctx,
  ) {
    return _gguf_get_version(
      ctx,
    );
  }

  late final _gguf_get_versionPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<gguf_context>)>>(
          'gguf_get_version');
  late final _gguf_get_version = _gguf_get_versionPtr
      .asFunction<int Function(ffi.Pointer<gguf_context>)>();

  int gguf_get_alignment(
    ffi.Pointer<gguf_context> ctx,
  ) {
    return _gguf_get_alignment(
      ctx,
    );
  }

  late final _gguf_get_alignmentPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<gguf_context>)>>(
          'gguf_get_alignment');
  late final _gguf_get_alignment = _gguf_get_alignmentPtr
      .asFunction<int Function(ffi.Pointer<gguf_context>)>();

  int gguf_get_data_offset(
    ffi.Pointer<gguf_context> ctx,
  ) {
    return _gguf_get_data_offset(
      ctx,
    );
  }

  late final _gguf_get_data_offsetPtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<gguf_context>)>>(
          'gguf_get_data_offset');
  late final _gguf_get_data_offset = _gguf_get_data_offsetPtr
      .asFunction<int Function(ffi.Pointer<gguf_context>)>();

  ffi.Pointer<ffi.Void> gguf_get_data(
    ffi.Pointer<gguf_context> ctx,
  ) {
    return _gguf_get_data(
      ctx,
    );
  }

  late final _gguf_get_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<gguf_context>)>>('gguf_get_data');
  late final _gguf_get_data = _gguf_get_dataPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<gguf_context>)>();

  int gguf_get_n_kv(
    ffi.Pointer<gguf_context> ctx,
  ) {
    return _gguf_get_n_kv(
      ctx,
    );
  }

  late final _gguf_get_n_kvPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<gguf_context>)>>(
          'gguf_get_n_kv');
  late final _gguf_get_n_kv =
      _gguf_get_n_kvPtr.asFunction<int Function(ffi.Pointer<gguf_context>)>();

  int gguf_find_key(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
  ) {
    return _gguf_find_key(
      ctx,
      key,
    );
  }

  late final _gguf_find_keyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<gguf_context>,
              ffi.Pointer<ffi.Char>)>>('gguf_find_key');
  late final _gguf_find_key = _gguf_find_keyPtr.asFunction<
      int Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ffi.Char> gguf_get_key(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_key(
      ctx,
      i,
    );
  }

  late final _gguf_get_keyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_key');
  late final _gguf_get_key = _gguf_get_keyPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<gguf_context>, int)>();

  int gguf_get_kv_type(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_kv_type(
      ctx,
      i,
    );
  }

  late final _gguf_get_kv_typePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_kv_type');
  late final _gguf_get_kv_type = _gguf_get_kv_typePtr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  int gguf_get_arr_type(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_arr_type(
      ctx,
      i,
    );
  }

  late final _gguf_get_arr_typePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_arr_type');
  late final _gguf_get_arr_type = _gguf_get_arr_typePtr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  /// results are undefined if the wrong type is used for the key
  int gguf_get_val_u8(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_u8(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_u8');
  late final _gguf_get_val_u8 = _gguf_get_val_u8Ptr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  int gguf_get_val_i8(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_i8(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_i8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int8 Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_i8');
  late final _gguf_get_val_i8 = _gguf_get_val_i8Ptr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  int gguf_get_val_u16(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_u16(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_u16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint16 Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_u16');
  late final _gguf_get_val_u16 = _gguf_get_val_u16Ptr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  int gguf_get_val_i16(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_i16(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_i16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_i16');
  late final _gguf_get_val_i16 = _gguf_get_val_i16Ptr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  int gguf_get_val_u32(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_u32(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_u32');
  late final _gguf_get_val_u32 = _gguf_get_val_u32Ptr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  int gguf_get_val_i32(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_i32(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_i32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_i32');
  late final _gguf_get_val_i32 = _gguf_get_val_i32Ptr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  double gguf_get_val_f32(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_f32(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_f32');
  late final _gguf_get_val_f32 = _gguf_get_val_f32Ptr
      .asFunction<double Function(ffi.Pointer<gguf_context>, int)>();

  int gguf_get_val_u64(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_u64(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_u64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint64 Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_u64');
  late final _gguf_get_val_u64 = _gguf_get_val_u64Ptr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  int gguf_get_val_i64(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_i64(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_i64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_i64');
  late final _gguf_get_val_i64 = _gguf_get_val_i64Ptr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  double gguf_get_val_f64(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_f64(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_f64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Double Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_f64');
  late final _gguf_get_val_f64 = _gguf_get_val_f64Ptr
      .asFunction<double Function(ffi.Pointer<gguf_context>, int)>();

  bool gguf_get_val_bool(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_bool(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_boolPtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_bool');
  late final _gguf_get_val_bool = _gguf_get_val_boolPtr
      .asFunction<bool Function(ffi.Pointer<gguf_context>, int)>();

  ffi.Pointer<ffi.Char> gguf_get_val_str(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_val_str(
      ctx,
      i,
    );
  }

  late final _gguf_get_val_strPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_val_str');
  late final _gguf_get_val_str = _gguf_get_val_strPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<gguf_context>, int)>();

  int gguf_get_arr_n(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_arr_n(
      ctx,
      i,
    );
  }

  late final _gguf_get_arr_nPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_arr_n');
  late final _gguf_get_arr_n = _gguf_get_arr_nPtr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  ffi.Pointer<ffi.Void> gguf_get_arr_data(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_arr_data(
      ctx,
      i,
    );
  }

  late final _gguf_get_arr_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_arr_data');
  late final _gguf_get_arr_data = _gguf_get_arr_dataPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<gguf_context>, int)>();

  ffi.Pointer<ffi.Char> gguf_get_arr_str(
    ffi.Pointer<gguf_context> ctx,
    int key_id,
    int i,
  ) {
    return _gguf_get_arr_str(
      ctx,
      key_id,
      i,
    );
  }

  late final _gguf_get_arr_strPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<gguf_context>, ffi.Int,
              ffi.Int)>>('gguf_get_arr_str');
  late final _gguf_get_arr_str = _gguf_get_arr_strPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<gguf_context>, int, int)>();

  int gguf_get_n_tensors(
    ffi.Pointer<gguf_context> ctx,
  ) {
    return _gguf_get_n_tensors(
      ctx,
    );
  }

  late final _gguf_get_n_tensorsPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<gguf_context>)>>(
          'gguf_get_n_tensors');
  late final _gguf_get_n_tensors = _gguf_get_n_tensorsPtr
      .asFunction<int Function(ffi.Pointer<gguf_context>)>();

  int gguf_find_tensor(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> name,
  ) {
    return _gguf_find_tensor(
      ctx,
      name,
    );
  }

  late final _gguf_find_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<gguf_context>,
              ffi.Pointer<ffi.Char>)>>('gguf_find_tensor');
  late final _gguf_find_tensor = _gguf_find_tensorPtr.asFunction<
      int Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>)>();

  int gguf_get_tensor_offset(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_tensor_offset(
      ctx,
      i,
    );
  }

  late final _gguf_get_tensor_offsetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_tensor_offset');
  late final _gguf_get_tensor_offset = _gguf_get_tensor_offsetPtr
      .asFunction<int Function(ffi.Pointer<gguf_context>, int)>();

  ffi.Pointer<ffi.Char> gguf_get_tensor_name(
    ffi.Pointer<gguf_context> ctx,
    int i,
  ) {
    return _gguf_get_tensor_name(
      ctx,
      i,
    );
  }

  late final _gguf_get_tensor_namePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<gguf_context>, ffi.Int)>>('gguf_get_tensor_name');
  late final _gguf_get_tensor_name = _gguf_get_tensor_namePtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<gguf_context>, int)>();

  /// overrides existing values or adds a new one
  void gguf_set_val_u8(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    int val,
  ) {
    return _gguf_set_val_u8(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Uint8)>>('gguf_set_val_u8');
  late final _gguf_set_val_u8 = _gguf_set_val_u8Ptr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, int)>();

  void gguf_set_val_i8(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    int val,
  ) {
    return _gguf_set_val_i8(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_i8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Int8)>>('gguf_set_val_i8');
  late final _gguf_set_val_i8 = _gguf_set_val_i8Ptr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, int)>();

  void gguf_set_val_u16(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    int val,
  ) {
    return _gguf_set_val_u16(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_u16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Uint16)>>('gguf_set_val_u16');
  late final _gguf_set_val_u16 = _gguf_set_val_u16Ptr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, int)>();

  void gguf_set_val_i16(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    int val,
  ) {
    return _gguf_set_val_i16(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_i16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Int16)>>('gguf_set_val_i16');
  late final _gguf_set_val_i16 = _gguf_set_val_i16Ptr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, int)>();

  void gguf_set_val_u32(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    int val,
  ) {
    return _gguf_set_val_u32(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Uint32)>>('gguf_set_val_u32');
  late final _gguf_set_val_u32 = _gguf_set_val_u32Ptr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, int)>();

  void gguf_set_val_i32(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    int val,
  ) {
    return _gguf_set_val_i32(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_i32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Int32)>>('gguf_set_val_i32');
  late final _gguf_set_val_i32 = _gguf_set_val_i32Ptr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, int)>();

  void gguf_set_val_f32(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    double val,
  ) {
    return _gguf_set_val_f32(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_f32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Float)>>('gguf_set_val_f32');
  late final _gguf_set_val_f32 = _gguf_set_val_f32Ptr.asFunction<
      void Function(
          ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, double)>();

  void gguf_set_val_u64(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    int val,
  ) {
    return _gguf_set_val_u64(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_u64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Uint64)>>('gguf_set_val_u64');
  late final _gguf_set_val_u64 = _gguf_set_val_u64Ptr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, int)>();

  void gguf_set_val_i64(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    int val,
  ) {
    return _gguf_set_val_i64(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_i64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Int64)>>('gguf_set_val_i64');
  late final _gguf_set_val_i64 = _gguf_set_val_i64Ptr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, int)>();

  void gguf_set_val_f64(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    double val,
  ) {
    return _gguf_set_val_f64(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_f64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Double)>>('gguf_set_val_f64');
  late final _gguf_set_val_f64 = _gguf_set_val_f64Ptr.asFunction<
      void Function(
          ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, double)>();

  void gguf_set_val_bool(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    bool val,
  ) {
    return _gguf_set_val_bool(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_boolPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Bool)>>('gguf_set_val_bool');
  late final _gguf_set_val_bool = _gguf_set_val_boolPtr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, bool)>();

  void gguf_set_val_str(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    ffi.Pointer<ffi.Char> val,
  ) {
    return _gguf_set_val_str(
      ctx,
      key,
      val,
    );
  }

  late final _gguf_set_val_strPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>)>>('gguf_set_val_str');
  late final _gguf_set_val_str = _gguf_set_val_strPtr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Char>)>();

  void gguf_set_arr_data(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    int type,
    ffi.Pointer<ffi.Void> data,
    int n,
  ) {
    return _gguf_set_arr_data(
      ctx,
      key,
      type,
      data,
      n,
    );
  }

  late final _gguf_set_arr_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Int32, ffi.Pointer<ffi.Void>, ffi.Int)>>('gguf_set_arr_data');
  late final _gguf_set_arr_data = _gguf_set_arr_dataPtr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, int,
          ffi.Pointer<ffi.Void>, int)>();

  void gguf_set_arr_str(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> key,
    ffi.Pointer<ffi.Pointer<ffi.Char>> data,
    int n,
  ) {
    return _gguf_set_arr_str(
      ctx,
      key,
      data,
      n,
    );
  }

  late final _gguf_set_arr_strPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<gguf_context>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Int)>>('gguf_set_arr_str');
  late final _gguf_set_arr_str = _gguf_set_arr_strPtr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Pointer<ffi.Char>>, int)>();

  /// set or add KV pairs from another context
  void gguf_set_kv(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<gguf_context> src,
  ) {
    return _gguf_set_kv(
      ctx,
      src,
    );
  }

  late final _gguf_set_kvPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>,
              ffi.Pointer<gguf_context>)>>('gguf_set_kv');
  late final _gguf_set_kv = _gguf_set_kvPtr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<gguf_context>)>();

  /// manage tensor info
  void gguf_add_tensor(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ggml_tensor> tensor,
  ) {
    return _gguf_add_tensor(
      ctx,
      tensor,
    );
  }

  late final _gguf_add_tensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>,
              ffi.Pointer<ggml_tensor>)>>('gguf_add_tensor');
  late final _gguf_add_tensor = _gguf_add_tensorPtr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ggml_tensor>)>();

  void gguf_set_tensor_type(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> name,
    int type,
  ) {
    return _gguf_set_tensor_type(
      ctx,
      name,
      type,
    );
  }

  late final _gguf_set_tensor_typePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Int32)>>('gguf_set_tensor_type');
  late final _gguf_set_tensor_type = _gguf_set_tensor_typePtr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, int)>();

  void gguf_set_tensor_data(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> name,
    ffi.Pointer<ffi.Void> data,
    int size,
  ) {
    return _gguf_set_tensor_data(
      ctx,
      name,
      data,
      size,
    );
  }

  late final _gguf_set_tensor_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Void>, ffi.Size)>>('gguf_set_tensor_data');
  late final _gguf_set_tensor_data = _gguf_set_tensor_dataPtr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<ffi.Void>, int)>();

  /// write the entire context to a binary file
  void gguf_write_to_file(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Char> fname,
    bool only_meta,
  ) {
    return _gguf_write_to_file(
      ctx,
      fname,
      only_meta,
    );
  }

  late final _gguf_write_to_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>,
              ffi.Bool)>>('gguf_write_to_file');
  late final _gguf_write_to_file = _gguf_write_to_filePtr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Char>, bool)>();

  /// get the size in bytes of the meta data (header, kv pairs, tensor info) including padding
  int gguf_get_meta_size(
    ffi.Pointer<gguf_context> ctx,
  ) {
    return _gguf_get_meta_size(
      ctx,
    );
  }

  late final _gguf_get_meta_sizePtr =
      _lookup<ffi.NativeFunction<ffi.Size Function(ffi.Pointer<gguf_context>)>>(
          'gguf_get_meta_size');
  late final _gguf_get_meta_size = _gguf_get_meta_sizePtr
      .asFunction<int Function(ffi.Pointer<gguf_context>)>();

  void gguf_get_meta_data(
    ffi.Pointer<gguf_context> ctx,
    ffi.Pointer<ffi.Void> data,
  ) {
    return _gguf_get_meta_data(
      ctx,
      data,
    );
  }

  late final _gguf_get_meta_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<gguf_context>,
              ffi.Pointer<ffi.Void>)>>('gguf_get_meta_data');
  late final _gguf_get_meta_data = _gguf_get_meta_dataPtr.asFunction<
      void Function(ffi.Pointer<gguf_context>, ffi.Pointer<ffi.Void>)>();

  /// system info
  int ggml_cpu_has_avx() {
    return _ggml_cpu_has_avx();
  }

  late final _ggml_cpu_has_avxPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_avx');
  late final _ggml_cpu_has_avx =
      _ggml_cpu_has_avxPtr.asFunction<int Function()>();

  int ggml_cpu_has_avx2() {
    return _ggml_cpu_has_avx2();
  }

  late final _ggml_cpu_has_avx2Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_avx2');
  late final _ggml_cpu_has_avx2 =
      _ggml_cpu_has_avx2Ptr.asFunction<int Function()>();

  int ggml_cpu_has_avx512() {
    return _ggml_cpu_has_avx512();
  }

  late final _ggml_cpu_has_avx512Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_avx512');
  late final _ggml_cpu_has_avx512 =
      _ggml_cpu_has_avx512Ptr.asFunction<int Function()>();

  int ggml_cpu_has_avx512_vbmi() {
    return _ggml_cpu_has_avx512_vbmi();
  }

  late final _ggml_cpu_has_avx512_vbmiPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>(
          'ggml_cpu_has_avx512_vbmi');
  late final _ggml_cpu_has_avx512_vbmi =
      _ggml_cpu_has_avx512_vbmiPtr.asFunction<int Function()>();

  int ggml_cpu_has_avx512_vnni() {
    return _ggml_cpu_has_avx512_vnni();
  }

  late final _ggml_cpu_has_avx512_vnniPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>(
          'ggml_cpu_has_avx512_vnni');
  late final _ggml_cpu_has_avx512_vnni =
      _ggml_cpu_has_avx512_vnniPtr.asFunction<int Function()>();

  int ggml_cpu_has_fma() {
    return _ggml_cpu_has_fma();
  }

  late final _ggml_cpu_has_fmaPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_fma');
  late final _ggml_cpu_has_fma =
      _ggml_cpu_has_fmaPtr.asFunction<int Function()>();

  int ggml_cpu_has_neon() {
    return _ggml_cpu_has_neon();
  }

  late final _ggml_cpu_has_neonPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_neon');
  late final _ggml_cpu_has_neon =
      _ggml_cpu_has_neonPtr.asFunction<int Function()>();

  int ggml_cpu_has_arm_fma() {
    return _ggml_cpu_has_arm_fma();
  }

  late final _ggml_cpu_has_arm_fmaPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_arm_fma');
  late final _ggml_cpu_has_arm_fma =
      _ggml_cpu_has_arm_fmaPtr.asFunction<int Function()>();

  int ggml_cpu_has_metal() {
    return _ggml_cpu_has_metal();
  }

  late final _ggml_cpu_has_metalPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_metal');
  late final _ggml_cpu_has_metal =
      _ggml_cpu_has_metalPtr.asFunction<int Function()>();

  int ggml_cpu_has_f16c() {
    return _ggml_cpu_has_f16c();
  }

  late final _ggml_cpu_has_f16cPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_f16c');
  late final _ggml_cpu_has_f16c =
      _ggml_cpu_has_f16cPtr.asFunction<int Function()>();

  int ggml_cpu_has_fp16_va() {
    return _ggml_cpu_has_fp16_va();
  }

  late final _ggml_cpu_has_fp16_vaPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_fp16_va');
  late final _ggml_cpu_has_fp16_va =
      _ggml_cpu_has_fp16_vaPtr.asFunction<int Function()>();

  int ggml_cpu_has_wasm_simd() {
    return _ggml_cpu_has_wasm_simd();
  }

  late final _ggml_cpu_has_wasm_simdPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_wasm_simd');
  late final _ggml_cpu_has_wasm_simd =
      _ggml_cpu_has_wasm_simdPtr.asFunction<int Function()>();

  int ggml_cpu_has_blas() {
    return _ggml_cpu_has_blas();
  }

  late final _ggml_cpu_has_blasPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_blas');
  late final _ggml_cpu_has_blas =
      _ggml_cpu_has_blasPtr.asFunction<int Function()>();

  int ggml_cpu_has_cublas() {
    return _ggml_cpu_has_cublas();
  }

  late final _ggml_cpu_has_cublasPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_cublas');
  late final _ggml_cpu_has_cublas =
      _ggml_cpu_has_cublasPtr.asFunction<int Function()>();

  int ggml_cpu_has_clblast() {
    return _ggml_cpu_has_clblast();
  }

  late final _ggml_cpu_has_clblastPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_clblast');
  late final _ggml_cpu_has_clblast =
      _ggml_cpu_has_clblastPtr.asFunction<int Function()>();

  int ggml_cpu_has_gpublas() {
    return _ggml_cpu_has_gpublas();
  }

  late final _ggml_cpu_has_gpublasPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_gpublas');
  late final _ggml_cpu_has_gpublas =
      _ggml_cpu_has_gpublasPtr.asFunction<int Function()>();

  int ggml_cpu_has_sse3() {
    return _ggml_cpu_has_sse3();
  }

  late final _ggml_cpu_has_sse3Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_sse3');
  late final _ggml_cpu_has_sse3 =
      _ggml_cpu_has_sse3Ptr.asFunction<int Function()>();

  int ggml_cpu_has_ssse3() {
    return _ggml_cpu_has_ssse3();
  }

  late final _ggml_cpu_has_ssse3Ptr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_ssse3');
  late final _ggml_cpu_has_ssse3 =
      _ggml_cpu_has_ssse3Ptr.asFunction<int Function()>();

  int ggml_cpu_has_vsx() {
    return _ggml_cpu_has_vsx();
  }

  late final _ggml_cpu_has_vsxPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('ggml_cpu_has_vsx');
  late final _ggml_cpu_has_vsx =
      _ggml_cpu_has_vsxPtr.asFunction<int Function()>();

  ggml_type_traits_t ggml_internal_get_type_traits(
    int type,
  ) {
    return _ggml_internal_get_type_traits(
      type,
    );
  }

  late final _ggml_internal_get_type_traitsPtr =
      _lookup<ffi.NativeFunction<ggml_type_traits_t Function(ffi.Int32)>>(
          'ggml_internal_get_type_traits');
  late final _ggml_internal_get_type_traits = _ggml_internal_get_type_traitsPtr
      .asFunction<ggml_type_traits_t Function(int)>();

  int renameat(
    int arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
    ffi.Pointer<ffi.Char> arg3,
  ) {
    return _renameat(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _renameatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Pointer<ffi.Char>, ffi.Int,
              ffi.Pointer<ffi.Char>)>>('renameat');
  late final _renameat = _renameatPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Char>, int, ffi.Pointer<ffi.Char>)>();

  int renamex_np(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
  ) {
    return _renamex_np(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _renamex_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              ffi.UnsignedInt)>>('renamex_np');
  late final _renamex_np = _renamex_npPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, int)>();

  int renameatx_np(
    int arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
    ffi.Pointer<ffi.Char> arg3,
    int arg4,
  ) {
    return _renameatx_np(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final _renameatx_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Int, ffi.Pointer<ffi.Char>, ffi.Int,
              ffi.Pointer<ffi.Char>, ffi.UnsignedInt)>>('renameatx_np');
  late final _renameatx_np = _renameatx_npPtr.asFunction<
      int Function(
          int, ffi.Pointer<ffi.Char>, int, ffi.Pointer<ffi.Char>, int)>();

  late final ffi.Pointer<ffi.Pointer<FILE>> ___stdinp =
      _lookup<ffi.Pointer<FILE>>('__stdinp');

  ffi.Pointer<FILE> get __stdinp => ___stdinp.value;

  set __stdinp(ffi.Pointer<FILE> value) => ___stdinp.value = value;

  late final ffi.Pointer<ffi.Pointer<FILE>> ___stdoutp =
      _lookup<ffi.Pointer<FILE>>('__stdoutp');

  ffi.Pointer<FILE> get __stdoutp => ___stdoutp.value;

  set __stdoutp(ffi.Pointer<FILE> value) => ___stdoutp.value = value;

  late final ffi.Pointer<ffi.Pointer<FILE>> ___stderrp =
      _lookup<ffi.Pointer<FILE>>('__stderrp');

  ffi.Pointer<FILE> get __stderrp => ___stderrp.value;

  set __stderrp(ffi.Pointer<FILE> value) => ___stderrp.value = value;

  /// ANSI-C
  void clearerr(
    ffi.Pointer<FILE> arg0,
  ) {
    return _clearerr(
      arg0,
    );
  }

  late final _clearerrPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<FILE>)>>(
          'clearerr');
  late final _clearerr =
      _clearerrPtr.asFunction<void Function(ffi.Pointer<FILE>)>();

  int fclose(
    ffi.Pointer<FILE> arg0,
  ) {
    return _fclose(
      arg0,
    );
  }

  late final _fclosePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'fclose');
  late final _fclose = _fclosePtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int feof(
    ffi.Pointer<FILE> arg0,
  ) {
    return _feof(
      arg0,
    );
  }

  late final _feofPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>('feof');
  late final _feof = _feofPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int ferror(
    ffi.Pointer<FILE> arg0,
  ) {
    return _ferror(
      arg0,
    );
  }

  late final _ferrorPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'ferror');
  late final _ferror = _ferrorPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int fflush(
    ffi.Pointer<FILE> arg0,
  ) {
    return _fflush(
      arg0,
    );
  }

  late final _fflushPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'fflush');
  late final _fflush = _fflushPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int fgetc(
    ffi.Pointer<FILE> arg0,
  ) {
    return _fgetc(
      arg0,
    );
  }

  late final _fgetcPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>('fgetc');
  late final _fgetc = _fgetcPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int fgetpos(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<fpos_t> arg1,
  ) {
    return _fgetpos(
      arg0,
      arg1,
    );
  }

  late final _fgetposPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<FILE>, ffi.Pointer<fpos_t>)>>('fgetpos');
  late final _fgetpos = _fgetposPtr
      .asFunction<int Function(ffi.Pointer<FILE>, ffi.Pointer<fpos_t>)>();

  ffi.Pointer<ffi.Char> fgets(
    ffi.Pointer<ffi.Char> arg0,
    int arg1,
    ffi.Pointer<FILE> arg2,
  ) {
    return _fgets(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _fgetsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ffi.Char>, ffi.Int, ffi.Pointer<FILE>)>>('fgets');
  late final _fgets = _fgetsPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<ffi.Char>, int, ffi.Pointer<FILE>)>();

  ffi.Pointer<FILE> fopen(
    ffi.Pointer<ffi.Char> __filename,
    ffi.Pointer<ffi.Char> __mode,
  ) {
    return _fopen(
      __filename,
      __mode,
    );
  }

  late final _fopenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('fopen');
  late final _fopen = _fopenPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  int fprintf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _fprintf(
      arg0,
      arg1,
    );
  }

  late final _fprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>>('fprintf');
  late final _fprintf = _fprintfPtr
      .asFunction<int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>();

  int fputc(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _fputc(
      arg0,
      arg1,
    );
  }

  late final _fputcPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          'fputc');
  late final _fputc =
      _fputcPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  int fputs(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _fputs(
      arg0,
      arg1,
    );
  }

  late final _fputsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<FILE>)>>('fputs');
  late final _fputs = _fputsPtr
      .asFunction<int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<FILE>)>();

  int fread(
    ffi.Pointer<ffi.Void> __ptr,
    int __size,
    int __nitems,
    ffi.Pointer<FILE> __stream,
  ) {
    return _fread(
      __ptr,
      __size,
      __nitems,
      __stream,
    );
  }

  late final _freadPtr = _lookup<
      ffi.NativeFunction<
          ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, ffi.Size, ffi.Size,
              ffi.Pointer<FILE>)>>('fread');
  late final _fread = _freadPtr.asFunction<
      int Function(ffi.Pointer<ffi.Void>, int, int, ffi.Pointer<FILE>)>();

  ffi.Pointer<FILE> freopen(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
    ffi.Pointer<FILE> arg2,
  ) {
    return _freopen(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _freopenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, ffi.Pointer<FILE>)>>('freopen');
  late final _freopen = _freopenPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, ffi.Pointer<FILE>)>();

  int fscanf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _fscanf(
      arg0,
      arg1,
    );
  }

  late final _fscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>>('fscanf');
  late final _fscanf = _fscanfPtr
      .asFunction<int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>();

  int fseek(
    ffi.Pointer<FILE> arg0,
    int arg1,
    int arg2,
  ) {
    return _fseek(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _fseekPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<FILE>, ffi.Long, ffi.Int)>>('fseek');
  late final _fseek =
      _fseekPtr.asFunction<int Function(ffi.Pointer<FILE>, int, int)>();

  int fsetpos(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<fpos_t> arg1,
  ) {
    return _fsetpos(
      arg0,
      arg1,
    );
  }

  late final _fsetposPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<FILE>, ffi.Pointer<fpos_t>)>>('fsetpos');
  late final _fsetpos = _fsetposPtr
      .asFunction<int Function(ffi.Pointer<FILE>, ffi.Pointer<fpos_t>)>();

  int ftell(
    ffi.Pointer<FILE> arg0,
  ) {
    return _ftell(
      arg0,
    );
  }

  late final _ftellPtr =
      _lookup<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<FILE>)>>(
          'ftell');
  late final _ftell = _ftellPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int fwrite(
    ffi.Pointer<ffi.Void> __ptr,
    int __size,
    int __nitems,
    ffi.Pointer<FILE> __stream,
  ) {
    return _fwrite(
      __ptr,
      __size,
      __nitems,
      __stream,
    );
  }

  late final _fwritePtr = _lookup<
      ffi.NativeFunction<
          ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, ffi.Size, ffi.Size,
              ffi.Pointer<FILE>)>>('fwrite');
  late final _fwrite = _fwritePtr.asFunction<
      int Function(ffi.Pointer<ffi.Void>, int, int, ffi.Pointer<FILE>)>();

  int getc(
    ffi.Pointer<FILE> arg0,
  ) {
    return _getc(
      arg0,
    );
  }

  late final _getcPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>('getc');
  late final _getc = _getcPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int getchar() {
    return _getchar();
  }

  late final _getcharPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('getchar');
  late final _getchar = _getcharPtr.asFunction<int Function()>();

  ffi.Pointer<ffi.Char> gets(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _gets(
      arg0,
    );
  }

  late final _getsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>>('gets');
  late final _gets = _getsPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>();

  void perror(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _perror(
      arg0,
    );
  }

  late final _perrorPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Char>)>>(
          'perror');
  late final _perror =
      _perrorPtr.asFunction<void Function(ffi.Pointer<ffi.Char>)>();

  int printf(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _printf(
      arg0,
    );
  }

  late final _printfPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'printf');
  late final _printf =
      _printfPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int putc(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _putc(
      arg0,
      arg1,
    );
  }

  late final _putcPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          'putc');
  late final _putc =
      _putcPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  int putchar(
    int arg0,
  ) {
    return _putchar(
      arg0,
    );
  }

  late final _putcharPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>('putchar');
  late final _putchar = _putcharPtr.asFunction<int Function(int)>();

  int puts(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _puts(
      arg0,
    );
  }

  late final _putsPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'puts');
  late final _puts = _putsPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int remove(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _remove(
      arg0,
    );
  }

  late final _removePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'remove');
  late final _remove =
      _removePtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  int rename(
    ffi.Pointer<ffi.Char> __old,
    ffi.Pointer<ffi.Char> __new,
  ) {
    return _rename(
      __old,
      __new,
    );
  }

  late final _renamePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('rename');
  late final _rename = _renamePtr
      .asFunction<int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  void rewind(
    ffi.Pointer<FILE> arg0,
  ) {
    return _rewind(
      arg0,
    );
  }

  late final _rewindPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<FILE>)>>(
          'rewind');
  late final _rewind =
      _rewindPtr.asFunction<void Function(ffi.Pointer<FILE>)>();

  int scanf(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _scanf(
      arg0,
    );
  }

  late final _scanfPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>)>>(
          'scanf');
  late final _scanf =
      _scanfPtr.asFunction<int Function(ffi.Pointer<ffi.Char>)>();

  void setbuf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _setbuf(
      arg0,
      arg1,
    );
  }

  late final _setbufPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>>('setbuf');
  late final _setbuf = _setbufPtr
      .asFunction<void Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>)>();

  int setvbuf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
    int arg3,
  ) {
    return _setvbuf(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _setvbufPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, ffi.Int,
              ffi.Size)>>('setvbuf');
  late final _setvbuf = _setvbufPtr.asFunction<
      int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, int, int)>();

  int sprintf(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _sprintf(
      arg0,
      arg1,
    );
  }

  late final _sprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('sprintf');
  late final _sprintf = _sprintfPtr
      .asFunction<int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  int sscanf(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _sscanf(
      arg0,
      arg1,
    );
  }

  late final _sscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('sscanf');
  late final _sscanf = _sscanfPtr
      .asFunction<int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<FILE> tmpfile() {
    return _tmpfile();
  }

  late final _tmpfilePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<FILE> Function()>>('tmpfile');
  late final _tmpfile = _tmpfilePtr.asFunction<ffi.Pointer<FILE> Function()>();

  ffi.Pointer<ffi.Char> tmpnam(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _tmpnam(
      arg0,
    );
  }

  late final _tmpnamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>>('tmpnam');
  late final _tmpnam = _tmpnamPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>();

  int ungetc(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _ungetc(
      arg0,
      arg1,
    );
  }

  late final _ungetcPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          'ungetc');
  late final _ungetc =
      _ungetcPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  int vfprintf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
    va_list arg2,
  ) {
    return _vfprintf(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _vfprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, va_list)>>('vfprintf');
  late final _vfprintf = _vfprintfPtr.asFunction<
      int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, va_list)>();

  int vprintf(
    ffi.Pointer<ffi.Char> arg0,
    va_list arg1,
  ) {
    return _vprintf(
      arg0,
      arg1,
    );
  }

  late final _vprintfPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>, va_list)>>(
      'vprintf');
  late final _vprintf =
      _vprintfPtr.asFunction<int Function(ffi.Pointer<ffi.Char>, va_list)>();

  int vsprintf(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
    va_list arg2,
  ) {
    return _vsprintf(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _vsprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              va_list)>>('vsprintf');
  late final _vsprintf = _vsprintfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, va_list)>();

  ffi.Pointer<ffi.Char> ctermid(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _ctermid(
      arg0,
    );
  }

  late final _ctermidPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>>('ctermid');
  late final _ctermid = _ctermidPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<FILE> fdopen(
    int arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _fdopen(
      arg0,
      arg1,
    );
  }

  late final _fdopenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(
              ffi.Int, ffi.Pointer<ffi.Char>)>>('fdopen');
  late final _fdopen = _fdopenPtr
      .asFunction<ffi.Pointer<FILE> Function(int, ffi.Pointer<ffi.Char>)>();

  int fileno(
    ffi.Pointer<FILE> arg0,
  ) {
    return _fileno(
      arg0,
    );
  }

  late final _filenoPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'fileno');
  late final _fileno = _filenoPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int pclose(
    ffi.Pointer<FILE> arg0,
  ) {
    return _pclose(
      arg0,
    );
  }

  late final _pclosePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'pclose');
  late final _pclose = _pclosePtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  ffi.Pointer<FILE> popen(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _popen(
      arg0,
      arg1,
    );
  }

  late final _popenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('popen');
  late final _popen = _popenPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  /// Functions internal to the implementation.
  int __srget(
    ffi.Pointer<FILE> arg0,
  ) {
    return ___srget(
      arg0,
    );
  }

  late final ___srgetPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          '__srget');
  late final ___srget =
      ___srgetPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int __svfscanf(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
    va_list arg2,
  ) {
    return ___svfscanf(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___svfscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>,
              va_list)>>('__svfscanf');
  late final ___svfscanf = ___svfscanfPtr.asFunction<
      int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, va_list)>();

  int __swbuf(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return ___swbuf(
      arg0,
      arg1,
    );
  }

  late final ___swbufPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          '__swbuf');
  late final ___swbuf =
      ___swbufPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  void flockfile(
    ffi.Pointer<FILE> arg0,
  ) {
    return _flockfile(
      arg0,
    );
  }

  late final _flockfilePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<FILE>)>>(
          'flockfile');
  late final _flockfile =
      _flockfilePtr.asFunction<void Function(ffi.Pointer<FILE>)>();

  int ftrylockfile(
    ffi.Pointer<FILE> arg0,
  ) {
    return _ftrylockfile(
      arg0,
    );
  }

  late final _ftrylockfilePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'ftrylockfile');
  late final _ftrylockfile =
      _ftrylockfilePtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  void funlockfile(
    ffi.Pointer<FILE> arg0,
  ) {
    return _funlockfile(
      arg0,
    );
  }

  late final _funlockfilePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<FILE>)>>(
          'funlockfile');
  late final _funlockfile =
      _funlockfilePtr.asFunction<void Function(ffi.Pointer<FILE>)>();

  int getc_unlocked(
    ffi.Pointer<FILE> arg0,
  ) {
    return _getc_unlocked(
      arg0,
    );
  }

  late final _getc_unlockedPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'getc_unlocked');
  late final _getc_unlocked =
      _getc_unlockedPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int getchar_unlocked() {
    return _getchar_unlocked();
  }

  late final _getchar_unlockedPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('getchar_unlocked');
  late final _getchar_unlocked =
      _getchar_unlockedPtr.asFunction<int Function()>();

  int putc_unlocked(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _putc_unlocked(
      arg0,
      arg1,
    );
  }

  late final _putc_unlockedPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          'putc_unlocked');
  late final _putc_unlocked =
      _putc_unlockedPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  int putchar_unlocked(
    int arg0,
  ) {
    return _putchar_unlocked(
      arg0,
    );
  }

  late final _putchar_unlockedPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int)>>(
          'putchar_unlocked');
  late final _putchar_unlocked =
      _putchar_unlockedPtr.asFunction<int Function(int)>();

  int getw(
    ffi.Pointer<FILE> arg0,
  ) {
    return _getw(
      arg0,
    );
  }

  late final _getwPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>('getw');
  late final _getw = _getwPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int putw(
    int arg0,
    ffi.Pointer<FILE> arg1,
  ) {
    return _putw(
      arg0,
      arg1,
    );
  }

  late final _putwPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<FILE>)>>(
          'putw');
  late final _putw =
      _putwPtr.asFunction<int Function(int, ffi.Pointer<FILE>)>();

  ffi.Pointer<ffi.Char> tempnam(
    ffi.Pointer<ffi.Char> __dir,
    ffi.Pointer<ffi.Char> __prefix,
  ) {
    return _tempnam(
      __dir,
      __prefix,
    );
  }

  late final _tempnamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('tempnam');
  late final _tempnam = _tempnamPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  int fseeko(
    ffi.Pointer<FILE> __stream,
    int __offset,
    int __whence,
  ) {
    return _fseeko(
      __stream,
      __offset,
      __whence,
    );
  }

  late final _fseekoPtr = _lookup<
          ffi
          .NativeFunction<ffi.Int Function(ffi.Pointer<FILE>, off_t, ffi.Int)>>(
      'fseeko');
  late final _fseeko =
      _fseekoPtr.asFunction<int Function(ffi.Pointer<FILE>, int, int)>();

  int ftello(
    ffi.Pointer<FILE> __stream,
  ) {
    return _ftello(
      __stream,
    );
  }

  late final _ftelloPtr =
      _lookup<ffi.NativeFunction<off_t Function(ffi.Pointer<FILE>)>>('ftello');
  late final _ftello = _ftelloPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int snprintf(
    ffi.Pointer<ffi.Char> __str,
    int __size,
    ffi.Pointer<ffi.Char> __format,
  ) {
    return _snprintf(
      __str,
      __size,
      __format,
    );
  }

  late final _snprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Size,
              ffi.Pointer<ffi.Char>)>>('snprintf');
  late final _snprintf = _snprintfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, int, ffi.Pointer<ffi.Char>)>();

  int vfscanf(
    ffi.Pointer<FILE> __stream,
    ffi.Pointer<ffi.Char> __format,
    va_list arg2,
  ) {
    return _vfscanf(
      __stream,
      __format,
      arg2,
    );
  }

  late final _vfscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, va_list)>>('vfscanf');
  late final _vfscanf = _vfscanfPtr.asFunction<
      int Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, va_list)>();

  int vscanf(
    ffi.Pointer<ffi.Char> __format,
    va_list arg1,
  ) {
    return _vscanf(
      __format,
      arg1,
    );
  }

  late final _vscanfPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Char>, va_list)>>(
      'vscanf');
  late final _vscanf =
      _vscanfPtr.asFunction<int Function(ffi.Pointer<ffi.Char>, va_list)>();

  int vsnprintf(
    ffi.Pointer<ffi.Char> __str,
    int __size,
    ffi.Pointer<ffi.Char> __format,
    va_list arg3,
  ) {
    return _vsnprintf(
      __str,
      __size,
      __format,
      arg3,
    );
  }

  late final _vsnprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Size,
              ffi.Pointer<ffi.Char>, va_list)>>('vsnprintf');
  late final _vsnprintf = _vsnprintfPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, int, ffi.Pointer<ffi.Char>, va_list)>();

  int vsscanf(
    ffi.Pointer<ffi.Char> __str,
    ffi.Pointer<ffi.Char> __format,
    va_list arg2,
  ) {
    return _vsscanf(
      __str,
      __format,
      arg2,
    );
  }

  late final _vsscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
              va_list)>>('vsscanf');
  late final _vsscanf = _vsscanfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, va_list)>();

  int dprintf(
    int arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _dprintf(
      arg0,
      arg1,
    );
  }

  late final _dprintfPtr = _lookup<
          ffi.NativeFunction<ffi.Int Function(ffi.Int, ffi.Pointer<ffi.Char>)>>(
      'dprintf');
  late final _dprintf =
      _dprintfPtr.asFunction<int Function(int, ffi.Pointer<ffi.Char>)>();

  int vdprintf(
    int arg0,
    ffi.Pointer<ffi.Char> arg1,
    va_list arg2,
  ) {
    return _vdprintf(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _vdprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Int, ffi.Pointer<ffi.Char>, va_list)>>('vdprintf');
  late final _vdprintf = _vdprintfPtr
      .asFunction<int Function(int, ffi.Pointer<ffi.Char>, va_list)>();

  int getdelim(
    ffi.Pointer<ffi.Pointer<ffi.Char>> __linep,
    ffi.Pointer<ffi.Size> __linecapp,
    int __delimiter,
    ffi.Pointer<FILE> __stream,
  ) {
    return _getdelim(
      __linep,
      __linecapp,
      __delimiter,
      __stream,
    );
  }

  late final _getdelimPtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Size>, ffi.Int, ffi.Pointer<FILE>)>>('getdelim');
  late final _getdelim = _getdelimPtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Size>,
          int, ffi.Pointer<FILE>)>();

  int getline(
    ffi.Pointer<ffi.Pointer<ffi.Char>> __linep,
    ffi.Pointer<ffi.Size> __linecapp,
    ffi.Pointer<FILE> __stream,
  ) {
    return _getline(
      __linep,
      __linecapp,
      __stream,
    );
  }

  late final _getlinePtr = _lookup<
      ffi.NativeFunction<
          ssize_t Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Size>, ffi.Pointer<FILE>)>>('getline');
  late final _getline = _getlinePtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Size>,
          ffi.Pointer<FILE>)>();

  ffi.Pointer<FILE> fmemopen(
    ffi.Pointer<ffi.Void> __buf,
    int __size,
    ffi.Pointer<ffi.Char> __mode,
  ) {
    return _fmemopen(
      __buf,
      __size,
      __mode,
    );
  }

  late final _fmemopenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(ffi.Pointer<ffi.Void>, ffi.Size,
              ffi.Pointer<ffi.Char>)>>('fmemopen');
  late final _fmemopen = _fmemopenPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Void>, int, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<FILE> open_memstream(
    ffi.Pointer<ffi.Pointer<ffi.Char>> __bufp,
    ffi.Pointer<ffi.Size> __sizep,
  ) {
    return _open_memstream(
      __bufp,
      __sizep,
    );
  }

  late final _open_memstreamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Size>)>>('open_memstream');
  late final _open_memstream = _open_memstreamPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Size>)>();

  /// perror(3) external variables
  late final ffi.Pointer<ffi.Int> _sys_nerr = _lookup<ffi.Int>('sys_nerr');

  int get sys_nerr => _sys_nerr.value;

  set sys_nerr(int value) => _sys_nerr.value = value;

  late final ffi.Pointer<ffi.Pointer<ffi.Pointer<ffi.Char>>> _sys_errlist =
      _lookup<ffi.Pointer<ffi.Pointer<ffi.Char>>>('sys_errlist');

  ffi.Pointer<ffi.Pointer<ffi.Char>> get sys_errlist => _sys_errlist.value;

  set sys_errlist(ffi.Pointer<ffi.Pointer<ffi.Char>> value) =>
      _sys_errlist.value = value;

  int asprintf(
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _asprintf(
      arg0,
      arg1,
    );
  }

  late final _asprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Char>)>>('asprintf');
  late final _asprintf = _asprintfPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ffi.Char> ctermid_r(
    ffi.Pointer<ffi.Char> arg0,
  ) {
    return _ctermid_r(
      arg0,
    );
  }

  late final _ctermid_rPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>>('ctermid_r');
  late final _ctermid_r = _ctermid_rPtr
      .asFunction<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Char>)>();

  ffi.Pointer<ffi.Char> fgetln(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Size> arg1,
  ) {
    return _fgetln(
      arg0,
      arg1,
    );
  }

  late final _fgetlnPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Size>)>>('fgetln');
  late final _fgetln = _fgetlnPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<FILE>, ffi.Pointer<ffi.Size>)>();

  ffi.Pointer<ffi.Char> fmtcheck(
    ffi.Pointer<ffi.Char> arg0,
    ffi.Pointer<ffi.Char> arg1,
  ) {
    return _fmtcheck(
      arg0,
      arg1,
    );
  }

  late final _fmtcheckPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>>('fmtcheck');
  late final _fmtcheck = _fmtcheckPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(
          ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>)>();

  int fpurge(
    ffi.Pointer<FILE> arg0,
  ) {
    return _fpurge(
      arg0,
    );
  }

  late final _fpurgePtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'fpurge');
  late final _fpurge = _fpurgePtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  void setbuffer(
    ffi.Pointer<FILE> arg0,
    ffi.Pointer<ffi.Char> arg1,
    int arg2,
  ) {
    return _setbuffer(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _setbufferPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, ffi.Int)>>('setbuffer');
  late final _setbuffer = _setbufferPtr.asFunction<
      void Function(ffi.Pointer<FILE>, ffi.Pointer<ffi.Char>, int)>();

  int setlinebuf(
    ffi.Pointer<FILE> arg0,
  ) {
    return _setlinebuf(
      arg0,
    );
  }

  late final _setlinebufPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<FILE>)>>(
          'setlinebuf');
  late final _setlinebuf =
      _setlinebufPtr.asFunction<int Function(ffi.Pointer<FILE>)>();

  int vasprintf(
    ffi.Pointer<ffi.Pointer<ffi.Char>> arg0,
    ffi.Pointer<ffi.Char> arg1,
    va_list arg2,
  ) {
    return _vasprintf(
      arg0,
      arg1,
      arg2,
    );
  }

  late final _vasprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>,
              ffi.Pointer<ffi.Char>, va_list)>>('vasprintf');
  late final _vasprintf = _vasprintfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.Char>>, ffi.Pointer<ffi.Char>,
          va_list)>();

  /// Stdio function-access interface.
  ffi.Pointer<FILE> funopen(
    ffi.Pointer<ffi.Void> arg0,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(
                    ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>>
        arg1,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int Function(
                    ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>>
        arg2,
    ffi.Pointer<
            ffi.NativeFunction<
                fpos_t Function(ffi.Pointer<ffi.Void>, fpos_t, ffi.Int)>>
        arg3,
    ffi.Pointer<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void>)>>
        arg4,
  ) {
    return _funopen(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final _funopenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<FILE> Function(
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Char>, ffi.Int)>>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Char>, ffi.Int)>>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      fpos_t Function(ffi.Pointer<ffi.Void>, fpos_t, ffi.Int)>>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int Function(ffi.Pointer<ffi.Void>)>>)>>('funopen');
  late final _funopen = _funopenPtr.asFunction<
      ffi.Pointer<FILE> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int Function(
                      ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>>,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int Function(
                      ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>>,
          ffi.Pointer<
              ffi.NativeFunction<
                  fpos_t Function(ffi.Pointer<ffi.Void>, fpos_t, ffi.Int)>>,
          ffi.Pointer<
              ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void>)>>)>();

  int __sprintf_chk(
    ffi.Pointer<ffi.Char> arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Char> arg3,
  ) {
    return ___sprintf_chk(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final ___sprintf_chkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Size,
              ffi.Pointer<ffi.Char>)>>('__sprintf_chk');
  late final ___sprintf_chk = ___sprintf_chkPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, int, int, ffi.Pointer<ffi.Char>)>();

  int __snprintf_chk(
    ffi.Pointer<ffi.Char> arg0,
    int arg1,
    int arg2,
    int arg3,
    ffi.Pointer<ffi.Char> arg4,
  ) {
    return ___snprintf_chk(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final ___snprintf_chkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Size, ffi.Int, ffi.Size,
              ffi.Pointer<ffi.Char>)>>('__snprintf_chk');
  late final ___snprintf_chk = ___snprintf_chkPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, int, int, int, ffi.Pointer<ffi.Char>)>();

  int __vsprintf_chk(
    ffi.Pointer<ffi.Char> arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Char> arg3,
    va_list arg4,
  ) {
    return ___vsprintf_chk(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final ___vsprintf_chkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Int, ffi.Size,
              ffi.Pointer<ffi.Char>, va_list)>>('__vsprintf_chk');
  late final ___vsprintf_chk = ___vsprintf_chkPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Char>, int, int, ffi.Pointer<ffi.Char>, va_list)>();

  int __vsnprintf_chk(
    ffi.Pointer<ffi.Char> arg0,
    int arg1,
    int arg2,
    int arg3,
    ffi.Pointer<ffi.Char> arg4,
    va_list arg5,
  ) {
    return ___vsnprintf_chk(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final ___vsnprintf_chkPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Size, ffi.Int, ffi.Size,
              ffi.Pointer<ffi.Char>, va_list)>>('__vsnprintf_chk');
  late final ___vsnprintf_chk = ___vsnprintf_chkPtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, int, int, int, ffi.Pointer<ffi.Char>,
          va_list)>();

  llama_context_params llama_context_default_params() {
    return _llama_context_default_params();
  }

  late final _llama_context_default_paramsPtr =
      _lookup<ffi.NativeFunction<llama_context_params Function()>>(
          'llama_context_default_params');
  late final _llama_context_default_params = _llama_context_default_paramsPtr
      .asFunction<llama_context_params Function()>();

  llama_model_quantize_params llama_model_quantize_default_params() {
    return _llama_model_quantize_default_params();
  }

  late final _llama_model_quantize_default_paramsPtr =
      _lookup<ffi.NativeFunction<llama_model_quantize_params Function()>>(
          'llama_model_quantize_default_params');
  late final _llama_model_quantize_default_params =
      _llama_model_quantize_default_paramsPtr
          .asFunction<llama_model_quantize_params Function()>();

  /// Initialize the llama + ggml backend
  /// If numa is true, use NUMA optimizations
  /// Call once at the start of the program
  void llama_backend_init(
    bool numa,
  ) {
    return _llama_backend_init(
      numa,
    );
  }

  late final _llama_backend_initPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Bool)>>(
          'llama_backend_init');
  late final _llama_backend_init =
      _llama_backend_initPtr.asFunction<void Function(bool)>();

  /// Call once at the end of the program - currently only used for MPI
  void llama_backend_free() {
    return _llama_backend_free();
  }

  late final _llama_backend_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('llama_backend_free');
  late final _llama_backend_free =
      _llama_backend_freePtr.asFunction<void Function()>();

  ffi.Pointer<llama_model> llama_load_model_from_file(
    ffi.Pointer<ffi.Char> path_model,
    llama_context_params params,
  ) {
    return _llama_load_model_from_file(
      path_model,
      params,
    );
  }

  late final _llama_load_model_from_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<llama_model> Function(ffi.Pointer<ffi.Char>,
              llama_context_params)>>('llama_load_model_from_file');
  late final _llama_load_model_from_file =
      _llama_load_model_from_filePtr.asFunction<
          ffi.Pointer<llama_model> Function(
              ffi.Pointer<ffi.Char>, llama_context_params)>();

  void llama_free_model(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_free_model(
      model,
    );
  }

  late final _llama_free_modelPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_model>)>>(
          'llama_free_model');
  late final _llama_free_model = _llama_free_modelPtr
      .asFunction<void Function(ffi.Pointer<llama_model>)>();

  ffi.Pointer<llama_context> llama_new_context_with_model(
    ffi.Pointer<llama_model> model,
    llama_context_params params,
  ) {
    return _llama_new_context_with_model(
      model,
      params,
    );
  }

  late final _llama_new_context_with_modelPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<llama_context> Function(ffi.Pointer<llama_model>,
              llama_context_params)>>('llama_new_context_with_model');
  late final _llama_new_context_with_model =
      _llama_new_context_with_modelPtr.asFunction<
          ffi.Pointer<llama_context> Function(
              ffi.Pointer<llama_model>, llama_context_params)>();

  /// Frees all allocated memory
  void llama_free(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_free(
      ctx,
    );
  }

  late final _llama_freePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>>(
      'llama_free');
  late final _llama_free =
      _llama_freePtr.asFunction<void Function(ffi.Pointer<llama_context>)>();

  int llama_time_us() {
    return _llama_time_us();
  }

  late final _llama_time_usPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function()>>('llama_time_us');
  late final _llama_time_us = _llama_time_usPtr.asFunction<int Function()>();

  int llama_max_devices() {
    return _llama_max_devices();
  }

  late final _llama_max_devicesPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function()>>('llama_max_devices');
  late final _llama_max_devices =
      _llama_max_devicesPtr.asFunction<int Function()>();

  bool llama_mmap_supported() {
    return _llama_mmap_supported();
  }

  late final _llama_mmap_supportedPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function()>>('llama_mmap_supported');
  late final _llama_mmap_supported =
      _llama_mmap_supportedPtr.asFunction<bool Function()>();

  bool llama_mlock_supported() {
    return _llama_mlock_supported();
  }

  late final _llama_mlock_supportedPtr =
      _lookup<ffi.NativeFunction<ffi.Bool Function()>>('llama_mlock_supported');
  late final _llama_mlock_supported =
      _llama_mlock_supportedPtr.asFunction<bool Function()>();

  int llama_n_vocab(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_n_vocab(
      ctx,
    );
  }

  late final _llama_n_vocabPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_context>)>>(
          'llama_n_vocab');
  late final _llama_n_vocab =
      _llama_n_vocabPtr.asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_n_ctx(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_n_ctx(
      ctx,
    );
  }

  late final _llama_n_ctxPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_context>)>>(
          'llama_n_ctx');
  late final _llama_n_ctx =
      _llama_n_ctxPtr.asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_n_ctx_train(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_n_ctx_train(
      ctx,
    );
  }

  late final _llama_n_ctx_trainPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_context>)>>(
          'llama_n_ctx_train');
  late final _llama_n_ctx_train = _llama_n_ctx_trainPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_n_embd(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_n_embd(
      ctx,
    );
  }

  late final _llama_n_embdPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_context>)>>(
          'llama_n_embd');
  late final _llama_n_embd =
      _llama_n_embdPtr.asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_vocab_type1(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_vocab_type1(
      ctx,
    );
  }

  late final _llama_vocab_type1Ptr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<llama_context>)>>(
      'llama_vocab_type');
  late final _llama_vocab_type1 = _llama_vocab_type1Ptr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_model_n_vocab(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_model_n_vocab(
      model,
    );
  }

  late final _llama_model_n_vocabPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_model>)>>(
          'llama_model_n_vocab');
  late final _llama_model_n_vocab = _llama_model_n_vocabPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_model_n_ctx(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_model_n_ctx(
      model,
    );
  }

  late final _llama_model_n_ctxPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_model>)>>(
          'llama_model_n_ctx');
  late final _llama_model_n_ctx = _llama_model_n_ctxPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_model_n_ctx_train(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_model_n_ctx_train(
      model,
    );
  }

  late final _llama_model_n_ctx_trainPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_model>)>>(
          'llama_model_n_ctx_train');
  late final _llama_model_n_ctx_train = _llama_model_n_ctx_trainPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  int llama_model_n_embd(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_model_n_embd(
      model,
    );
  }

  late final _llama_model_n_embdPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_model>)>>(
          'llama_model_n_embd');
  late final _llama_model_n_embd = _llama_model_n_embdPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  /// Get a string describing the model type
  int llama_model_desc(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> buf,
    int buf_size,
  ) {
    return _llama_model_desc(
      model,
      buf,
      buf_size,
    );
  }

  late final _llama_model_descPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>,
              ffi.Size)>>('llama_model_desc');
  late final _llama_model_desc = _llama_model_descPtr.asFunction<
      int Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>, int)>();

  /// Returns the total size of all the tensors in the model in bytes
  int llama_model_size(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_model_size(
      model,
    );
  }

  late final _llama_model_sizePtr = _lookup<
          ffi.NativeFunction<ffi.Uint64 Function(ffi.Pointer<llama_model>)>>(
      'llama_model_size');
  late final _llama_model_size =
      _llama_model_sizePtr.asFunction<int Function(ffi.Pointer<llama_model>)>();

  /// Returns the total number of parameters in the model
  int llama_model_n_params(
    ffi.Pointer<llama_model> model,
  ) {
    return _llama_model_n_params(
      model,
    );
  }

  late final _llama_model_n_paramsPtr = _lookup<
          ffi.NativeFunction<ffi.Uint64 Function(ffi.Pointer<llama_model>)>>(
      'llama_model_n_params');
  late final _llama_model_n_params = _llama_model_n_paramsPtr
      .asFunction<int Function(ffi.Pointer<llama_model>)>();

  /// Returns 0 on success
  int llama_model_quantize(
    ffi.Pointer<ffi.Char> fname_inp,
    ffi.Pointer<ffi.Char> fname_out,
    ffi.Pointer<llama_model_quantize_params> params,
  ) {
    return _llama_model_quantize(
      fname_inp,
      fname_out,
      params,
    );
  }

  late final _llama_model_quantizePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
                  ffi.Pointer<llama_model_quantize_params>)>>(
      'llama_model_quantize');
  late final _llama_model_quantize = _llama_model_quantizePtr.asFunction<
      int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<llama_model_quantize_params>)>();

  int llama_apply_lora_from_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> path_lora,
    ffi.Pointer<ffi.Char> path_base_model,
    int n_threads,
  ) {
    return _llama_apply_lora_from_file(
      ctx,
      path_lora,
      path_base_model,
      n_threads,
    );
  }

  late final _llama_apply_lora_from_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, ffi.Int)>>('llama_apply_lora_from_file');
  late final _llama_apply_lora_from_file =
      _llama_apply_lora_from_filePtr.asFunction<
          int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, int)>();

  int llama_model_apply_lora_from_file(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> path_lora,
    ffi.Pointer<ffi.Char> path_base_model,
    int n_threads,
  ) {
    return _llama_model_apply_lora_from_file(
      model,
      path_lora,
      path_base_model,
      n_threads,
    );
  }

  late final _llama_model_apply_lora_from_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<llama_model>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>,
              ffi.Int)>>('llama_model_apply_lora_from_file');
  late final _llama_model_apply_lora_from_file =
      _llama_model_apply_lora_from_filePtr.asFunction<
          int Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<ffi.Char>, int)>();

  /// Returns the number of tokens in the KV cache
  int llama_get_kv_cache_token_count(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_get_kv_cache_token_count(
      ctx,
    );
  }

  late final _llama_get_kv_cache_token_countPtr =
      _lookup<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<llama_context>)>>(
          'llama_get_kv_cache_token_count');
  late final _llama_get_kv_cache_token_count =
      _llama_get_kv_cache_token_countPtr
          .asFunction<int Function(ffi.Pointer<llama_context>)>();

  /// Sets the current rng seed.
  void llama_set_rng_seed(
    ffi.Pointer<llama_context> ctx,
    int seed,
  ) {
    return _llama_set_rng_seed(
      ctx,
      seed,
    );
  }

  late final _llama_set_rng_seedPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>, ffi.Uint32)>>('llama_set_rng_seed');
  late final _llama_set_rng_seed = _llama_set_rng_seedPtr
      .asFunction<void Function(ffi.Pointer<llama_context>, int)>();

  /// Returns the maximum size in bytes of the state (rng, logits, embedding
  /// and kv_cache) - will often be smaller after compacting tokens
  int llama_get_state_size(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_get_state_size(
      ctx,
    );
  }

  late final _llama_get_state_sizePtr = _lookup<
          ffi.NativeFunction<ffi.Size Function(ffi.Pointer<llama_context>)>>(
      'llama_get_state_size');
  late final _llama_get_state_size = _llama_get_state_sizePtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  /// Copies the state to the specified destination address.
  /// Destination needs to have allocated enough memory.
  /// Returns the number of bytes copied
  int llama_copy_state_data(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> dst,
  ) {
    return _llama_copy_state_data(
      ctx,
      dst,
    );
  }

  late final _llama_copy_state_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<llama_context>,
              ffi.Pointer<ffi.Uint8>)>>('llama_copy_state_data');
  late final _llama_copy_state_data = _llama_copy_state_dataPtr.asFunction<
      int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>)>();

  /// Set the state reading from the specified address
  /// Returns the number of bytes read
  int llama_set_state_data(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Uint8> src,
  ) {
    return _llama_set_state_data(
      ctx,
      src,
    );
  }

  late final _llama_set_state_dataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Size Function(ffi.Pointer<llama_context>,
              ffi.Pointer<ffi.Uint8>)>>('llama_set_state_data');
  late final _llama_set_state_data = _llama_set_state_dataPtr.asFunction<
      int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Uint8>)>();

  /// Save/load session file
  bool llama_load_session_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> path_session,
    ffi.Pointer<llama_token> tokens_out,
    int n_token_capacity,
    ffi.Pointer<ffi.Size> n_token_count_out,
  ) {
    return _llama_load_session_file(
      ctx,
      path_session,
      tokens_out,
      n_token_capacity,
      n_token_count_out,
    );
  }

  late final _llama_load_session_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<ffi.Char>,
              ffi.Pointer<llama_token>,
              ffi.Size,
              ffi.Pointer<ffi.Size>)>>('llama_load_session_file');
  late final _llama_load_session_file = _llama_load_session_filePtr.asFunction<
      bool Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<llama_token>, int, ffi.Pointer<ffi.Size>)>();

  bool llama_save_session_file(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> path_session,
    ffi.Pointer<llama_token> tokens,
    int n_token_count,
  ) {
    return _llama_save_session_file(
      ctx,
      path_session,
      tokens,
      n_token_count,
    );
  }

  late final _llama_save_session_filePtr = _lookup<
      ffi.NativeFunction<
          ffi.Bool Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Char>,
              ffi.Pointer<llama_token>, ffi.Size)>>('llama_save_session_file');
  late final _llama_save_session_file = _llama_save_session_filePtr.asFunction<
      bool Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Char>,
          ffi.Pointer<llama_token>, int)>();

  /// Run the llama inference to obtain the logits and probabilities for the next token.
  /// tokens + n_tokens is the provided batch of new tokens to process
  /// n_past is the number of tokens to use from previous eval calls
  /// Returns 0 on success
  int llama_eval(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token> tokens,
    int n_tokens,
    int n_past,
    int n_threads,
  ) {
    return _llama_eval(
      ctx,
      tokens,
      n_tokens,
      n_past,
      n_threads,
    );
  }

  late final _llama_evalPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<llama_context>, ffi.Pointer<llama_token>,
              ffi.Int, ffi.Int, ffi.Int)>>('llama_eval');
  late final _llama_eval = _llama_evalPtr.asFunction<
      int Function(ffi.Pointer<llama_context>, ffi.Pointer<llama_token>, int,
          int, int)>();

  /// Same as llama_eval, but use float matrix input directly.
  int llama_eval_embd(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Float> embd,
    int n_tokens,
    int n_past,
    int n_threads,
  ) {
    return _llama_eval_embd(
      ctx,
      embd,
      n_tokens,
      n_past,
      n_threads,
    );
  }

  late final _llama_eval_embdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Float>,
              ffi.Int, ffi.Int, ffi.Int)>>('llama_eval_embd');
  late final _llama_eval_embd = _llama_eval_embdPtr.asFunction<
      int Function(
          ffi.Pointer<llama_context>, ffi.Pointer<ffi.Float>, int, int, int)>();

  /// Export a static computation graph for context of 511 and batch size of 1
  /// NOTE: since this functionality is mostly for debugging and demonstration purposes, we hardcode these
  /// parameters here to keep things simple
  /// IMPORTANT: do not use for anything else other than debugging and testing!
  int llama_eval_export(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> fname,
  ) {
    return _llama_eval_export(
      ctx,
      fname,
    );
  }

  late final _llama_eval_exportPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<llama_context>,
              ffi.Pointer<ffi.Char>)>>('llama_eval_export');
  late final _llama_eval_export = _llama_eval_exportPtr.asFunction<
      int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Char>)>();

  /// Token logits obtained from the last call to llama_eval()
  /// The logits for the last token are stored in the last row
  /// Can be mutated in order to change the probabilities of the next token
  /// Rows: n_tokens
  /// Cols: n_vocab
  ffi.Pointer<ffi.Float> llama_get_logits(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_get_logits(
      ctx,
    );
  }

  late final _llama_get_logitsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(
              ffi.Pointer<llama_context>)>>('llama_get_logits');
  late final _llama_get_logits = _llama_get_logitsPtr.asFunction<
      ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>)>();

  /// Get the embeddings for the input
  /// shape: [n_embd] (1-dimensional)
  ffi.Pointer<ffi.Float> llama_get_embeddings(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_get_embeddings(
      ctx,
    );
  }

  late final _llama_get_embeddingsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Float> Function(
              ffi.Pointer<llama_context>)>>('llama_get_embeddings');
  late final _llama_get_embeddings = _llama_get_embeddingsPtr.asFunction<
      ffi.Pointer<ffi.Float> Function(ffi.Pointer<llama_context>)>();

  /// Vocab
  ffi.Pointer<ffi.Char> llama_token_get_text(
    ffi.Pointer<llama_context> ctx,
    int token,
  ) {
    return _llama_token_get_text(
      ctx,
      token,
    );
  }

  late final _llama_token_get_textPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_context>,
              llama_token)>>('llama_token_get_text');
  late final _llama_token_get_text = _llama_token_get_textPtr.asFunction<
      ffi.Pointer<ffi.Char> Function(ffi.Pointer<llama_context>, int)>();

  double llama_token_get_score(
    ffi.Pointer<llama_context> ctx,
    int token,
  ) {
    return _llama_token_get_score(
      ctx,
      token,
    );
  }

  late final _llama_token_get_scorePtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(ffi.Pointer<llama_context>,
              llama_token)>>('llama_token_get_score');
  late final _llama_token_get_score = _llama_token_get_scorePtr
      .asFunction<double Function(ffi.Pointer<llama_context>, int)>();

  int llama_token_get_type(
    ffi.Pointer<llama_context> ctx,
    int token,
  ) {
    return _llama_token_get_type(
      ctx,
      token,
    );
  }

  late final _llama_token_get_typePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<llama_context>,
              llama_token)>>('llama_token_get_type');
  late final _llama_token_get_type = _llama_token_get_typePtr
      .asFunction<int Function(ffi.Pointer<llama_context>, int)>();

  /// Special tokens
  int llama_token_bos(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_token_bos(
      ctx,
    );
  }

  late final _llama_token_bosPtr = _lookup<
          ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_context>)>>(
      'llama_token_bos');
  late final _llama_token_bos = _llama_token_bosPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_token_eos(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_token_eos(
      ctx,
    );
  }

  late final _llama_token_eosPtr = _lookup<
          ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_context>)>>(
      'llama_token_eos');
  late final _llama_token_eos = _llama_token_eosPtr
      .asFunction<int Function(ffi.Pointer<llama_context>)>();

  int llama_token_nl(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_token_nl(
      ctx,
    );
  }

  late final _llama_token_nlPtr = _lookup<
          ffi.NativeFunction<llama_token Function(ffi.Pointer<llama_context>)>>(
      'llama_token_nl');
  late final _llama_token_nl =
      _llama_token_nlPtr.asFunction<int Function(ffi.Pointer<llama_context>)>();

  /// Convert the provided text into tokens.
  /// The tokens pointer must be large enough to hold the resulting tokens.
  /// Returns the number of tokens on success, no more than n_max_tokens
  /// Returns a negative number on failure - the number of tokens that would have been returned
  int llama_tokenize(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<ffi.Char> text,
    int text_len,
    ffi.Pointer<llama_token> tokens,
    int n_max_tokens,
    bool add_bos,
  ) {
    return _llama_tokenize(
      ctx,
      text,
      text_len,
      tokens,
      n_max_tokens,
      add_bos,
    );
  }

  late final _llama_tokenizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Pointer<llama_token>,
              ffi.Int,
              ffi.Bool)>>('llama_tokenize');
  late final _llama_tokenize = _llama_tokenizePtr.asFunction<
      int Function(ffi.Pointer<llama_context>, ffi.Pointer<ffi.Char>, int,
          ffi.Pointer<llama_token>, int, bool)>();

  int llama_tokenize_with_model(
    ffi.Pointer<llama_model> model,
    ffi.Pointer<ffi.Char> text,
    int text_len,
    ffi.Pointer<llama_token> tokens,
    int n_max_tokens,
    bool add_bos,
  ) {
    return _llama_tokenize_with_model(
      model,
      text,
      text_len,
      tokens,
      n_max_tokens,
      add_bos,
    );
  }

  late final _llama_tokenize_with_modelPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<llama_model>,
              ffi.Pointer<ffi.Char>,
              ffi.Int,
              ffi.Pointer<llama_token>,
              ffi.Int,
              ffi.Bool)>>('llama_tokenize_with_model');
  late final _llama_tokenize_with_model =
      _llama_tokenize_with_modelPtr.asFunction<
          int Function(ffi.Pointer<llama_model>, ffi.Pointer<ffi.Char>, int,
              ffi.Pointer<llama_token>, int, bool)>();

  /// Token Id -> Piece.
  /// Uses the vocabulary in the provided context.
  /// Does not write null terminator to the buffer.
  /// User code is responsible to remove the leading whitespace of the first non-BOS token when decoding multiple tokens.
  int llama_token_to_piece(
    ffi.Pointer<llama_context> ctx,
    int token,
    ffi.Pointer<ffi.Char> buf,
    int length,
  ) {
    return _llama_token_to_piece(
      ctx,
      token,
      buf,
      length,
    );
  }

  late final _llama_token_to_piecePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(ffi.Pointer<llama_context>, llama_token,
              ffi.Pointer<ffi.Char>, ffi.Int)>>('llama_token_to_piece');
  late final _llama_token_to_piece = _llama_token_to_piecePtr.asFunction<
      int Function(
          ffi.Pointer<llama_context>, int, ffi.Pointer<ffi.Char>, int)>();

  int llama_token_to_piece_with_model(
    ffi.Pointer<llama_model> model,
    int token,
    ffi.Pointer<ffi.Char> buf,
    int length,
  ) {
    return _llama_token_to_piece_with_model(
      model,
      token,
      buf,
      length,
    );
  }

  late final _llama_token_to_piece_with_modelPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<llama_model>,
              llama_token,
              ffi.Pointer<ffi.Char>,
              ffi.Int)>>('llama_token_to_piece_with_model');
  late final _llama_token_to_piece_with_model =
      _llama_token_to_piece_with_modelPtr.asFunction<
          int Function(
              ffi.Pointer<llama_model>, int, ffi.Pointer<ffi.Char>, int)>();

  /// Grammar
  ffi.Pointer<llama_grammar> llama_grammar_init(
    ffi.Pointer<ffi.Pointer<llama_grammar_element>> rules,
    int n_rules,
    int start_rule_index,
  ) {
    return _llama_grammar_init(
      rules,
      n_rules,
      start_rule_index,
    );
  }

  late final _llama_grammar_initPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<llama_grammar> Function(
              ffi.Pointer<ffi.Pointer<llama_grammar_element>>,
              ffi.Size,
              ffi.Size)>>('llama_grammar_init');
  late final _llama_grammar_init = _llama_grammar_initPtr.asFunction<
      ffi.Pointer<llama_grammar> Function(
          ffi.Pointer<ffi.Pointer<llama_grammar_element>>, int, int)>();

  void llama_grammar_free(
    ffi.Pointer<llama_grammar> grammar,
  ) {
    return _llama_grammar_free(
      grammar,
    );
  }

  late final _llama_grammar_freePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_grammar>)>>(
      'llama_grammar_free');
  late final _llama_grammar_free = _llama_grammar_freePtr
      .asFunction<void Function(ffi.Pointer<llama_grammar>)>();

  ffi.Pointer<llama_grammar> llama_grammar_copy(
    ffi.Pointer<llama_grammar> grammar,
  ) {
    return _llama_grammar_copy(
      grammar,
    );
  }

  late final _llama_grammar_copyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<llama_grammar> Function(
              ffi.Pointer<llama_grammar>)>>('llama_grammar_copy');
  late final _llama_grammar_copy = _llama_grammar_copyPtr.asFunction<
      ffi.Pointer<llama_grammar> Function(ffi.Pointer<llama_grammar>)>();

  /// @details Repetition penalty described in CTRL academic paper https://arxiv.org/abs/1909.05858, with negative logit fix.
  void llama_sample_repetition_penalty(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    ffi.Pointer<llama_token> last_tokens,
    int last_tokens_size,
    double penalty,
  ) {
    return _llama_sample_repetition_penalty(
      ctx,
      candidates,
      last_tokens,
      last_tokens_size,
      penalty,
    );
  }

  late final _llama_sample_repetition_penaltyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<llama_token>,
              ffi.Size,
              ffi.Float)>>('llama_sample_repetition_penalty');
  late final _llama_sample_repetition_penalty =
      _llama_sample_repetition_penaltyPtr.asFunction<
          void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<llama_token>,
              int,
              double)>();

  /// @details Frequency and presence penalties described in OpenAI API https://platform.openai.com/docs/api-reference/parameter-details.
  void llama_sample_frequency_and_presence_penalties(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    ffi.Pointer<llama_token> last_tokens,
    int last_tokens_size,
    double alpha_frequency,
    double alpha_presence,
  ) {
    return _llama_sample_frequency_and_presence_penalties(
      ctx,
      candidates,
      last_tokens,
      last_tokens_size,
      alpha_frequency,
      alpha_presence,
    );
  }

  late final _llama_sample_frequency_and_presence_penaltiesPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<llama_token>,
              ffi.Size,
              ffi.Float,
              ffi.Float)>>('llama_sample_frequency_and_presence_penalties');
  late final _llama_sample_frequency_and_presence_penalties =
      _llama_sample_frequency_and_presence_penaltiesPtr.asFunction<
          void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<llama_token>,
              int,
              double,
              double)>();

  /// @details Apply classifier-free guidance to the logits as described in academic paper "Stay on topic with Classifier-Free Guidance" https://arxiv.org/abs/2306.17806
  /// @param candidates A vector of `llama_token_data` containing the candidate tokens, the logits must be directly extracted from the original generation context without being sorted.
  /// @params guidance_ctx A separate context from the same model. Other than a negative prompt at the beginning, it should have all generated and user input tokens copied from the main context.
  /// @params scale Guidance strength. 1.0f means no guidance. Higher values mean stronger guidance.
  void llama_sample_classifier_free_guidance(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    ffi.Pointer<llama_context> guidance_ctx,
    double scale,
  ) {
    return _llama_sample_classifier_free_guidance(
      ctx,
      candidates,
      guidance_ctx,
      scale,
    );
  }

  late final _llama_sample_classifier_free_guidancePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<llama_context>,
              ffi.Float)>>('llama_sample_classifier_free_guidance');
  late final _llama_sample_classifier_free_guidance =
      _llama_sample_classifier_free_guidancePtr.asFunction<
          void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<llama_context>,
              double)>();

  /// @details Sorts candidate tokens by their logits in descending order and calculate probabilities based on logits.
  void llama_sample_softmax(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
  ) {
    return _llama_sample_softmax(
      ctx,
      candidates,
    );
  }

  late final _llama_sample_softmaxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>)>>('llama_sample_softmax');
  late final _llama_sample_softmax = _llama_sample_softmaxPtr.asFunction<
      void Function(
          ffi.Pointer<llama_context>, ffi.Pointer<llama_token_data_array>)>();

  /// @details Top-K sampling described in academic paper "The Curious Case of Neural Text Degeneration" https://arxiv.org/abs/1904.09751
  void llama_sample_top_k(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    int k,
    int min_keep,
  ) {
    return _llama_sample_top_k(
      ctx,
      candidates,
      k,
      min_keep,
    );
  }

  late final _llama_sample_top_kPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Int,
              ffi.Size)>>('llama_sample_top_k');
  late final _llama_sample_top_k = _llama_sample_top_kPtr.asFunction<
      void Function(ffi.Pointer<llama_context>,
          ffi.Pointer<llama_token_data_array>, int, int)>();

  /// @details Nucleus sampling described in academic paper "The Curious Case of Neural Text Degeneration" https://arxiv.org/abs/1904.09751
  void llama_sample_top_p(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double p,
    int min_keep,
  ) {
    return _llama_sample_top_p(
      ctx,
      candidates,
      p,
      min_keep,
    );
  }

  late final _llama_sample_top_pPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float,
              ffi.Size)>>('llama_sample_top_p');
  late final _llama_sample_top_p = _llama_sample_top_pPtr.asFunction<
      void Function(ffi.Pointer<llama_context>,
          ffi.Pointer<llama_token_data_array>, double, int)>();

  /// @details Tail Free Sampling described in https://www.trentonbricken.com/Tail-Free-Sampling/.
  void llama_sample_tail_free(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double z,
    int min_keep,
  ) {
    return _llama_sample_tail_free(
      ctx,
      candidates,
      z,
      min_keep,
    );
  }

  late final _llama_sample_tail_freePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float,
              ffi.Size)>>('llama_sample_tail_free');
  late final _llama_sample_tail_free = _llama_sample_tail_freePtr.asFunction<
      void Function(ffi.Pointer<llama_context>,
          ffi.Pointer<llama_token_data_array>, double, int)>();

  /// @details Locally Typical Sampling implementation described in the paper https://arxiv.org/abs/2202.00666.
  void llama_sample_typical(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double p,
    int min_keep,
  ) {
    return _llama_sample_typical(
      ctx,
      candidates,
      p,
      min_keep,
    );
  }

  late final _llama_sample_typicalPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float,
              ffi.Size)>>('llama_sample_typical');
  late final _llama_sample_typical = _llama_sample_typicalPtr.asFunction<
      void Function(ffi.Pointer<llama_context>,
          ffi.Pointer<llama_token_data_array>, double, int)>();

  void llama_sample_temperature(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double temp,
  ) {
    return _llama_sample_temperature(
      ctx,
      candidates,
      temp,
    );
  }

  late final _llama_sample_temperaturePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float)>>('llama_sample_temperature');
  late final _llama_sample_temperature =
      _llama_sample_temperaturePtr.asFunction<
          void Function(ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>, double)>();

  /// @details Apply constraints from grammar
  void llama_sample_grammar(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    ffi.Pointer<llama_grammar> grammar,
  ) {
    return _llama_sample_grammar(
      ctx,
      candidates,
      grammar,
    );
  }

  late final _llama_sample_grammarPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Pointer<llama_grammar>)>>('llama_sample_grammar');
  late final _llama_sample_grammar = _llama_sample_grammarPtr.asFunction<
      void Function(ffi.Pointer<llama_context>,
          ffi.Pointer<llama_token_data_array>, ffi.Pointer<llama_grammar>)>();

  /// @details Mirostat 1.0 algorithm described in the paper https://arxiv.org/abs/2007.14966. Uses tokens instead of words.
  /// @param candidates A vector of `llama_token_data` containing the candidate tokens, their probabilities (p), and log-odds (logit) for the current position in the generated text.
  /// @param tau  The target cross-entropy (or surprise) value you want to achieve for the generated text. A higher value corresponds to more surprising or less predictable text, while a lower value corresponds to less surprising or more predictable text.
  /// @param eta The learning rate used to update `mu` based on the error between the target and observed surprisal of the sampled word. A larger learning rate will cause `mu` to be updated more quickly, while a smaller learning rate will result in slower updates.
  /// @param m The number of tokens considered in the estimation of `s_hat`. This is an arbitrary value that is used to calculate `s_hat`, which in turn helps to calculate the value of `k`. In the paper, they use `m = 100`, but you can experiment with different values to see how it affects the performance of the algorithm.
  /// @param mu Maximum cross-entropy. This value is initialized to be twice the target cross-entropy (`2 * tau`) and is updated in the algorithm based on the error between the target and observed surprisal.
  int llama_sample_token_mirostat(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double tau,
    double eta,
    int m,
    ffi.Pointer<ffi.Float> mu,
  ) {
    return _llama_sample_token_mirostat(
      ctx,
      candidates,
      tau,
      eta,
      m,
      mu,
    );
  }

  late final _llama_sample_token_mirostatPtr = _lookup<
      ffi.NativeFunction<
          llama_token Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float,
              ffi.Float,
              ffi.Int,
              ffi.Pointer<ffi.Float>)>>('llama_sample_token_mirostat');
  late final _llama_sample_token_mirostat =
      _llama_sample_token_mirostatPtr.asFunction<
          int Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              double,
              double,
              int,
              ffi.Pointer<ffi.Float>)>();

  /// @details Mirostat 2.0 algorithm described in the paper https://arxiv.org/abs/2007.14966. Uses tokens instead of words.
  /// @param candidates A vector of `llama_token_data` containing the candidate tokens, their probabilities (p), and log-odds (logit) for the current position in the generated text.
  /// @param tau  The target cross-entropy (or surprise) value you want to achieve for the generated text. A higher value corresponds to more surprising or less predictable text, while a lower value corresponds to less surprising or more predictable text.
  /// @param eta The learning rate used to update `mu` based on the error between the target and observed surprisal of the sampled word. A larger learning rate will cause `mu` to be updated more quickly, while a smaller learning rate will result in slower updates.
  /// @param mu Maximum cross-entropy. This value is initialized to be twice the target cross-entropy (`2 * tau`) and is updated in the algorithm based on the error between the target and observed surprisal.
  int llama_sample_token_mirostat_v2(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
    double tau,
    double eta,
    ffi.Pointer<ffi.Float> mu,
  ) {
    return _llama_sample_token_mirostat_v2(
      ctx,
      candidates,
      tau,
      eta,
      mu,
    );
  }

  late final _llama_sample_token_mirostat_v2Ptr = _lookup<
      ffi.NativeFunction<
          llama_token Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              ffi.Float,
              ffi.Float,
              ffi.Pointer<ffi.Float>)>>('llama_sample_token_mirostat_v2');
  late final _llama_sample_token_mirostat_v2 =
      _llama_sample_token_mirostat_v2Ptr.asFunction<
          int Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>,
              double,
              double,
              ffi.Pointer<ffi.Float>)>();

  /// @details Selects the token with the highest probability.
  int llama_sample_token_greedy(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
  ) {
    return _llama_sample_token_greedy(
      ctx,
      candidates,
    );
  }

  late final _llama_sample_token_greedyPtr = _lookup<
          ffi.NativeFunction<
              llama_token Function(ffi.Pointer<llama_context>,
                  ffi.Pointer<llama_token_data_array>)>>(
      'llama_sample_token_greedy');
  late final _llama_sample_token_greedy =
      _llama_sample_token_greedyPtr.asFunction<
          int Function(ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>)>();

  /// @details Randomly selects a token from the candidates based on their probabilities.
  int llama_sample_token(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_token_data_array> candidates,
  ) {
    return _llama_sample_token(
      ctx,
      candidates,
    );
  }

  late final _llama_sample_tokenPtr = _lookup<
      ffi.NativeFunction<
          llama_token Function(ffi.Pointer<llama_context>,
              ffi.Pointer<llama_token_data_array>)>>('llama_sample_token');
  late final _llama_sample_token = _llama_sample_tokenPtr.asFunction<
      int Function(
          ffi.Pointer<llama_context>, ffi.Pointer<llama_token_data_array>)>();

  /// @details Accepts the sampled token into the grammar
  void llama_grammar_accept_token(
    ffi.Pointer<llama_context> ctx,
    ffi.Pointer<llama_grammar> grammar,
    int token,
  ) {
    return _llama_grammar_accept_token(
      ctx,
      grammar,
      token,
    );
  }

  late final _llama_grammar_accept_tokenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              ffi.Pointer<llama_grammar>,
              llama_token)>>('llama_grammar_accept_token');
  late final _llama_grammar_accept_token =
      _llama_grammar_accept_tokenPtr.asFunction<
          void Function(
              ffi.Pointer<llama_context>, ffi.Pointer<llama_grammar>, int)>();

  /// @details Deterministically returns entire sentence constructed by a beam search.
  /// @param ctx Pointer to the llama_context.
  /// @param callback Invoked for each iteration of the beam_search loop, passing in beams_state.
  /// @param callback_data A pointer that is simply passed back to callback.
  /// @param n_beams Number of beams to use.
  /// @param n_past Number of tokens already evaluated.
  /// @param n_predict Maximum number of tokens to predict. EOS may occur earlier.
  /// @param n_threads Number of threads as passed to llama_eval().
  void llama_beam_search(
    ffi.Pointer<llama_context> ctx,
    llama_beam_search_callback_fn_t callback,
    ffi.Pointer<ffi.Void> callback_data,
    int n_beams,
    int n_past,
    int n_predict,
    int n_threads,
  ) {
    return _llama_beam_search(
      ctx,
      callback,
      callback_data,
      n_beams,
      n_past,
      n_predict,
      n_threads,
    );
  }

  late final _llama_beam_searchPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<llama_context>,
              llama_beam_search_callback_fn_t,
              ffi.Pointer<ffi.Void>,
              ffi.Size,
              ffi.Int,
              ffi.Int,
              ffi.Int)>>('llama_beam_search');
  late final _llama_beam_search = _llama_beam_searchPtr.asFunction<
      void Function(ffi.Pointer<llama_context>, llama_beam_search_callback_fn_t,
          ffi.Pointer<ffi.Void>, int, int, int, int)>();

  /// Performance information
  llama_timings llama_get_timings(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_get_timings(
      ctx,
    );
  }

  late final _llama_get_timingsPtr = _lookup<
          ffi
          .NativeFunction<llama_timings Function(ffi.Pointer<llama_context>)>>(
      'llama_get_timings');
  late final _llama_get_timings = _llama_get_timingsPtr
      .asFunction<llama_timings Function(ffi.Pointer<llama_context>)>();

  void llama_print_timings(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_print_timings(
      ctx,
    );
  }

  late final _llama_print_timingsPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>>(
      'llama_print_timings');
  late final _llama_print_timings = _llama_print_timingsPtr
      .asFunction<void Function(ffi.Pointer<llama_context>)>();

  void llama_reset_timings(
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_reset_timings(
      ctx,
    );
  }

  late final _llama_reset_timingsPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<llama_context>)>>(
      'llama_reset_timings');
  late final _llama_reset_timings = _llama_reset_timingsPtr
      .asFunction<void Function(ffi.Pointer<llama_context>)>();

  /// Print system information
  ffi.Pointer<ffi.Char> llama_print_system_info() {
    return _llama_print_system_info();
  }

  late final _llama_print_system_infoPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Char> Function()>>(
          'llama_print_system_info');
  late final _llama_print_system_info = _llama_print_system_infoPtr
      .asFunction<ffi.Pointer<ffi.Char> Function()>();

  /// Set callback for all future logging events.
  /// If this is not called, or NULL is supplied, everything is output on stderr.
  void llama_log_set(
    llama_log_callback log_callback,
    ffi.Pointer<ffi.Void> user_data,
  ) {
    return _llama_log_set(
      log_callback,
      user_data,
    );
  }

  late final _llama_log_setPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              llama_log_callback, ffi.Pointer<ffi.Void>)>>('llama_log_set');
  late final _llama_log_set = _llama_log_setPtr
      .asFunction<void Function(llama_log_callback, ffi.Pointer<ffi.Void>)>();

  void llama_dump_timing_info_yaml(
    ffi.Pointer<FILE> stream,
    ffi.Pointer<llama_context> ctx,
  ) {
    return _llama_dump_timing_info_yaml(
      stream,
      ctx,
    );
  }

  late final _llama_dump_timing_info_yamlPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<FILE>,
              ffi.Pointer<llama_context>)>>('llama_dump_timing_info_yaml');
  late final _llama_dump_timing_info_yaml =
      _llama_dump_timing_info_yamlPtr.asFunction<
          void Function(ffi.Pointer<FILE>, ffi.Pointer<llama_context>)>();
}

/// mbstate_t is an opaque object to keep conversion state, during multibyte
/// stream conversions.  The content must not be referenced by user programs.
final class __mbstate_t extends ffi.Union {
  @ffi.Array.multi([128])
  external ffi.Array<ffi.Char> __mbstate8;

  /// for alignment
  @ffi.LongLong()
  external int _mbstateL;
}

final class __darwin_pthread_handler_rec extends ffi.Struct {
  /// Routine to call
  external ffi
      .Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>
      __routine;

  /// Argument to pass
  external ffi.Pointer<ffi.Void> __arg;

  external ffi.Pointer<__darwin_pthread_handler_rec> __next;
}

final class _opaque_pthread_attr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([56])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_cond_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([40])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_condattr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_mutex_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([56])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_mutexattr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_once_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_rwlock_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([192])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_rwlockattr_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Char> __opaque;
}

final class _opaque_pthread_t extends ffi.Struct {
  @ffi.Long()
  external int __sig;

  external ffi.Pointer<__darwin_pthread_handler_rec> __cleanup_stack;

  @ffi.Array.multi([8176])
  external ffi.Array<ffi.Char> __opaque;
}

/// ggml object
final class ggml_object extends ffi.Struct {
  @ffi.Size()
  external int offs;

  @ffi.Size()
  external int size;

  external ffi.Pointer<ggml_object> next;

  @ffi.Int32()
  external int type;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Char> padding;
}

abstract class ggml_object_type {
  static const int GGML_OBJECT_TENSOR = 0;
  static const int GGML_OBJECT_GRAPH = 1;
  static const int GGML_OBJECT_WORK_BUFFER = 2;
}

final class ggml_context extends ffi.Opaque {}

abstract class ggml_type {
  static const int GGML_TYPE_F32 = 0;
  static const int GGML_TYPE_F16 = 1;
  static const int GGML_TYPE_Q4_0 = 2;
  static const int GGML_TYPE_Q4_1 = 3;

  /// GGML_TYPE_Q4_2 = 4, support has been removed
  /// GGML_TYPE_Q4_3 (5) support has been removed
  static const int GGML_TYPE_Q5_0 = 6;
  static const int GGML_TYPE_Q5_1 = 7;
  static const int GGML_TYPE_Q8_0 = 8;
  static const int GGML_TYPE_Q8_1 = 9;

  /// k-quantizations
  static const int GGML_TYPE_Q2_K = 10;
  static const int GGML_TYPE_Q3_K = 11;
  static const int GGML_TYPE_Q4_K = 12;
  static const int GGML_TYPE_Q5_K = 13;
  static const int GGML_TYPE_Q6_K = 14;
  static const int GGML_TYPE_Q8_K = 15;
  static const int GGML_TYPE_I8 = 16;
  static const int GGML_TYPE_I16 = 17;
  static const int GGML_TYPE_I32 = 18;
  static const int GGML_TYPE_COUNT = 19;
}

abstract class ggml_backend {
  static const int GGML_BACKEND_CPU = 0;
  static const int GGML_BACKEND_GPU = 10;
  static const int GGML_BACKEND_GPU_SPLIT = 20;
}

/// model file types
abstract class ggml_ftype {
  static const int GGML_FTYPE_UNKNOWN = -1;
  static const int GGML_FTYPE_ALL_F32 = 0;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_F16 = 1;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q4_0 = 2;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q4_1 = 3;

  /// tok_embeddings.weight and output.weight are F16
  static const int GGML_FTYPE_MOSTLY_Q4_1_SOME_F16 = 4;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q8_0 = 7;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q5_0 = 8;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q5_1 = 9;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q2_K = 10;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q3_K = 11;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q4_K = 12;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q5_K = 13;

  /// except 1d tensors
  static const int GGML_FTYPE_MOSTLY_Q6_K = 14;
}

/// available tensor operations:
abstract class ggml_op {
  static const int GGML_OP_NONE = 0;
  static const int GGML_OP_DUP = 1;
  static const int GGML_OP_ADD = 2;
  static const int GGML_OP_ADD1 = 3;
  static const int GGML_OP_ACC = 4;
  static const int GGML_OP_SUB = 5;
  static const int GGML_OP_MUL = 6;
  static const int GGML_OP_DIV = 7;
  static const int GGML_OP_SQR = 8;
  static const int GGML_OP_SQRT = 9;
  static const int GGML_OP_LOG = 10;
  static const int GGML_OP_SUM = 11;
  static const int GGML_OP_SUM_ROWS = 12;
  static const int GGML_OP_MEAN = 13;
  static const int GGML_OP_ARGMAX = 14;
  static const int GGML_OP_REPEAT = 15;
  static const int GGML_OP_REPEAT_BACK = 16;
  static const int GGML_OP_CONCAT = 17;
  static const int GGML_OP_SILU_BACK = 18;

  /// normalize
  static const int GGML_OP_NORM = 19;
  static const int GGML_OP_RMS_NORM = 20;
  static const int GGML_OP_RMS_NORM_BACK = 21;
  static const int GGML_OP_GROUP_NORM = 22;
  static const int GGML_OP_MUL_MAT = 23;
  static const int GGML_OP_OUT_PROD = 24;
  static const int GGML_OP_SCALE = 25;
  static const int GGML_OP_SET = 26;
  static const int GGML_OP_CPY = 27;
  static const int GGML_OP_CONT = 28;
  static const int GGML_OP_RESHAPE = 29;
  static const int GGML_OP_VIEW = 30;
  static const int GGML_OP_PERMUTE = 31;
  static const int GGML_OP_TRANSPOSE = 32;
  static const int GGML_OP_GET_ROWS = 33;
  static const int GGML_OP_GET_ROWS_BACK = 34;
  static const int GGML_OP_DIAG = 35;
  static const int GGML_OP_DIAG_MASK_INF = 36;
  static const int GGML_OP_DIAG_MASK_ZERO = 37;
  static const int GGML_OP_SOFT_MAX = 38;
  static const int GGML_OP_SOFT_MAX_BACK = 39;
  static const int GGML_OP_ROPE = 40;
  static const int GGML_OP_ROPE_BACK = 41;
  static const int GGML_OP_ALIBI = 42;
  static const int GGML_OP_CLAMP = 43;
  static const int GGML_OP_CONV_1D = 44;
  static const int GGML_OP_CONV_2D = 45;
  static const int GGML_OP_CONV_TRANSPOSE_2D = 46;
  static const int GGML_OP_POOL_1D = 47;
  static const int GGML_OP_POOL_2D = 48;

  /// nearest interpolate
  static const int GGML_OP_UPSCALE = 49;
  static const int GGML_OP_FLASH_ATTN = 50;
  static const int GGML_OP_FLASH_FF = 51;
  static const int GGML_OP_FLASH_ATTN_BACK = 52;
  static const int GGML_OP_WIN_PART = 53;
  static const int GGML_OP_WIN_UNPART = 54;
  static const int GGML_OP_GET_REL_POS = 55;
  static const int GGML_OP_ADD_REL_POS = 56;
  static const int GGML_OP_UNARY = 57;
  static const int GGML_OP_MAP_UNARY = 58;
  static const int GGML_OP_MAP_BINARY = 59;
  static const int GGML_OP_MAP_CUSTOM1_F32 = 60;
  static const int GGML_OP_MAP_CUSTOM2_F32 = 61;
  static const int GGML_OP_MAP_CUSTOM3_F32 = 62;
  static const int GGML_OP_MAP_CUSTOM1 = 63;
  static const int GGML_OP_MAP_CUSTOM2 = 64;
  static const int GGML_OP_MAP_CUSTOM3 = 65;
  static const int GGML_OP_CROSS_ENTROPY_LOSS = 66;
  static const int GGML_OP_CROSS_ENTROPY_LOSS_BACK = 67;
  static const int GGML_OP_COUNT = 68;
}

abstract class ggml_unary_op {
  static const int GGML_UNARY_OP_ABS = 0;
  static const int GGML_UNARY_OP_SGN = 1;
  static const int GGML_UNARY_OP_NEG = 2;
  static const int GGML_UNARY_OP_STEP = 3;
  static const int GGML_UNARY_OP_TANH = 4;
  static const int GGML_UNARY_OP_ELU = 5;
  static const int GGML_UNARY_OP_RELU = 6;
  static const int GGML_UNARY_OP_GELU = 7;
  static const int GGML_UNARY_OP_GELU_QUICK = 8;
  static const int GGML_UNARY_OP_SILU = 9;
}

/// n-dimensional tensor
final class ggml_tensor extends ffi.Struct {
  @ffi.Int32()
  external int type;

  @ffi.Int32()
  external int backend;

  @ffi.Int()
  external int n_dims;

  /// number of elements
  @ffi.Array.multi([4])
  external ffi.Array<ffi.Int64> ne;

  /// stride in bytes:
  /// nb[0] = sizeof(type)
  /// nb[1] = nb[0]   * ne[0] + padding
  /// nb[i] = nb[i-1] * ne[i-1]
  @ffi.Array.multi([4])
  external ffi.Array<ffi.Size> nb;

  /// compute data
  @ffi.Int32()
  external int op;

  /// op params - allocated as int32_t for alignment
  @ffi.Array.multi([8])
  external ffi.Array<ffi.Int32> op_params;

  @ffi.Bool()
  external bool is_param;

  external ffi.Pointer<ggml_tensor> grad;

  @ffi.Array.multi([6])
  external ffi.Array<ffi.Pointer<ggml_tensor>> src;

  /// performance
  @ffi.Int()
  external int perf_runs;

  @ffi.Int64()
  external int perf_cycles;

  @ffi.Int64()
  external int perf_time_us;

  external ffi.Pointer<ggml_tensor> view_src;

  @ffi.Size()
  external int view_offs;

  external ffi.Pointer<ffi.Void> data;

  @ffi.Array.multi([64])
  external ffi.Array<ffi.Char> name;

  /// extra things e.g. for ggml-cuda.cu
  external ffi.Pointer<ffi.Void> extra;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Char> padding;
}

/// the compute plan that needs to be prepared for ggml_graph_compute()
/// since https://github.com/ggerganov/ggml/issues/287
final class ggml_cplan extends ffi.Struct {
  /// size of work buffer, calculated by `ggml_graph_plan()`
  @ffi.Size()
  external int work_size;

  /// work buffer, to be allocated by caller before calling to `ggml_graph_compute()`
  external ffi.Pointer<ffi.Uint8> work_data;

  @ffi.Int()
  external int n_threads;

  /// the `n_tasks` of nodes, 1:1 mapping to cgraph nodes
  @ffi.Array.multi([4096])
  external ffi.Array<ffi.Int> n_tasks;

  /// abort ggml_graph_compute when true
  external ffi.Pointer<
          ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ffi.Void> data)>>
      abort_callback;

  external ffi.Pointer<ffi.Void> abort_callback_data;
}

/// computation graph
final class ggml_cgraph extends ffi.Struct {
  @ffi.Int()
  external int n_nodes;

  @ffi.Int()
  external int n_leafs;

  @ffi.Array.multi([4096])
  external ffi.Array<ffi.Pointer<ggml_tensor>> nodes;

  @ffi.Array.multi([4096])
  external ffi.Array<ffi.Pointer<ggml_tensor>> grads;

  @ffi.Array.multi([4096])
  external ffi.Array<ffi.Pointer<ggml_tensor>> leafs;

  @ffi.Array.multi([8273])
  external ffi.Array<ffi.Pointer<ffi.Void>> visited_hash_table;

  /// performance
  @ffi.Int()
  external int perf_runs;

  @ffi.Int64()
  external int perf_cycles;

  @ffi.Int64()
  external int perf_time_us;
}

/// scratch buffer
final class ggml_scratch extends ffi.Struct {
  @ffi.Size()
  external int offs;

  @ffi.Size()
  external int size;

  external ffi.Pointer<ffi.Void> data;
}

final class ggml_init_params extends ffi.Struct {
  /// bytes
  @ffi.Size()
  external int mem_size;

  /// if NULL, memory will be allocated internally
  external ffi.Pointer<ffi.Void> mem_buffer;

  /// don't allocate memory for the tensor data
  @ffi.Bool()
  external bool no_alloc;
}

/// NOTE: the INIT or FINALIZE pass is not scheduled unless explicitly enabled.
/// This behavior was changed since https://github.com/ggerganov/llama.cpp/pull/1995.
abstract class ggml_task_type {
  static const int GGML_TASK_INIT = 0;
  static const int GGML_TASK_COMPUTE = 1;
  static const int GGML_TASK_FINALIZE = 2;
}

final class ggml_compute_params extends ffi.Struct {
  @ffi.Int32()
  external int type;

  /// ith = thread index, nth = number of threads
  @ffi.Int()
  external int ith;

  @ffi.Int()
  external int nth;

  /// work buffer for all threads
  @ffi.Size()
  external int wsize;

  external ffi.Pointer<ffi.Void> wdata;
}

abstract class ggml_op_pool {
  static const int GGML_OP_POOL_MAX = 0;
  static const int GGML_OP_POOL_AVG = 1;
  static const int GGML_OP_POOL_COUNT = 2;
}

/// custom operators
typedef ggml_unary_op_f32_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Int, ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Float>)>>;
typedef ggml_binary_op_f32_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Int, ffi.Pointer<ffi.Float>,
            ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Float>)>>;
typedef ggml_custom1_op_f32_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>;
typedef ggml_custom2_op_f32_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>,
            ffi.Pointer<ggml_tensor>)>>;
typedef ggml_custom3_op_f32_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>,
            ffi.Pointer<ggml_tensor>, ffi.Pointer<ggml_tensor>)>>;

/// custom operators v2
typedef ggml_custom1_op_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ggml_tensor> dst,
            ffi.Pointer<ggml_tensor> a,
            ffi.Int ith,
            ffi.Int nth,
            ffi.Pointer<ffi.Void> userdata)>>;
typedef ggml_custom2_op_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ggml_tensor> dst,
            ffi.Pointer<ggml_tensor> a,
            ffi.Pointer<ggml_tensor> b,
            ffi.Int ith,
            ffi.Int nth,
            ffi.Pointer<ffi.Void> userdata)>>;
typedef ggml_custom3_op_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ggml_tensor> dst,
            ffi.Pointer<ggml_tensor> a,
            ffi.Pointer<ggml_tensor> b,
            ffi.Pointer<ggml_tensor> c,
            ffi.Int ith,
            ffi.Int nth,
            ffi.Pointer<ffi.Void> userdata)>>;

/// optimization methods
abstract class ggml_opt_type {
  static const int GGML_OPT_ADAM = 0;
  static const int GGML_OPT_LBFGS = 1;
}

/// linesearch methods
abstract class ggml_linesearch {
  static const int GGML_LINESEARCH_DEFAULT = 1;
  static const int GGML_LINESEARCH_BACKTRACKING_ARMIJO = 0;
  static const int GGML_LINESEARCH_BACKTRACKING_WOLFE = 1;
  static const int GGML_LINESEARCH_BACKTRACKING_STRONG_WOLFE = 2;
}

/// optimization return values
abstract class ggml_opt_result {
  static const int GGML_OPT_OK = 0;
  static const int GGML_OPT_DID_NOT_CONVERGE = 1;
  static const int GGML_OPT_NO_CONTEXT = 2;
  static const int GGML_OPT_INVALID_WOLFE = 3;
  static const int GGML_OPT_FAIL = 4;
  static const int GGML_LINESEARCH_FAIL = -128;
  static const int GGML_LINESEARCH_MINIMUM_STEP = -127;
  static const int GGML_LINESEARCH_MAXIMUM_STEP = -126;
  static const int GGML_LINESEARCH_MAXIMUM_ITERATIONS = -125;
  static const int GGML_LINESEARCH_INVALID_PARAMETERS = -124;
}

/// optimization parameters
///
/// see ggml.c (ggml_opt_default_params) for default values
final class ggml_opt_params extends ffi.Struct {
  @ffi.Int32()
  external int type;

  @ffi.Int()
  external int n_threads;

  /// delta-based convergence test
  ///
  /// if past == 0 - disabled
  /// if past > 0:
  /// stop if |f(x) - f(x_past)| < delta * max(1, |f(x)|)
  @ffi.Int()
  external int past;

  @ffi.Float()
  external double delta;

  /// maximum number of iterations without improvement
  ///
  /// if 0 - disabled
  /// if > 0:
  /// assume convergence if no cost improvement in this number of iterations
  @ffi.Int()
  external int max_no_improvement;

  @ffi.Bool()
  external bool print_forward_graph;

  @ffi.Bool()
  external bool print_backward_graph;

  external UnnamedStruct1 adam;

  external UnnamedStruct2 lbfgs;
}

/// ADAM parameters
final class UnnamedStruct1 extends ffi.Struct {
  @ffi.Int()
  external int n_iter;

  /// schedule multiplier (fixed, decay or warmup)
  @ffi.Float()
  external double sched;

  /// weight decay for AdamW, use 0.0f to disable
  @ffi.Float()
  external double decay;

  /// minimum number of tensor dimension to apply weight decay
  @ffi.Int()
  external int decay_min_ndim;

  /// learning rate
  @ffi.Float()
  external double alpha;

  @ffi.Float()
  external double beta1;

  @ffi.Float()
  external double beta2;

  /// epsilon for numerical stability
  @ffi.Float()
  external double eps;

  /// epsilon for convergence test
  @ffi.Float()
  external double eps_f;

  /// epsilon for convergence test
  @ffi.Float()
  external double eps_g;

  /// gradient clipping
  @ffi.Float()
  external double gclip;
}

/// LBFGS parameters
final class UnnamedStruct2 extends ffi.Struct {
  /// number of corrections to approximate the inv. Hessian
  @ffi.Int()
  external int m;

  @ffi.Int()
  external int n_iter;

  @ffi.Int()
  external int max_linesearch;

  /// convergence tolerance
  @ffi.Float()
  external double eps;

  /// line search tolerance
  @ffi.Float()
  external double ftol;

  @ffi.Float()
  external double wolfe;

  @ffi.Float()
  external double min_step;

  @ffi.Float()
  external double max_step;

  @ffi.Int32()
  external int linesearch;
}

final class ggml_opt_context extends ffi.Struct {
  external ffi.Pointer<ggml_context> ctx;

  external ggml_opt_params params;

  @ffi.Int()
  external int iter;

  /// number of parameter elements
  @ffi.Int64()
  external int nx;

  @ffi.Bool()
  external bool just_initialized;

  @ffi.Float()
  external double loss_before;

  @ffi.Float()
  external double loss_after;

  external UnnamedStruct3 adam;

  external UnnamedStruct4 lbfgs;
}

final class UnnamedStruct3 extends ffi.Struct {
  /// first moment
  external ffi.Pointer<ggml_tensor> m;

  /// second moment
  external ffi.Pointer<ggml_tensor> v;

  /// past function values
  external ffi.Pointer<ggml_tensor> pf;

  @ffi.Float()
  external double fx_best;

  @ffi.Float()
  external double fx_prev;

  @ffi.Int()
  external int n_no_improvement;
}

final class UnnamedStruct4 extends ffi.Struct {
  /// current parameters
  external ffi.Pointer<ggml_tensor> x;

  /// previous parameters
  external ffi.Pointer<ggml_tensor> xp;

  /// current gradient
  external ffi.Pointer<ggml_tensor> g;

  /// previous gradient
  external ffi.Pointer<ggml_tensor> gp;

  /// search direction
  external ffi.Pointer<ggml_tensor> d;

  /// past function values
  external ffi.Pointer<ggml_tensor> pf;

  /// the L-BFGS memory alpha
  external ffi.Pointer<ggml_tensor> lmal;

  /// the L-BFGS memory ys
  external ffi.Pointer<ggml_tensor> lmys;

  /// the L-BFGS memory s
  external ffi.Pointer<ggml_tensor> lms;

  /// the L-BFGS memory y
  external ffi.Pointer<ggml_tensor> lmy;

  @ffi.Float()
  external double fx_best;

  @ffi.Float()
  external double step;

  @ffi.Int()
  external int j;

  @ffi.Int()
  external int k;

  @ffi.Int()
  external int end;

  @ffi.Int()
  external int n_no_improvement;
}

typedef ggml_opt_callback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ffi.Void> data, ffi.Pointer<ffi.Float> sched)>>;

/// gguf
abstract class gguf_type {
  static const int GGUF_TYPE_UINT8 = 0;
  static const int GGUF_TYPE_INT8 = 1;
  static const int GGUF_TYPE_UINT16 = 2;
  static const int GGUF_TYPE_INT16 = 3;
  static const int GGUF_TYPE_UINT32 = 4;
  static const int GGUF_TYPE_INT32 = 5;
  static const int GGUF_TYPE_FLOAT32 = 6;
  static const int GGUF_TYPE_BOOL = 7;
  static const int GGUF_TYPE_STRING = 8;
  static const int GGUF_TYPE_ARRAY = 9;
  static const int GGUF_TYPE_UINT64 = 10;
  static const int GGUF_TYPE_INT64 = 11;
  static const int GGUF_TYPE_FLOAT64 = 12;

  /// marks the end of the enum
  static const int GGUF_TYPE_COUNT = 13;
}

final class gguf_context extends ffi.Opaque {}

final class gguf_init_params extends ffi.Struct {
  @ffi.Bool()
  external bool no_alloc;

  /// if not NULL, create a ggml_context and allocate the tensor data in it
  external ffi.Pointer<ffi.Pointer<ggml_context>> ctx;
}

final class ggml_type_traits_t extends ffi.Struct {
  external ffi.Pointer<ffi.Char> type_name;

  @ffi.Int()
  external int blck_size;

  @ffi.Size()
  external int type_size;

  @ffi.Bool()
  external bool is_quantized;

  external ggml_to_float_t to_float;

  external ggml_from_float_t from_float;

  external ggml_from_float_t from_float_reference;

  external ggml_vec_dot_t vec_dot;

  @ffi.Int32()
  external int vec_dot_type;
}

typedef ggml_to_float_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ffi.Void> x, ffi.Pointer<ffi.Float> y, ffi.Int k)>>;
typedef ggml_from_float_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ffi.Float> x, ffi.Pointer<ffi.Void> y, ffi.Int k)>>;
typedef ggml_vec_dot_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Int n, ffi.Pointer<ffi.Float> s,
            ffi.Pointer<ffi.Void> x, ffi.Pointer<ffi.Void> y)>>;

/// stdio buffers
final class __sbuf extends ffi.Struct {
  external ffi.Pointer<ffi.UnsignedChar> _base;

  @ffi.Int()
  external int _size;
}

/// hold a buncha junk that would grow the ABI
final class __sFILEX extends ffi.Opaque {}

/// stdio state variables.
///
/// The following always hold:
///
/// if (_flags&(__SLBF|__SWR)) == (__SLBF|__SWR),
/// _lbfsize is -_bf._size, else _lbfsize is 0
/// if _flags&__SRD, _w is 0
/// if _flags&__SWR, _r is 0
///
/// This ensures that the getc and putc macros (or inline functions) never
/// try to write or read from a file that is in `read' or `write' mode.
/// (Moreover, they can, and do, automatically switch from read mode to
/// write mode, and back, on "r+" and "w+" files.)
///
/// _lbfsize is used only to make the inline line-buffered output stream
/// code as compact as possible.
///
/// _ub, _up, and _ur are used when ungetc() pushes back more characters
/// than fit in the current _bf, or when ungetc() pushes back a character
/// that does not match the previous one in _bf.  When this happens,
/// _ub._base becomes non-nil (i.e., a stream has ungetc() data iff
/// _ub._base!=NULL) and _up and _ur save the current values of _p and _r.
///
/// NB: see WARNING above before changing the layout of this structure!
final class __sFILE extends ffi.Struct {
  /// current position in (some) buffer
  external ffi.Pointer<ffi.UnsignedChar> _p;

  /// read space left for getc()
  @ffi.Int()
  external int _r;

  /// write space left for putc()
  @ffi.Int()
  external int _w;

  /// flags, below; this FILE is free if 0
  @ffi.Short()
  external int _flags;

  /// fileno, if Unix descriptor, else -1
  @ffi.Short()
  external int _file;

  /// the buffer (at least 1 byte, if !NULL)
  external __sbuf _bf;

  /// 0 or -_bf._size, for inline putc
  @ffi.Int()
  external int _lbfsize;

  /// cookie passed to io functions
  external ffi.Pointer<ffi.Void> _cookie;

  external ffi
      .Pointer<ffi.NativeFunction<ffi.Int Function(ffi.Pointer<ffi.Void>)>>
      _close;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>> _read;

  external ffi.Pointer<
      ffi.NativeFunction<
          fpos_t Function(ffi.Pointer<ffi.Void>, fpos_t, ffi.Int)>> _seek;

  external ffi.Pointer<
      ffi.NativeFunction<
          ffi.Int Function(
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>, ffi.Int)>> _write;

  /// ungetc buffer
  external __sbuf _ub;

  /// additions to FILE to not break ABI
  external ffi.Pointer<__sFILEX> _extra;

  /// saved _r when _r is counting ungetc data
  @ffi.Int()
  external int _ur;

  /// guarantee an ungetc() buffer
  @ffi.Array.multi([3])
  external ffi.Array<ffi.UnsignedChar> _ubuf;

  /// guarantee a getc() buffer
  @ffi.Array.multi([1])
  external ffi.Array<ffi.UnsignedChar> _nbuf;

  /// buffer for fgetln()
  external __sbuf _lb;

  /// stat.st_blksize (may be != _bf._size)
  @ffi.Int()
  external int _blksize;

  /// current lseek offset (see WARNING)
  @fpos_t()
  external int _offset;
}

typedef fpos_t = __darwin_off_t;
typedef __darwin_off_t = __int64_t;
typedef __int64_t = ffi.LongLong;

/// stdio state variables.
///
/// The following always hold:
///
/// if (_flags&(__SLBF|__SWR)) == (__SLBF|__SWR),
/// _lbfsize is -_bf._size, else _lbfsize is 0
/// if _flags&__SRD, _w is 0
/// if _flags&__SWR, _r is 0
///
/// This ensures that the getc and putc macros (or inline functions) never
/// try to write or read from a file that is in `read' or `write' mode.
/// (Moreover, they can, and do, automatically switch from read mode to
/// write mode, and back, on "r+" and "w+" files.)
///
/// _lbfsize is used only to make the inline line-buffered output stream
/// code as compact as possible.
///
/// _ub, _up, and _ur are used when ungetc() pushes back more characters
/// than fit in the current _bf, or when ungetc() pushes back a character
/// that does not match the previous one in _bf.  When this happens,
/// _ub._base becomes non-nil (i.e., a stream has ungetc() data iff
/// _ub._base!=NULL) and _up and _ur save the current values of _p and _r.
///
/// NB: see WARNING above before changing the layout of this structure!
typedef FILE = __sFILE;
typedef va_list = __darwin_va_list;
typedef __darwin_va_list = __builtin_va_list;
typedef __builtin_va_list = ffi.Pointer<ffi.Char>;
typedef off_t = __darwin_off_t;
typedef ssize_t = __darwin_ssize_t;
typedef __darwin_ssize_t = ffi.Long;

/// C interface
///
/// TODO: show sample usage
final class llama_model extends ffi.Opaque {}

final class llama_context extends ffi.Opaque {}

abstract class llama_log_level {
  static const int LLAMA_LOG_LEVEL_ERROR = 2;
  static const int LLAMA_LOG_LEVEL_WARN = 3;
  static const int LLAMA_LOG_LEVEL_INFO = 4;
}

abstract class llama_vocab_type {
  /// SentencePiece
  static const int LLAMA_VOCAB_TYPE_SPM = 0;

  /// Byte Pair Encoding
  static const int LLAMA_VOCAB_TYPE_BPE = 1;
}

abstract class llama_token_type {
  static const int LLAMA_TOKEN_TYPE_UNDEFINED = 0;
  static const int LLAMA_TOKEN_TYPE_NORMAL = 1;
  static const int LLAMA_TOKEN_TYPE_UNKNOWN = 2;
  static const int LLAMA_TOKEN_TYPE_CONTROL = 3;
  static const int LLAMA_TOKEN_TYPE_USER_DEFINED = 4;
  static const int LLAMA_TOKEN_TYPE_UNUSED = 5;
  static const int LLAMA_TOKEN_TYPE_BYTE = 6;
}

/// model file types
abstract class llama_ftype {
  static const int LLAMA_FTYPE_ALL_F32 = 0;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_F16 = 1;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q4_0 = 2;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q4_1 = 3;

  /// tok_embeddings.weight and output.weight are F16
  static const int LLAMA_FTYPE_MOSTLY_Q4_1_SOME_F16 = 4;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q8_0 = 7;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q5_0 = 8;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q5_1 = 9;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q2_K = 10;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q3_K_S = 11;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q3_K_M = 12;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q3_K_L = 13;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q4_K_S = 14;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q4_K_M = 15;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q5_K_S = 16;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q5_K_M = 17;

  /// except 1d tensors
  static const int LLAMA_FTYPE_MOSTLY_Q6_K = 18;

  /// not specified in the model file
  static const int LLAMA_FTYPE_GUESSED = 1024;
}

final class llama_token_data extends ffi.Struct {
  /// token id
  @llama_token()
  external int id;

  /// log-odds of the token
  @ffi.Float()
  external double logit;

  /// probability of the token
  @ffi.Float()
  external double p;
}

typedef llama_token = ffi.Int;

final class llama_token_data_array extends ffi.Struct {
  external ffi.Pointer<llama_token_data> data;

  @ffi.Size()
  external int size;

  @ffi.Bool()
  external bool sorted;
}

final class llama_context_params extends ffi.Struct {
  /// RNG seed, -1 for random
  @ffi.Uint32()
  external int seed;

  /// text context
  @ffi.Int32()
  external int n_ctx;

  /// prompt processing batch size
  @ffi.Int32()
  external int n_batch;

  /// number of layers to store in VRAM
  @ffi.Int32()
  external int n_gpu_layers;

  /// the GPU that is used for scratch and small tensors
  @ffi.Int32()
  external int main_gpu;

  /// how to split layers across multiple GPUs (size: LLAMA_MAX_DEVICES)
  external ffi.Pointer<ffi.Float> tensor_split;

  /// RoPE base frequency
  @ffi.Float()
  external double rope_freq_base;

  /// RoPE frequency scaling factor
  @ffi.Float()
  external double rope_freq_scale;

  /// called with a progress value between 0 and 1, pass NULL to disable
  external llama_progress_callback progress_callback;

  /// context pointer passed to the progress callback
  external ffi.Pointer<ffi.Void> progress_callback_user_data;

  /// if true, reduce VRAM usage at the cost of performance
  @ffi.Bool()
  external bool low_vram;

  /// if true, use experimental mul_mat_q kernels
  @ffi.Bool()
  external bool mul_mat_q;

  /// use fp16 for KV cache
  @ffi.Bool()
  external bool f16_kv;

  /// the llama_eval() call computes all logits, not just the last one
  @ffi.Bool()
  external bool logits_all;

  /// only load the vocabulary, no weights
  @ffi.Bool()
  external bool vocab_only;

  /// use mmap if possible
  @ffi.Bool()
  external bool use_mmap;

  /// force system to keep model in RAM
  @ffi.Bool()
  external bool use_mlock;

  /// embedding mode only
  @ffi.Bool()
  external bool embedding;
}

typedef llama_progress_callback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Float progress, ffi.Pointer<ffi.Void> ctx)>>;

/// model quantization parameters
final class llama_model_quantize_params extends ffi.Struct {
  /// number of threads to use for quantizing, if <=0 will use std::thread::hardware_concurrency()
  @ffi.Int()
  external int nthread;

  /// quantize to this llama_ftype
  @ffi.Int32()
  external int ftype;

  /// allow quantizing non-f32/f16 tensors
  @ffi.Bool()
  external bool allow_requantize;

  /// quantize output.weight
  @ffi.Bool()
  external bool quantize_output_tensor;

  /// only copy tensors - ftype, allow_requantize and quantize_output_tensor are ignored
  @ffi.Bool()
  external bool only_copy;
}

/// grammar types
final class llama_grammar extends ffi.Opaque {}

/// grammar element type
abstract class llama_gretype {
  /// end of rule definition
  static const int LLAMA_GRETYPE_END = 0;

  /// start of alternate definition for rule
  static const int LLAMA_GRETYPE_ALT = 1;

  /// non-terminal element: reference to rule
  static const int LLAMA_GRETYPE_RULE_REF = 2;

  /// terminal element: character (code point)
  static const int LLAMA_GRETYPE_CHAR = 3;

  /// inverse char(s) ([^a], [^a-b] [^abc])
  static const int LLAMA_GRETYPE_CHAR_NOT = 4;

  /// modifies a preceding LLAMA_GRETYPE_CHAR or LLAMA_GRETYPE_CHAR_ALT to
  /// be an inclusive range ([a-z])
  static const int LLAMA_GRETYPE_CHAR_RNG_UPPER = 5;

  /// modifies a preceding LLAMA_GRETYPE_CHAR or
  /// LLAMA_GRETYPE_CHAR_RNG_UPPER to add an alternate char to match ([ab], [a-zA])
  static const int LLAMA_GRETYPE_CHAR_ALT = 6;
}

final class llama_grammar_element extends ffi.Struct {
  @ffi.Int32()
  external int type;

  /// Unicode code point or rule ID
  @ffi.Uint32()
  external int value;
}

/// performance timing information
final class llama_timings extends ffi.Struct {
  @ffi.Double()
  external double t_start_ms;

  @ffi.Double()
  external double t_end_ms;

  @ffi.Double()
  external double t_load_ms;

  @ffi.Double()
  external double t_sample_ms;

  @ffi.Double()
  external double t_p_eval_ms;

  @ffi.Double()
  external double t_eval_ms;

  @ffi.Int32()
  external int n_sample;

  @ffi.Int32()
  external int n_p_eval;

  @ffi.Int32()
  external int n_eval;
}

/// Beam search
final class llama_beam_view extends ffi.Struct {
  external ffi.Pointer<llama_token> tokens;

  @ffi.Size()
  external int n_tokens;

  /// Cumulative beam probability (renormalized relative to all beams)
  @ffi.Float()
  external double p;

  /// Callback should set this to true when a beam is at end-of-beam.
  @ffi.Bool()
  external bool eob;
}

/// Passed to beam_search_callback function.
/// Whenever 0 < common_prefix_length, this number of tokens should be copied from any of the beams
/// (e.g. beams[0]) as they will be removed (shifted) from all beams in all subsequent callbacks.
/// These pointers are valid only during the synchronous callback, so should not be saved.
final class llama_beams_state extends ffi.Struct {
  external ffi.Pointer<llama_beam_view> beam_views;

  /// Number of elements in beam_views[].
  @ffi.Size()
  external int n_beams;

  /// Current max length of prefix tokens shared by all beams.
  @ffi.Size()
  external int common_prefix_length;

  /// True iff this is the last callback invocation.
  @ffi.Bool()
  external bool last_call;
}

/// Type of pointer to the beam_search_callback function.
/// void* callback_data is any custom data passed to llama_beam_search, that is subsequently
/// passed back to beam_search_callback. This avoids having to use global variables in the callback.
typedef llama_beam_search_callback_fn_t = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<ffi.Void>, llama_beams_state)>>;

/// Signature for logging events
/// Note that text includes the new line character at the end for most events.
/// If your logging mechanism cannot handle that, check if the last character is '\n' and strip it
/// if it exists.
/// It might not exist for progress report where '.' is output repeatedly.
typedef llama_log_callback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Int32 level, ffi.Pointer<ffi.Char> text,
            ffi.Pointer<ffi.Void> user_data)>>;

const int __WORDSIZE = 64;

const int __DARWIN_ONLY_64_BIT_INO_T = 1;

const int __DARWIN_ONLY_UNIX_CONFORMANCE = 1;

const int __DARWIN_ONLY_VERS_1050 = 1;

const int __DARWIN_UNIX03 = 1;

const int __DARWIN_64_BIT_INO_T = 1;

const int __DARWIN_VERS_1050 = 1;

const int __DARWIN_NON_CANCELABLE = 0;

const String __DARWIN_SUF_EXTSN = '\$DARWIN_EXTSN';

const int __DARWIN_C_ANSI = 4096;

const int __DARWIN_C_FULL = 900000;

const int __DARWIN_C_LEVEL = 900000;

const int __STDC_WANT_LIB_EXT1__ = 1;

const int __DARWIN_NO_LONG_LONG = 0;

const int _DARWIN_FEATURE_64_BIT_INODE = 1;

const int _DARWIN_FEATURE_ONLY_64_BIT_INODE = 1;

const int _DARWIN_FEATURE_ONLY_VERS_1050 = 1;

const int _DARWIN_FEATURE_ONLY_UNIX_CONFORMANCE = 1;

const int _DARWIN_FEATURE_UNIX_CONFORMANCE = 3;

const int __has_ptrcheck = 0;

const int __DARWIN_NULL = 0;

const int __PTHREAD_SIZE__ = 8176;

const int __PTHREAD_ATTR_SIZE__ = 56;

const int __PTHREAD_MUTEXATTR_SIZE__ = 8;

const int __PTHREAD_MUTEX_SIZE__ = 56;

const int __PTHREAD_CONDATTR_SIZE__ = 8;

const int __PTHREAD_COND_SIZE__ = 40;

const int __PTHREAD_ONCE_SIZE__ = 8;

const int __PTHREAD_RWLOCK_SIZE__ = 192;

const int __PTHREAD_RWLOCKATTR_SIZE__ = 16;

const int USER_ADDR_NULL = 0;

const int INT8_MAX = 127;

const int INT16_MAX = 32767;

const int INT32_MAX = 2147483647;

const int INT64_MAX = 9223372036854775807;

const int INT8_MIN = -128;

const int INT16_MIN = -32768;

const int INT32_MIN = -2147483648;

const int INT64_MIN = -9223372036854775808;

const int UINT8_MAX = 255;

const int UINT16_MAX = 65535;

const int UINT32_MAX = 4294967295;

const int UINT64_MAX = -1;

const int INT_LEAST8_MIN = -128;

const int INT_LEAST16_MIN = -32768;

const int INT_LEAST32_MIN = -2147483648;

const int INT_LEAST64_MIN = -9223372036854775808;

const int INT_LEAST8_MAX = 127;

const int INT_LEAST16_MAX = 32767;

const int INT_LEAST32_MAX = 2147483647;

const int INT_LEAST64_MAX = 9223372036854775807;

const int UINT_LEAST8_MAX = 255;

const int UINT_LEAST16_MAX = 65535;

const int UINT_LEAST32_MAX = 4294967295;

const int UINT_LEAST64_MAX = -1;

const int INT_FAST8_MIN = -128;

const int INT_FAST16_MIN = -32768;

const int INT_FAST32_MIN = -2147483648;

const int INT_FAST64_MIN = -9223372036854775808;

const int INT_FAST8_MAX = 127;

const int INT_FAST16_MAX = 32767;

const int INT_FAST32_MAX = 2147483647;

const int INT_FAST64_MAX = 9223372036854775807;

const int UINT_FAST8_MAX = 255;

const int UINT_FAST16_MAX = 65535;

const int UINT_FAST32_MAX = 4294967295;

const int UINT_FAST64_MAX = -1;

const int INTPTR_MAX = 9223372036854775807;

const int INTPTR_MIN = -9223372036854775808;

const int UINTPTR_MAX = -1;

const int INTMAX_MAX = 9223372036854775807;

const int UINTMAX_MAX = -1;

const int INTMAX_MIN = -9223372036854775808;

const int PTRDIFF_MIN = -9223372036854775808;

const int PTRDIFF_MAX = 9223372036854775807;

const int SIZE_MAX = -1;

const int RSIZE_MAX = 9223372036854775807;

const int WCHAR_MAX = 2147483647;

const int WCHAR_MIN = -2147483648;

const int WINT_MIN = -2147483648;

const int WINT_MAX = 2147483647;

const int SIG_ATOMIC_MIN = -2147483648;

const int SIG_ATOMIC_MAX = 2147483647;

const int __DARWIN_WCHAR_MAX = 2147483647;

const int __DARWIN_WCHAR_MIN = -2147483648;

const int __DARWIN_WEOF = -1;

const int _FORTIFY_SOURCE = 2;

const int NULL = 0;

const int __bool_true_false_are_defined = 1;

const int true1 = 1;

const int false1 = 0;

const int GGML_FILE_MAGIC = 1734831468;

const int GGML_FILE_VERSION = 1;

const int GGML_QNT_VERSION = 2;

const int GGML_QNT_VERSION_FACTOR = 1000;

const int GGML_MAX_DIMS = 4;

const int GGML_MAX_NODES = 4096;

const int GGML_MAX_PARAMS = 256;

const int GGML_MAX_CONTEXTS = 64;

const int GGML_MAX_SRC = 6;

const int GGML_MAX_NAME = 64;

const int GGML_MAX_OP_PARAMS = 32;

const int GGML_DEFAULT_N_THREADS = 4;

const int GGML_MEM_ALIGN = 16;

const int GGML_EXIT_SUCCESS = 0;

const int GGML_EXIT_ABORTED = 1;

const int GGUF_MAGIC = 1179993927;

const int GGUF_VERSION = 2;

const int GGUF_DEFAULT_ALIGNMENT = 32;

const int GGML_GRAPH_HASHTABLE_SIZE = 8273;

const int GGML_N_TASKS_MAX = -1;

const int LLAMA_MAX_DEVICES = 1;

const int __API_TO_BE_DEPRECATED = 100000;

const int __API_TO_BE_DEPRECATED_MACOS = 100000;

const int __API_TO_BE_DEPRECATED_IOS = 100000;

const int __API_TO_BE_DEPRECATED_TVOS = 100000;

const int __API_TO_BE_DEPRECATED_WATCHOS = 100000;

const int __API_TO_BE_DEPRECATED_MACCATALYST = 100000;

const int __API_TO_BE_DEPRECATED_DRIVERKIT = 100000;

const int __MAC_10_0 = 1000;

const int __MAC_10_1 = 1010;

const int __MAC_10_2 = 1020;

const int __MAC_10_3 = 1030;

const int __MAC_10_4 = 1040;

const int __MAC_10_5 = 1050;

const int __MAC_10_6 = 1060;

const int __MAC_10_7 = 1070;

const int __MAC_10_8 = 1080;

const int __MAC_10_9 = 1090;

const int __MAC_10_10 = 101000;

const int __MAC_10_10_2 = 101002;

const int __MAC_10_10_3 = 101003;

const int __MAC_10_11 = 101100;

const int __MAC_10_11_2 = 101102;

const int __MAC_10_11_3 = 101103;

const int __MAC_10_11_4 = 101104;

const int __MAC_10_12 = 101200;

const int __MAC_10_12_1 = 101201;

const int __MAC_10_12_2 = 101202;

const int __MAC_10_12_4 = 101204;

const int __MAC_10_13 = 101300;

const int __MAC_10_13_1 = 101301;

const int __MAC_10_13_2 = 101302;

const int __MAC_10_13_4 = 101304;

const int __MAC_10_14 = 101400;

const int __MAC_10_14_1 = 101401;

const int __MAC_10_14_4 = 101404;

const int __MAC_10_14_6 = 101406;

const int __MAC_10_15 = 101500;

const int __MAC_10_15_1 = 101501;

const int __MAC_10_15_4 = 101504;

const int __MAC_10_16 = 101600;

const int __MAC_11_0 = 110000;

const int __MAC_11_1 = 110100;

const int __MAC_11_3 = 110300;

const int __MAC_11_4 = 110400;

const int __MAC_11_5 = 110500;

const int __MAC_11_6 = 110600;

const int __MAC_12_0 = 120000;

const int __MAC_12_1 = 120100;

const int __MAC_12_2 = 120200;

const int __MAC_12_3 = 120300;

const int __MAC_13_0 = 130000;

const int __MAC_13_1 = 130100;

const int __MAC_13_2 = 130200;

const int __MAC_13_3 = 130300;

const int __IPHONE_2_0 = 20000;

const int __IPHONE_2_1 = 20100;

const int __IPHONE_2_2 = 20200;

const int __IPHONE_3_0 = 30000;

const int __IPHONE_3_1 = 30100;

const int __IPHONE_3_2 = 30200;

const int __IPHONE_4_0 = 40000;

const int __IPHONE_4_1 = 40100;

const int __IPHONE_4_2 = 40200;

const int __IPHONE_4_3 = 40300;

const int __IPHONE_5_0 = 50000;

const int __IPHONE_5_1 = 50100;

const int __IPHONE_6_0 = 60000;

const int __IPHONE_6_1 = 60100;

const int __IPHONE_7_0 = 70000;

const int __IPHONE_7_1 = 70100;

const int __IPHONE_8_0 = 80000;

const int __IPHONE_8_1 = 80100;

const int __IPHONE_8_2 = 80200;

const int __IPHONE_8_3 = 80300;

const int __IPHONE_8_4 = 80400;

const int __IPHONE_9_0 = 90000;

const int __IPHONE_9_1 = 90100;

const int __IPHONE_9_2 = 90200;

const int __IPHONE_9_3 = 90300;

const int __IPHONE_10_0 = 100000;

const int __IPHONE_10_1 = 100100;

const int __IPHONE_10_2 = 100200;

const int __IPHONE_10_3 = 100300;

const int __IPHONE_11_0 = 110000;

const int __IPHONE_11_1 = 110100;

const int __IPHONE_11_2 = 110200;

const int __IPHONE_11_3 = 110300;

const int __IPHONE_11_4 = 110400;

const int __IPHONE_12_0 = 120000;

const int __IPHONE_12_1 = 120100;

const int __IPHONE_12_2 = 120200;

const int __IPHONE_12_3 = 120300;

const int __IPHONE_12_4 = 120400;

const int __IPHONE_13_0 = 130000;

const int __IPHONE_13_1 = 130100;

const int __IPHONE_13_2 = 130200;

const int __IPHONE_13_3 = 130300;

const int __IPHONE_13_4 = 130400;

const int __IPHONE_13_5 = 130500;

const int __IPHONE_13_6 = 130600;

const int __IPHONE_13_7 = 130700;

const int __IPHONE_14_0 = 140000;

const int __IPHONE_14_1 = 140100;

const int __IPHONE_14_2 = 140200;

const int __IPHONE_14_3 = 140300;

const int __IPHONE_14_5 = 140500;

const int __IPHONE_14_6 = 140600;

const int __IPHONE_14_7 = 140700;

const int __IPHONE_14_8 = 140800;

const int __IPHONE_15_0 = 150000;

const int __IPHONE_15_1 = 150100;

const int __IPHONE_15_2 = 150200;

const int __IPHONE_15_3 = 150300;

const int __IPHONE_15_4 = 150400;

const int __IPHONE_16_0 = 160000;

const int __IPHONE_16_1 = 160100;

const int __IPHONE_16_2 = 160200;

const int __IPHONE_16_3 = 160300;

const int __IPHONE_16_4 = 160400;

const int __TVOS_9_0 = 90000;

const int __TVOS_9_1 = 90100;

const int __TVOS_9_2 = 90200;

const int __TVOS_10_0 = 100000;

const int __TVOS_10_0_1 = 100001;

const int __TVOS_10_1 = 100100;

const int __TVOS_10_2 = 100200;

const int __TVOS_11_0 = 110000;

const int __TVOS_11_1 = 110100;

const int __TVOS_11_2 = 110200;

const int __TVOS_11_3 = 110300;

const int __TVOS_11_4 = 110400;

const int __TVOS_12_0 = 120000;

const int __TVOS_12_1 = 120100;

const int __TVOS_12_2 = 120200;

const int __TVOS_12_3 = 120300;

const int __TVOS_12_4 = 120400;

const int __TVOS_13_0 = 130000;

const int __TVOS_13_2 = 130200;

const int __TVOS_13_3 = 130300;

const int __TVOS_13_4 = 130400;

const int __TVOS_14_0 = 140000;

const int __TVOS_14_1 = 140100;

const int __TVOS_14_2 = 140200;

const int __TVOS_14_3 = 140300;

const int __TVOS_14_5 = 140500;

const int __TVOS_14_6 = 140600;

const int __TVOS_14_7 = 140700;

const int __TVOS_15_0 = 150000;

const int __TVOS_15_1 = 150100;

const int __TVOS_15_2 = 150200;

const int __TVOS_15_3 = 150300;

const int __TVOS_15_4 = 150400;

const int __TVOS_16_0 = 160000;

const int __TVOS_16_1 = 160100;

const int __TVOS_16_2 = 160200;

const int __TVOS_16_3 = 160300;

const int __TVOS_16_4 = 160400;

const int __WATCHOS_1_0 = 10000;

const int __WATCHOS_2_0 = 20000;

const int __WATCHOS_2_1 = 20100;

const int __WATCHOS_2_2 = 20200;

const int __WATCHOS_3_0 = 30000;

const int __WATCHOS_3_1 = 30100;

const int __WATCHOS_3_1_1 = 30101;

const int __WATCHOS_3_2 = 30200;

const int __WATCHOS_4_0 = 40000;

const int __WATCHOS_4_1 = 40100;

const int __WATCHOS_4_2 = 40200;

const int __WATCHOS_4_3 = 40300;

const int __WATCHOS_5_0 = 50000;

const int __WATCHOS_5_1 = 50100;

const int __WATCHOS_5_2 = 50200;

const int __WATCHOS_5_3 = 50300;

const int __WATCHOS_6_0 = 60000;

const int __WATCHOS_6_1 = 60100;

const int __WATCHOS_6_2 = 60200;

const int __WATCHOS_7_0 = 70000;

const int __WATCHOS_7_1 = 70100;

const int __WATCHOS_7_2 = 70200;

const int __WATCHOS_7_3 = 70300;

const int __WATCHOS_7_4 = 70400;

const int __WATCHOS_7_5 = 70500;

const int __WATCHOS_7_6 = 70600;

const int __WATCHOS_8_0 = 80000;

const int __WATCHOS_8_1 = 80100;

const int __WATCHOS_8_3 = 80300;

const int __WATCHOS_8_4 = 80400;

const int __WATCHOS_8_5 = 80500;

const int __WATCHOS_9_0 = 90000;

const int __WATCHOS_9_1 = 90100;

const int __WATCHOS_9_2 = 90200;

const int __WATCHOS_9_3 = 90300;

const int __WATCHOS_9_4 = 90400;

const int MAC_OS_X_VERSION_10_0 = 1000;

const int MAC_OS_X_VERSION_10_1 = 1010;

const int MAC_OS_X_VERSION_10_2 = 1020;

const int MAC_OS_X_VERSION_10_3 = 1030;

const int MAC_OS_X_VERSION_10_4 = 1040;

const int MAC_OS_X_VERSION_10_5 = 1050;

const int MAC_OS_X_VERSION_10_6 = 1060;

const int MAC_OS_X_VERSION_10_7 = 1070;

const int MAC_OS_X_VERSION_10_8 = 1080;

const int MAC_OS_X_VERSION_10_9 = 1090;

const int MAC_OS_X_VERSION_10_10 = 101000;

const int MAC_OS_X_VERSION_10_10_2 = 101002;

const int MAC_OS_X_VERSION_10_10_3 = 101003;

const int MAC_OS_X_VERSION_10_11 = 101100;

const int MAC_OS_X_VERSION_10_11_2 = 101102;

const int MAC_OS_X_VERSION_10_11_3 = 101103;

const int MAC_OS_X_VERSION_10_11_4 = 101104;

const int MAC_OS_X_VERSION_10_12 = 101200;

const int MAC_OS_X_VERSION_10_12_1 = 101201;

const int MAC_OS_X_VERSION_10_12_2 = 101202;

const int MAC_OS_X_VERSION_10_12_4 = 101204;

const int MAC_OS_X_VERSION_10_13 = 101300;

const int MAC_OS_X_VERSION_10_13_1 = 101301;

const int MAC_OS_X_VERSION_10_13_2 = 101302;

const int MAC_OS_X_VERSION_10_13_4 = 101304;

const int MAC_OS_X_VERSION_10_14 = 101400;

const int MAC_OS_X_VERSION_10_14_1 = 101401;

const int MAC_OS_X_VERSION_10_14_4 = 101404;

const int MAC_OS_X_VERSION_10_14_6 = 101406;

const int MAC_OS_X_VERSION_10_15 = 101500;

const int MAC_OS_X_VERSION_10_15_1 = 101501;

const int MAC_OS_X_VERSION_10_16 = 101600;

const int MAC_OS_VERSION_11_0 = 110000;

const int MAC_OS_VERSION_12_0 = 120000;

const int MAC_OS_VERSION_13_0 = 130000;

const int __DRIVERKIT_19_0 = 190000;

const int __DRIVERKIT_20_0 = 200000;

const int __DRIVERKIT_21_0 = 210000;

const int __MAC_OS_X_VERSION_MIN_REQUIRED = 130000;

const int __MAC_OS_X_VERSION_MAX_ALLOWED = 130300;

const int __ENABLE_LEGACY_MAC_AVAILABILITY = 1;

const int RENAME_SECLUDE = 1;

const int RENAME_SWAP = 2;

const int RENAME_EXCL = 4;

const int RENAME_RESERVED1 = 8;

const int RENAME_NOFOLLOW_ANY = 16;

const int __SLBF = 1;

const int __SNBF = 2;

const int __SRD = 4;

const int __SWR = 8;

const int __SRW = 16;

const int __SEOF = 32;

const int __SERR = 64;

const int __SMBF = 128;

const int __SAPP = 256;

const int __SSTR = 512;

const int __SOPT = 1024;

const int __SNPT = 2048;

const int __SOFF = 4096;

const int __SMOD = 8192;

const int __SALC = 16384;

const int __SIGN = 32768;

const int _IOFBF = 0;

const int _IOLBF = 1;

const int _IONBF = 2;

const int BUFSIZ = 1024;

const int EOF = -1;

const int FOPEN_MAX = 20;

const int FILENAME_MAX = 1024;

const String P_tmpdir = '/var/tmp/';

const int L_tmpnam = 1024;

const int TMP_MAX = 308915776;

const int SEEK_SET = 0;

const int SEEK_CUR = 1;

const int SEEK_END = 2;

const int L_ctermid = 1024;

const int LLAMA_DEFAULT_SEED = 4294967295;

const int LLAMA_FILE_MAGIC_GGSN = 1734833006;

const int LLAMA_SESSION_MAGIC = 1734833006;

const int LLAMA_SESSION_VERSION = 1;
